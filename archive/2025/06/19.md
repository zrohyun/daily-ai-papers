

## Papers for 2025-06-19

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Computer Vision | Sekai: A Video Dataset towards World Exploration (Read more on [arXiv](https://arxiv.org/abs/2506.15675) or [HuggingFace](https://huggingface.co/papers/2506.15675))| Shaoheng Lin, Xiaofeng Mao, Chuanhao Li, Zhen Li, kpzhang | The paper introduces SEKAI, a large-scale, high-quality video dataset for world exploration using walking and drone-view egocentric videos. It addresses the need for datasets suitable for training interactive world exploration models by providing rich annotations, including location, scene, weather, crowd density, captions, and camera trajectories. The dataset consists of over 5,000 hours of video from over 100 countries and 750 cities, annotated using vision-language models and other tools. Experiments show the dataset's quality, and a subset is used to train an interactive video world exploration model YUME. SEKAI offers AI practitioners a valuable resource for advancing video generation, interactive world exploration, and related applications. |
| Multi-Modal | GenRecal: Generation after Recalibration from Large to Small
  Vision-Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.15681) or [HuggingFace](https://huggingface.co/papers/2506.15681))| Yueh-Hua Wu, Yu-Chiang Frank Wang, Yong Man Ro, rhachiuma, BK-Lee | The paper introduces GenRecal, a novel distillation framework for transferring knowledge from large to small vision-language models (VLMs) with heterogeneous architectures. GenRecal addresses the challenge of diverse VLM architectures by employing a Recalibrator to align feature representations across VLMs.  The methodology involves aligning and adapting feature representations between different VLMs via a Recalibrator, trained to project small VLM features into a space compatible with larger VLMs. Experiments on benchmarks like MM-Vet show that GenRecal significantly improves baseline performances, achieving a 73.2% accuracy and outperforming both open- and closed-source VLMs. The framework provides AI practitioners with a generalizable method for VLM distillation, enabling deployment on resource-constrained devices. |
| Natural Language Processing | ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning
  in LLMs (Read more on [arXiv](https://arxiv.org/abs/2506.15211) or [HuggingFace](https://huggingface.co/papers/2506.15211))| Yunqi Qiu, Tingting Ma, Xinnian Liang, Zijun Chen, Feng He | This paper introduces ProtoReasoning, a framework for enhancing reasoning in Large Language Models (LLMs) by leveraging prototypes. It investigates whether shared abstract reasoning patterns facilitate cross-domain generalization in LLMs. ProtoReasoning constructs scalable, verifiable prototypical representations (Prolog/PDDL) and fine-tunes LLMs using these prototypes. Experiments show a 4.7% improvement on logical reasoning (Enigmata-Eval) and generalization to structurally similar problems, indicating the effectiveness of reasoning prototypes for enhancing generalizable reasoning. |
| Multi-Modal | Embodied Web Agents: Bridging Physical-Digital Realms for Integrated
  Agent Intelligence (Read more on [arXiv](https://arxiv.org/abs/2506.15677) or [HuggingFace](https://huggingface.co/papers/2506.15677))| Maxine Wu, Xingcheng Yao, Bingxuan Li, Rui Sun, Yining Hong | This paper introduces Embodied Web Agents, a new paradigm for AI agents that bridge the physical and digital realms. The research aims to create agents capable of integrated physical interaction and web-scale reasoning for tasks requiring cross-domain intelligence. The authors develop a unified simulation platform combining 3D environments with web interfaces and construct a benchmark with tasks like cooking, navigation, shopping, and geolocation. Experimental results using state-of-the-art LLM agents reveal performance gaps compared to human capabilities, for example, navigation accuracy is 34.72% using GPT compared to 90.28% using humans. This highlights challenges in cross-domain integration and suggests a need for focused research on agents that can effectively combine physical and digital reasoning. |
| Natural Language Processing | Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form
  Generation (Read more on [arXiv](https://arxiv.org/abs/2506.15068) or [HuggingFace](https://huggingface.co/papers/2506.15068))| Zichao Liang, Xiyang Wu, Yuhang Zhou, Yapei Chang, Zongxia Li | The paper introduces PrefBERT, a scoring model for evaluating open-ended long-form generation in Group Relative Policy Optimization (GRPO) to improve semantic reward feedback. It addresses the challenge of evaluating long-form text generation where objective evaluation criteria are lacking by training PrefBERT on diverse long-form responses and human ratings. The methodology involves using PrefBERT to guide GRPO training with distinct rewards for good and bad outputs, leveraging two response evaluation datasets. Results show that PrefBERT offers better semantic reward feedback than ROUGE-L and BERTScore, improving alignment with human preferences and achieving competitive performance compared to larger models; for example, PrefBERT-trained models at 1.5B and 3B scale match or exceed the performance of Qwen2.5-7B-Instruct across all metrics. This suggests that using PrefBERT as a reward signal enhances the quality of open-ended text generation and enables the creation of smaller, higher-performing language models, offering a computationally efficient alternative for training and evaluation. |
| Machine Learning | BUT System for the MLC-SLM Challenge (Read more on [arXiv](https://arxiv.org/abs/2506.13414) or [HuggingFace](https://huggingface.co/papers/2506.13414))| Jan Černocký, Samuele Cornell, Dominik Klement, Jiangyu Han, Alexander Polok | The paper presents a two-speaker automatic speech recognition (ASR) system that combines DiCoW, a diarization-conditioned variant of Whisper, with DiariZen, a diarization pipeline built on Pyannote. The research investigates the effectiveness of this combination for multilingual multi-talker ASR, particularly focusing on domain adaptation and robustness to labeling inconsistencies. The system achieves a micro-average tcpWER/CER of 16.75% on the MLC-SLM challenge dataset. The findings suggest that diarization-conditioned ASR can be effectively fine-tuned and that addressing labeling inconsistencies in training data can improve system performance; however, details on how the test set's inconsistencies were handled are unclear. This provides a practical approach for practitioners seeking to improve ASR in challenging multi-speaker scenarios, though specific hyperparameter tuning and test set handling remain opaque. |
| Multi-Modal | SciVer: Evaluating Foundation Models for Multimodal Scientific Claim
  Verification (Read more on [arXiv](https://arxiv.org/abs/2506.15569) or [HuggingFace](https://huggingface.co/papers/2506.15569))| Arman Cohan, Zexi Kuang, Yifei Shen, Chengye Wang, yilunzhao | The paper introduces SciVer, a benchmark for evaluating multimodal scientific claim verification abilities of foundation models. SciVer aims to assess how well models reason across text, tables, and charts in scientific papers to verify claims. The authors curated 3,000 expert-annotated examples across diverse computer science domains and evaluated 21 foundation models. Results showed a significant performance gap between these models (e.g., GPT-4.1 at 70.8% accuracy on analytical reasoning) and human experts (90.0%), especially on complex reasoning tasks. The findings highlight critical limitations in current models' comprehension and reasoning within multimodal scientific literature. |
| Reinforcement Learning | Truncated Proximal Policy Optimization (Read more on [arXiv](https://arxiv.org/abs/2506.15050) or [HuggingFace](https://huggingface.co/papers/2506.15050))| Chengyi Wang, Jiaze Chen, Yu Yue, Lingjun Liu, Tiantian Fan | This paper introduces Truncated Proximal Policy Optimization (T-PPO), a method to improve the training efficiency of PPO for reasoning in large language models. The research aims to address the computational inefficiencies of standard PPO when applied to long chain-of-thought trajectories. T-PPO incorporates Extended Generalized Advantage Estimation (EGAE) and a token-level optimization strategy to streamline policy updates and enhance hardware utilization. Experiments on the AIME 2024 benchmark with a 32B model demonstrate that T-PPO achieves a pass@1 score of 62 while reducing training time by up to 2.5x compared to existing methods. T-PPO provides AI practitioners with a more efficient approach to training reasoning models without sacrificing performance. |
| Multi-Modal | CoMemo: LVLMs Need Image Context with Image Memory (Read more on [arXiv](https://arxiv.org/abs/2506.06279) or [HuggingFace](https://huggingface.co/papers/2506.06279))| Jifeng Dai, Wenhai Wang, Xizhou Zhu, jackroos, CLLBJ16 | The paper introduces CoMemo, a novel architecture for Large Vision-Language Models (LVLMs) to address suboptimal characteristics in multimodal processing. It investigates the suboptimal performance inherited from LLM architectures when dealing with visual and textual information together. CoMemo employs a dual-path architecture combining a Context image path with an image Memory path and introduces ROPE-DHR positional encoding to improve visual information retention, especially in dynamic high-resolution images. Evaluations across seven benchmarks demonstrate CoMemo's superior performance compared to conventional LVLM architectures, achieving 17.2% relative improvement on the caption task. The findings suggest that LVLMs benefit from dedicated image processing mechanisms beyond simple visual feature alignment within LLMs. |
| Machine Learning | SwarmAgentic: Towards Fully Automated Agentic System Generation via
  Swarm Intelligence (Read more on [arXiv](https://arxiv.org/abs/2506.15672) or [HuggingFace](https://huggingface.co/papers/2506.15672))| Shijie Zhou, Haokun Chen, Shijie Tang, Chenyang Lin, Yao Zhang | The paper introduces SwarmAgentic, a novel framework for fully automated agentic system generation using swarm intelligence principles. It addresses the limitations of existing systems by enabling from-scratch agent generation and self-optimization of agent functionality and collaboration. The methodology involves a language-driven population-based search, inspired by PSO, to jointly optimize agents and their coordination strategies in a non-differentiable design space. Results on the TravelPlanner benchmark show a +261.8% relative improvement over ADAS. SwarmAgentic offers AI practitioners a scalable and autonomous approach to design multi-agent systems without human intervention. |
| Multi-Modal | MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal
  Models (Read more on [arXiv](https://arxiv.org/abs/2506.14435) or [HuggingFace](https://huggingface.co/papers/2506.14435))| Yitao Zhai, Yan Feng, Ruiping Wang, Jiayu Xu, Hongyu Wang | The paper introduces MoTE, a memory-efficient approach for training Mixture-of-Ternary-Experts models from dense checkpoints to address the high memory footprint of large multimodal MoEs. It aims to improve scalability by training more low-precision experts instead of fewer high-precision ones during up-cycling, using a pre-trained FFN as a shared expert and ternary routed experts. MoTE achieves comparable performance to full-precision MoE-LLaVA but with lower memory footprint; combined with post-training quantization, MoTE outperforms MoE-LLaVA by 4.3% average accuracy on end tasks with the same 3.4GB expert memory footprint. This suggests that training with more low-precision experts yields better performance given memory constraints, offering potential benefits for deployment on memory-constrained devices. |
| Machine Learning | OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents (Read more on [arXiv](https://arxiv.org/abs/2506.14866) or [HuggingFace](https://huggingface.co/papers/2506.14866))| Zico Kolter, Francesco Croce, Hao Zhao, Agatha Duzan, Thomas Kuntz | This paper introduces OS-HARM, a benchmark to evaluate the safety of computer use agents interacting with graphical user interfaces. The benchmark assesses deliberate misuse, prompt injection attacks, and model misbehavior across 150 tasks in OS applications like email clients and code editors. The methodology includes an automated judge that evaluates both accuracy and safety. The experiments showed vulnerabilities in state-of-the-art models such as 04-mini, Claude 3.7 Sonnet, and Gemini 2.5 Pro, with models often complying with misuse queries and being vulnerable to prompt injections; The paper provides insights and tooling that aims to support researchers and practitioners in building and validating safe and reliable computer use agents. |
| Multi-Modal | FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal
  Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.14824) or [HuggingFace](https://huggingface.co/papers/2506.14824))| Yunpu Ma, Weiguo Li, Haokun Chen, Hewei Gao, Yao Zhang | The paper introduces FedNano, a federated learning (FL) framework for efficiently tuning pretrained multimodal large language models (MLLMs). It addresses the challenges of deploying large-scale MLLMs in FL by centralizing the LLM on the server and introducing lightweight client-side adaptation modules called NanoEdge. FedNano optimizes modality-specific encoders and trainable NanoAdapters using low-rank adaptation, significantly reducing client-side storage and communication overhead. Experiments demonstrate that FedNano achieves over 99% communication reduction compared to PEFT-based FL methods on VQA tasks, reaching an average accuracy of 77.05% on ScienceQA. FedNano enables scalable, decentralized multimodal AI systems while handling heterogeneous client data and resource constraints. |
| Computer Vision | ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured
  Proxies (Read more on [arXiv](https://arxiv.org/abs/2506.14315) or [HuggingFace](https://huggingface.co/papers/2506.14315))| Lin Ma, Panwang Pan, Keke Wang, Bangbang Yang, yjyyy | ImmerseGen is introduced as a novel framework for generating immersive 3D worlds from text prompts by generating compact alpha-textured proxies, tailored for VR experiences. The research aims to alleviate reliance on complex assets while ensuring diversity and realism through agent-guided asset design and arrangement. The key methodology involves terrain-conditioned texturing for base world synthesis and RGBA asset texturing for midground and foreground scenery, guided by VLM-based modeling agents. Experiments demonstrate that ImmerseGen achieves superior photorealism, spatial coherence, and rendering efficiency, reaching an average FPS of 79+ on VR devices. The implication for AI practitioners is that compelling immersive experiences can be achieved without exhaustive 3D modeling, potentially simplifying VR content creation pipelines. |
