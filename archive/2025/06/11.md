

## Papers for 2025-06-11

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | Geopolitical biases in LLMs: what are the "good" and the "bad" countries
  according to contemporary language models (Read more on [arXiv](https://arxiv.org/abs/2506.06751) or [HuggingFace](https://huggingface.co/papers/2506.06751))| Dmitrii Korzh, tlenusik, apanc, IvanLazichny, msalnikov | This paper evaluates geopolitical biases in LLMs by examining their interpretation of historical events with conflicting national perspectives. The research aims to determine if LLMs demonstrate geopolitical biases by favoring specific national viewpoints when interpreting controversial historical events. The methodology involves using a manually collected dataset of opinions on historical conflicts and assessing LLM responses to neutral event descriptions paired with contrasting viewpoints. The primary results reveal significant geopolitical biases, with models favoring specific national narratives, and simple debiasing prompts having limited impact; for example, GPT-40-mini prefers the USA position in UK vs. USA events, increasing its preference from 76% to 91% when explicitly mentioning the countries. These findings imply that AI practitioners must be aware of and address national narrative biases in LLMs to ensure fair and unbiased outputs. |
| Natural Language Processing | RuleReasoner: Reinforced Rule-based Reasoning via Domain-aware Dynamic
  Sampling (Read more on [arXiv](https://arxiv.org/abs/2506.08672) or [HuggingFace](https://huggingface.co/papers/2506.08672))| Jiaqi Li, Yang Liu, zlzheng | The paper introduces RuleReasoner, a method for enhancing rule-based reasoning in small language models (SLMs) using reinforcement learning. It addresses the question of whether SRMs can effectively learn rule-based reasoning and generalize across diverse tasks. RuleReasoner employs a domain-aware dynamic sampling approach, resampling training batches based on historical rewards, improving data efficiency. Empirical evaluations show RuleReasoner outperforms frontier LRMs, achieving a △4.1% average points on eight ID tasks and △10.4% on three OOD tasks over OpenAI-01. This approach enables more efficient and generalizable rule-based reasoning in SLMs, offering practitioners a more computationally efficient alternative to large-scale model training. |
| Machine Learning | Solving Inequality Proofs with Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.07927) or [HuggingFace](https://huggingface.co/papers/2506.07927))| Alex Gu, Tony Xia, Jikai Jin, Luna Lyu, Jiayi Sheng | This paper introduces INEQMATH, a new benchmark for evaluating the ability of large language models (LLMs) to solve Olympiad-level inequality proofs. The work decomposes inequality proving into bound estimation and relation prediction, using an LLM-as-judge framework with step-wise verification.  Results show that even strong LLMs achieve less than 10% overall accuracy on INEQMATH under step-wise scrutiny, highlighting a significant gap between finding correct answers and producing sound proofs. The study also explores potential improvement strategies such as theorem-guided reasoning and self-refinement. The findings emphasize the need for more robust deductive reasoning methods in LLMs, beyond merely answer-finding capabilities. |
| Computer Vision | Self Forcing: Bridging the Train-Test Gap in Autoregressive Video
  Diffusion (Read more on [arXiv](https://arxiv.org/abs/2506.08009) or [HuggingFace](https://huggingface.co/papers/2506.08009))| Eli Shechtman, Mingyuan Zhou, Zhengqi Li, Xun Huang, gdhe17 | The paper introduces Self Forcing, a novel training paradigm for autoregressive video diffusion models to address the exposure bias problem. The main objective is to bridge the train-test distribution gap by conditioning frame generation on previously self-generated outputs with KV caching during training. Self Forcing enables holistic supervision via video-level distribution-matching losses and stochastic gradient truncation, balancing cost and performance. Experimental results demonstrate real-time video generation at 17 FPS with sub-second latency on a single GPU. This improves visual fidelity while unlocking interactive video generation applications. |
| Multi-Modal | Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error
  Diagnosis in GUI Automation (Read more on [arXiv](https://arxiv.org/abs/2506.04614) or [HuggingFace](https://huggingface.co/papers/2506.04614))| Junyang Wang, Haowei Liu, Haiyang Xu, Xi Zhang, Yuyang Wanyan | The paper introduces GUI-Critic-R1, a model designed to diagnose errors pre-execution in GUI automation tasks. The research aims to improve the accuracy and efficiency of GUI agents by providing critical feedback before actions are performed. GUI-Critic-R1 employs a Suggestion-aware Gradient Relative Policy Optimization (S-GRPO) strategy and is trained using a novel reasoning-bootstrapping based data collection pipeline, creating GUI-Critic-Train and GUI-Critic-Test datasets. Experimental results on AndroidWorld demonstrate a success rate increase from 22.4% to 27.6%. The proposed method offers a more reliable way to prevent cumulative errors and enhance operational efficiency in real-time GUI automation environments. |
| Multi-Modal | Aligning Text, Images, and 3D Structure Token-by-Token (Read more on [arXiv](https://arxiv.org/abs/2506.08002) or [HuggingFace](https://huggingface.co/papers/2506.08002))| Georgia Gkioxari, Vansh Tibrewal, Aadarsh Sahoo | This paper introduces Kyvo, an autoregressive model aligning text, images, and structured 3D scenes. The research aims to enable LLMs to perform complex visual tasks in 3D by incorporating structured 3D information. Kyvo tokenizes and aligns text, images, and 3D modalities within a unified LLM framework, training decoder-only transformers for autoregressive tasks. The model achieves a Jaccard Index of 0.9212 on CLEVR scene recognition, outperforming baseline VLMs. Kyvo provides AI practitioners with a unified approach to 3D visual understanding and generation by leveraging structured 3D representations. |
| Computer Vision | Frame Guidance: Training-Free Guidance for Frame-Level Control in Video
  Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2506.07177) or [HuggingFace](https://huggingface.co/papers/2506.07177))| Soo Ye Kim, Jaehyeong Jo, Sangwon Jang, jaehong31, tkkitkki | The paper introduces Frame Guidance, a training-free method for controllable video generation using frame-level inputs in video diffusion models. It addresses the challenge of fine-grained control by proposing a latent processing method that reduces memory usage and a latent optimization strategy for coherent video generation. Frame Guidance achieves effective control across tasks like keyframe guidance and stylization without training, being compatible with any video model. Experimental results demonstrate high-quality controlled videos, with a memory usage reduction of up to 15x using latent slicing. Frame Guidance enables a practical, model-agnostic framework for controllable video synthesis, offering increased flexibility and efficiency for practitioners. |
| Natural Language Processing | ECoRAG: Evidentiality-guided Compression for Long Context RAG (Read more on [arXiv](https://arxiv.org/abs/2506.05167) or [HuggingFace](https://huggingface.co/papers/2506.05167))| Seung-won Hwang, Dohyeon Lee, Jinsu Kim, yeonseokjeong | This paper introduces ECoRAG, an evidentiality-guided compression framework for long context Retrieval-Augmented Generation (RAG). The research aims to improve LLM performance on ODQA tasks by compressing retrieved documents based on whether answer generation is supported by the correct evidence. ECoRAG compresses documents based on evidentiality, incorporating additional information if needed, finding a compression ratio that enables the LLM to generate the correct answer with minimal tokens. Experiments on Natural Questions show that ECoRAG improves LLM performance, outperforming existing methods with 36.48% EM score. ECoRAG offers AI practitioners a cost-efficient method to reduce latency and token usage in RAG applications by retaining only necessary information. |
| Computer Vision | DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for
  Parameter-Efficient Video-Text Retrieval (Read more on [arXiv](https://arxiv.org/abs/2506.08887) or [HuggingFace](https://huggingface.co/papers/2506.08887))| Yifeng Zhang, Tao He, Tianxiang Hao, Guoqiang Gong, lunar677 | The paper introduces DiscoVLA, a parameter-efficient adaptation of CLIP for video-text retrieval. It addresses discrepancies in vision, language, and alignment when transferring from image-level to video-level VL matching. The approach involves Image-Video Features Fusion (IVFusion), Pseudo Image-level Alignment (PImgAlign) and Image-to-Video Alignment Distillation (AlignDistill). DiscoVLA achieves state-of-the-art results, reaching 50.5% R@1 on MSRVTT with CLIP (ViT-B/16), a 1.5% improvement over previous methods. This approach offers AI practitioners a strategy to improve video-text retrieval by explicitly reducing vision, language and alignment discrepancies without full fine-tuning. |
| Computer Vision | Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural
  Compressor (Read more on [arXiv](https://arxiv.org/abs/2506.07932) or [HuggingFace](https://huggingface.co/papers/2506.07932))| Nandita Vijaykumar, Mohammadreza Mofayezi, Sankeerth Durvasula, Yushi Guan, rishitdagli | Squeeze3D introduces a novel framework for extreme 3D data compression by leveraging pre-trained generative models. It aims to achieve high compression ratios for 3D data across various formats while preserving visual quality. The method uses trainable mapping networks to bridge the latent spaces between a pre-trained encoder and a pre-trained generator, creating a compact latent code.  Experiments demonstrate compression ratios of up to 2187x for meshes, 55x for point clouds, and 619x for radiance fields. This framework offers AI practitioners a flexible and efficient compression solution by reusing existing models without object-specific training. |
| Natural Language Processing | MoA: Heterogeneous Mixture of Adapters for Parameter-Efficient
  Fine-Tuning of Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.05928) or [HuggingFace](https://huggingface.co/papers/2506.05928))| Wenqiao Zhang, Rolan Yan, Hongyang He, Tianwei Lin, cajie | The paper introduces a heterogeneous Mixture-of-Adapters (MoA) approach to parameter-efficient fine-tuning (PEFT) for large language models (LLMs). It addresses the representation collapse and expert load imbalance issues in homogeneous MoE-LoRA architectures by dynamically integrating PEFT adapter experts with diverse structures. The methodology involves token-level dynamic routing to leverage complementary representational capabilities for expert specialization. Experiments demonstrate that MoA outperforms homogeneous MoE-LORA methods in both performance and parameter efficiency, achieving higher accuracy on math benchmarks (81.51%) with only 24.52M trainable parameters. The proposed MoA enables AI practitioners to achieve efficient adaptation to downstream tasks, leveraging the pre-trained knowledge with reduced computational overhead. |
| Natural Language Processing | Institutional Books 1.0: A 242B token dataset from Harvard Library's
  collections, refined for accuracy and usability (Read more on [arXiv](https://arxiv.org/abs/2506.08300) or [HuggingFace](https://huggingface.co/papers/2506.08300))| Kristi Mukk, Jack Cushman, John Hess, Catherine Brobston, Matteo Cargnelutti | The paper introduces Institutional Books 1.0, a 242B token dataset derived from Harvard Library's collections, designed to improve the quality and accessibility of training data for large language models. The project aimed to curate a high-quality, public domain dataset from digitized books, focusing on accuracy and usability. The methodology included data extraction, analysis of temporal and language coverage, topic classification using a fine-tuned BERT model achieving 97.8% accuracy on a benchmark dataset, and deduplication. The release of this dataset and associated analyses aims to provide AI practitioners with a refined historical collection, fostering sustainable data stewardship and collaboration within the AI community. |
| Machine Learning | Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction (Read more on [arXiv](https://arxiv.org/abs/2506.07976) or [HuggingFace](https://huggingface.co/papers/2506.07976))| Amrith Setlur, Yifei Zhou, Lunjun Zhang, Junhong Shen, JackBAI | This paper introduces interaction scaling as a new dimension for test-time scaling in interactive agents. The research aims to improve agent performance by increasing the number of interaction steps rather than solely relying on longer reasoning traces. The methodology involves a curriculum-based online reinforcement learning approach called TTI (Test-Time Interaction) that adaptively adjusts rollout lengths. TTI achieves state-of-the-art performance among open-source agents on WebVoyager with an average task success rate of 64.8%. Interaction scaling provides a complementary and efficient means to enable agents to explore and adapt dynamically, potentially benefiting diverse agentic problem domains. |
| Natural Language Processing | Mathesis: Towards Formal Theorem Proving from Natural Languages (Read more on [arXiv](https://arxiv.org/abs/2506.07047) or [HuggingFace](https://huggingface.co/papers/2506.07047))| Roozbeh Yousefzadeh, Pengyi Zhai, Zijin Feng, Yu Xuejun, Jianyuan1 | The paper introduces Mathesis, an end-to-end theorem proving pipeline processing informal problem statements in natural language. It addresses the need for automated theorem provers to handle real-world problems by introducing Mathesis-Autoformalizer, which uses reinforcement learning and a novel LeanScorer for enhanced formalization ability, and Mathesis-Prover. The research aims to improve the formalization and proving of theorems directly from natural language inputs. The methodology involves creating the Gaokao-Formal benchmark and utilizing reinforcement learning with hierarchical preference optimization. Mathesis achieves 64% accuracy on MiniF2F with pass@32 and a state-of-the-art 18% on Gaokao-Formal, outperforming existing models in end-to-end theorem proving, enabling more practical applications of formal reasoning systems. |
| Natural Language Processing | RKEFino1: A Regulation Knowledge-Enhanced Large Language Model (Read more on [arXiv](https://arxiv.org/abs/2506.05700) or [HuggingFace](https://huggingface.co/papers/2506.05700))| Jeff Zhao, Ruoyu Xiang, Yueru He, YanAdjeNole | RKEFino1 is a regulation knowledge-enhanced large language model designed to improve accuracy and compliance in financial applications. The research aims to enhance a pre-existing financial model, Fino1, by fine-tuning it with domain-specific knowledge from XBRL, CDM, and MOF. The methodology involves supervised fine-tuning and reinforcement learning, guided by curated reasoning paths and specific QA tasks. Experiments demonstrate RKEFino1 significantly outperforms Fino1, achieving a 70.69% accuracy on the MR-QA task compared to Fino1's 56.87%. This model provides AI practitioners with an enhanced tool for addressing compliance-critical financial tasks. |
| Natural Language Processing | QQSUM: A Novel Task and Model of Quantitative Query-Focused
  Summarization for Review-based Product Question Answering (Read more on [arXiv](https://arxiv.org/abs/2506.04020) or [HuggingFace](https://huggingface.co/papers/2506.04020))| Zhuang Li, Minh Ngoc Dinh, Xiuzhen Zhang, An Quang Tang | The paper introduces Quantitative Query-Focused Summarization (QQSUM), a novel task for generating comprehensive answers to product-related questions by summarizing diverse customer opinions with their prevalence. It addresses the limitation of existing PQA systems that generate single-perspective answers. The paper proposes QQSUM-RAG, an extended RAG framework using few-shot learning to jointly train a KP-oriented retriever and a summary generator. Experiments on a curated dataset (AMAZONKP) demonstrate that QQSUM-RAG outperforms RAG baselines, achieving up to 2.11 times improvement in textual similarity and a 67.12% improvement in quantification performance for KPs. This framework provides AI practitioners with a methodology for creating more nuanced, opinion-aware product review summarization models. |
