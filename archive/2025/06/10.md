

## Papers for 2025-06-10

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Reinforcement Learning | Reinforcement Pre-Training (Read more on [arXiv](https://arxiv.org/abs/2506.08007) or [HuggingFace](https://huggingface.co/papers/2506.08007))| Tianzhu Ye, Qingxiu Dong, frontierai, YaoTang23, unilm | The paper introduces Reinforcement Pre-Training (RPT) as a new paradigm for large language model pre-training by reframing next-token prediction as a reasoning task trained with reinforcement learning. The main research objective is to leverage vast amounts of text data for general-purpose RL rather than relying on domain-specific annotated answers. RPT incentivizes next-token reasoning by providing verifiable rewards for correct predictions. Experiments demonstrate that RPT improves next-token prediction accuracy, achieving consistently higher accuracy across difficulty levels and matching the performance of larger models (e.g., RPT-14B achieves comparable performance to R1-Distill-Qwen-32B). RPT provides a stronger pre-trained foundation for subsequent reinforcement fine-tuning, enhancing zero-shot performance on downstream tasks. |
| Multi-Modal | Lingshu: A Generalist Foundation Model for Unified Multimodal Medical
  Understanding and Reasoning (Read more on [arXiv](https://arxiv.org/abs/2506.07044) or [HuggingFace](https://huggingface.co/papers/2506.07044))| 26hzhang, gowitheflow, Jianyu, kenchan0226, xww033 | The paper introduces LINGSHU, a medical-specialized multimodal large language model (MLLM) for unified medical understanding and reasoning. It aims to address limitations of existing medical MLLMs, including limited medical knowledge coverage and susceptibility to hallucinations. The methodology involves a comprehensive data curation procedure, multi-stage training, and the application of reinforcement learning. Results show that LINGSHU consistently outperforms existing open-source multimodal models on various tasks, including multimodal QA, text-based QA, and medical report generation, achieving a state-of-the-art average score of 66.6 on medical multimodal benchmarks. The implication is that medical-specialized MLLMs like LINGSHU show potential for practical applications in real-world medical contexts. |
| Natural Language Processing | MiniCPM4: Ultra-Efficient LLMs on End Devices (Read more on [arXiv](https://arxiv.org/abs/2506.07900) or [HuggingFace](https://huggingface.co/papers/2506.07900))| Yuxuan Li, MiniCPM Team, BigDong, guojunshaoyao, xcjthu | The paper introduces MiniCPM4, an ultra-efficient large language model designed for end-side devices. The research aims to enhance LLM efficiency through innovations in model architecture, training data, algorithms, and inference systems. Key to the methodology is InfLLM v2, a trainable sparse attention mechanism, along with UltraClean and UltraChat v2 datasets. Evaluation shows MiniCPM4-8B significantly outperforms open-source models of similar size and achieves a 7-fold speed improvement over Qwen3-8B in processing 128K-length documents. The model enables practical LLM deployment on resource-constrained devices, expanding application scenarios. |
| Natural Language Processing | Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety
  Assurance (Read more on [arXiv](https://arxiv.org/abs/2506.06444) or [HuggingFace](https://huggingface.co/papers/2506.06444))| Hanghang Tong, Jingrui He, Tianxin Wei, Gaotang Li, Ruizhong Qiu | This paper introduces SAFFRON, a novel inference scaling paradigm to enhance LLM safety assurance against jailbreak attacks. It addresses the exploration-efficiency dilemma by using a multifurcation reward model (MRM) to reduce the number of reward model evaluations. The methodology includes partial supervision training for MRM, conservative exploration constraints, and Trie-based key-value caching. Experiments show SAFFRON-1 achieves a 0.409 attack success rate on Harmful HEx-PHI, outperforming baselines. This work provides AI practitioners with an inference-time scaling strategy to improve LLM safety, which can be incorporated into safety protocols. |
| Computer Vision | OneIG-Bench: Omni-dimensional Nuanced Evaluation for Image Generation (Read more on [arXiv](https://arxiv.org/abs/2506.07977) or [HuggingFace](https://huggingface.co/papers/2506.07977))| Shuhan Wu, Peng Xing, Jingjing Chang, wchengad, fangyixiao | The paper introduces OneIG-Bench, a comprehensive benchmark for evaluating text-to-image (T2I) models across multiple dimensions. It addresses the limitations of existing benchmarks by evaluating reasoning, text rendering, and stylization capabilities. OneIG-Bench facilitates fine-grained analysis of T2I models across six core categories using a diverse set of prompts primarily sourced from real-world scenarios. Experimental results quantitatively demonstrate model performance with metrics like alignment, text score, and diversity, achieving a ranking of models, though the metrics for knowledge and reasoning may need improvement. The benchmark enables researchers and practitioners to identify model strengths and bottlenecks in the image generation pipeline to guide further development. |
| Multi-Modal | SpatialLM: Training Large Language Models for Structured Indoor Modeling (Read more on [arXiv](https://arxiv.org/abs/2506.07491) or [HuggingFace](https://huggingface.co/papers/2506.07491))| Rui Tang, Chuan Fang, Junhao Zhong, bertjiazheng, ysmao | The paper presents SpatialLM, a large language model for generating structured 3D scene understanding outputs from 3D point cloud data. It investigates aligning point cloud features with LLMs for tasks such as layout estimation and 3D object detection. The key methodology involves fine-tuning open-source LLMs on a large-scale synthetic dataset of indoor scenes with 3D annotations. Results show SpatialLM achieves state-of-the-art performance in layout estimation on Structured3D (F1 score of 86.5% at IOU2D@0.25) and competitive results in 3D object detection. SpatialLM provides a feasible approach to enhance spatial understanding capabilities of LLMs for applications like augmented reality and embodied robotics. |
| Multi-Modal | Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal
  Learning (Read more on [arXiv](https://arxiv.org/abs/2506.06205) or [HuggingFace](https://huggingface.co/papers/2506.06205))| Yansheng Wang, Ziyang Liu, Jiaxin Hu, Peiyu He, sc-bd | The paper introduces Astra, a dual-model architecture for general-purpose mobile robot navigation. Astra addresses navigation challenges by integrating a multimodal LLM for global localization and a multitask network for local path planning and odometry estimation. The methodology involves a hybrid topological-semantic graph and self-supervised learning for robust feature extraction. Deployed on real robots, Astra achieves high end-to-end mission success rates, reaching 84.2% in warehouse environments. The work provides AI practitioners with a comprehensive system showcasing the effectiveness of hierarchical multimodal learning for robot navigation in diverse indoor environments. |
| Computer Vision | Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers (Read more on [arXiv](https://arxiv.org/abs/2506.07986) or [HuggingFace](https://huggingface.co/papers/2506.07986))| Wangmeng Zuo, Zhaoxi Chen, Zhengyao Lv, ChenyangSi, ldiex | The paper introduces TACA, a parameter-efficient method to improve text-image alignment in multimodal diffusion transformers. It addresses cross-modal attention suppression and timestep-insensitive weighting in MM-DiTs via temperature scaling and timestep-dependent adjustments. TACA, combined with LoRA fine-tuning, enhances text-image alignment on the T2I-CompBench benchmark. For FLUX.1-Dev, incorporating TACA results in substantial improvements, yielding relative gains of 16.4% in spatial relationship understanding and 5.9% in shape accuracy. The approach offers AI practitioners an efficient method to enhance semantic fidelity in text-to-image diffusion models with minimal computational overhead. |
| Multi-Modal | GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular
  Structure Recognition (Read more on [arXiv](https://arxiv.org/abs/2506.07553) or [HuggingFace](https://huggingface.co/papers/2506.07553))| Xingjian Wei, Yifan He, Jiang Wu, Hoter, jcwang0602 | The paper introduces GTR-Mol-VLM for Optical Chemical Structure Recognition (OCSR), leveraging graph traversal as visual chain of thought to improve molecular structure parsing. It addresses challenges with complex structures and inconsistent annotations using a data-centric approach, Faithfully Recognize What You've Seen. The key method involves incremental atom-bond predictions emulating human reasoning, supported by a large-scale instruction-tuning dataset (GTR-COT-1.3M) and a new benchmark (MolRec-Bench). GTR-Mol-VLM achieves superior results, outperforming baselines by 14 percentage points in scenarios with functional group abbreviations, as evaluated by SMILES and graph-based metrics. This framework advances cheminformatics and AI for Science by providing a more effective way to digitize chemical knowledge from images. |
| Natural Language Processing | Through the Valley: Path to Effective Long CoT Training for Small
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.07712) or [HuggingFace](https://huggingface.co/papers/2506.07712))| Wei Lu, Jiaxi Li, Albus-Chen, RogerLos | This paper investigates the impact of long chain-of-thought (CoT) training on small language models (SLMs) and identifies a "Long CoT Degradation" phenomenon. The study aims to understand how the scale of long CoT data affects the performance of SLMs in reasoning tasks. Through supervised fine-tuning experiments on Qwen2.5, LLaMA3, and Gemma3 families, the authors observed that SLMs trained on limited long CoT data can lose up to 75% of their original performance. The research suggests that error accumulation due to longer responses poses a significant challenge for SLMs, and proper scaling is needed to mitigate degradation. Results also reveal RL can boost performance on fine-tuned SLMs. |
| Multi-Modal | BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation (Read more on [arXiv](https://arxiv.org/abs/2506.07530) or [HuggingFace](https://huggingface.co/papers/2506.07530))| Xilin Chen, Ruiping Wang, Chuyan Xiong, Hongyu Wang | This paper introduces BitVLA, a 1-bit Vision-Language-Action model for robotics manipulation designed for resource-constrained systems. The research focuses on quantizing VLA models to ternary values ({-1, 0, 1}) and employing distillation-aware training to compress the vision encoder to 1.58-bit weights. BitVLA achieves comparable performance to OpenVLA-OFT with 4-bit quantization on the LIBERO benchmark while using only 29.8% of the memory. This demonstrates the potential of BitVLA for deployment on memory-limited edge devices by offering a cost-effective and high-performance solution for robotic manipulation. |
| Machine Learning | Pre-trained Large Language Models Learn Hidden Markov Models In-context (Read more on [arXiv](https://arxiv.org/abs/2506.07298) or [HuggingFace](https://huggingface.co/papers/2506.07298))| Jennifer J. Sun, Yahya Satter, Zhaolin Gao, sarahdean, DaiYijia | The paper explores the ability of pre-trained large language models (LLMs) to learn and predict Hidden Markov Model (HMM)-generated sequences in-context. The primary research question is whether LLMs can effectively model data generated by HMMs via in-context learning. The methodology involves training LLMs on synthetic HMM data and evaluating their predictive accuracy across various HMM configurations. Empirically, LLMs achieved predictive accuracy approaching the theoretical optimum. The main implication is that LLMs can potentially uncover hidden structure in complex scientific data, offering a new tool for sequential data analysis. |
| Natural Language Processing | The Illusion of Thinking: Understanding the Strengths and Limitations of
  Reasoning Models via the Lens of Problem Complexity (Read more on [arXiv](https://arxiv.org/abs/2506.06941) or [HuggingFace](https://huggingface.co/papers/2506.06941))| Samy Bengio, Maxwell Horton, Keivan Alizadeh, Iman Mirzadeh, parshinsh | The paper examines the reasoning capabilities of Large Reasoning Models (LRMs) through the lens of problem complexity. It investigates whether LRMs develop generalizable problem-solving skills or rely on pattern matching by manipulating the compositional complexity of puzzles. The study compared LRMs and standard LLMs, revealing that performance collapses to zero beyond a certain complexity threshold, with reasoning effort declining despite sufficient token budgets. LRMs demonstrate limitations in exact computation and inconsistent reasoning across puzzle types, suggesting limited self-correction capabilities; these findings raise questions about the true reasoning capabilities of current LRMs. |
| Natural Language Processing | CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.07463) or [HuggingFace](https://huggingface.co/papers/2506.07463))| Yang Yu, Jijie Li, Yonghua, ldwang, ZacLiu | The paper introduces CCI4.0, a large-scale bilingual (Chinese and English) pretraining dataset designed to enhance reasoning in large language models. It aims to address the limited availability of high-quality and diverse corpora for pretraining, particularly for reasoning skills. The methodology involves a novel pipeline encompassing deduplication, multi-classifier quality scoring, fluency filtering, and the synthesis of 4.5 billion chain-of-thought reasoning templates. Empirical evaluations demonstrate that LLMs pretrained on CCI4.0 achieve consistent improvements in downstream tasks, especially in math and code reflection tasks; for instance, models achieved improved performance on CommonsenseQA. The study highlights the crucial role of rigorous data curation and human thinking templates in improving LLM performance. |
| Natural Language Processing | Well Begun is Half Done: Low-resource Preference Alignment by
  Weak-to-Strong Decoding (Read more on [arXiv](https://arxiv.org/abs/2506.07434) or [HuggingFace](https://huggingface.co/papers/2506.07434))| Tianyu Liu, Yuxuan Fan, Wen Luo, SylvainWei, songff | This paper introduces Weak-to-Strong Decoding (WSD) for low-resource preference alignment in large language models (LLMs). The primary objective is to enhance LLM alignment by leveraging a small, aligned model to guide the decoding process of a larger base model. WSD begins with the small model drafting a well-aligned initial response, followed by the base model continuing the generation under a dynamically adjusted auto-switch mechanism. Experiments show that WSD effectively enhances different base models, outperforming baselines on metrics such as the HH-RLHF score of 98.19% while maintaining downstream task performance. WSD provides AI practitioners with an effective strategy to improve LLM alignment without incurring high computational costs or alignment tax. |
| Multi-Modal | GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection
  Behavior (Read more on [arXiv](https://arxiv.org/abs/2506.08012) or [HuggingFace](https://huggingface.co/papers/2506.08012))| Lewei Lu, Jiaheng Yu, Bo Wang, Shengnan Ma, Penghao Wu | The paper introduces GUI-Reflection, a framework enabling multimodal GUI models to learn self-reflection and error correction. The research aims to enhance GUI automation by integrating self-reflection capabilities through GUI-specific pre-training, offline supervised fine-tuning (SFT), and online reflection tuning. The key methodology involves scalable data pipelines for constructing reflection and error correction scenarios automatically. Experimental results show that the GUI-Reflection model achieves a 34.72% success rate on level-2 tasks after online reflection tuning, demonstrating enhanced adaptability and robustness. This framework equips GUI agents with improved self-correction, paving the way for more reliable and intelligent GUI automation. |
| Natural Language Processing | ConfQA: Answer Only If You Are Confident (Read more on [arXiv](https://arxiv.org/abs/2506.07309) or [HuggingFace](https://huggingface.co/papers/2506.07309))| Alicia Sun, Vera Yan, Kai Sun, Yifan Ethan Xu, MaggieHuang | This paper introduces ConfQA, a fine-tuning strategy to reduce hallucination in large language models (LLMs). The research aims to improve LLM factuality by calibrating confidence and selectively answering questions. ConfQA trains LLMs to admit "I am unsure" when uncertain, utilizing a dampening prompt and factual statements from knowledge graphs.  Experiments show ConfQA reduces hallucination rates to below 5% across multiple benchmarks while increasing accuracy gains to beyond 95% with a dual knowledge framework. The main implication is that LLMs can be effectively trained to refrain from generating confident but inaccurate information, enabling more reliable knowledge integration. |
| Computer Vision | Vision Transformers Don't Need Trained Registers (Read more on [arXiv](https://arxiv.org/abs/2506.08010) or [HuggingFace](https://huggingface.co/papers/2506.08010))| Yossi Gandelsman, Alexei Efros, Amil Dravid, Nick Jiang | This paper investigates the emergence of high-norm tokens in Vision Transformers (ViTs) that lead to noisy attention maps. The research aims to mitigate these artifacts without retraining models from scratch. Their methodology involves identifying specific register neurons responsible for the high-norm activations and redirecting these activations to an untrained token, mimicking the effect of trained register tokens. Experiments demonstrate that this test-time register approach enhances performance across visual tasks and achieves results comparable to models explicitly trained with register tokens, improving unsupervised object discovery by 20 points. The method offers a training-free solution for improving ViTs and VLMs, benefiting AI practitioners by simplifying deployment and enhancing model interpretability. |
| Computer Vision | Dreamland: Controllable World Creation with Simulator and Generative
  Models (Read more on [arXiv](https://arxiv.org/abs/2506.08006) or [HuggingFace](https://huggingface.co/papers/2506.08006))| Honglin He, Weizhen Wang, Leon Liu, Ziyang Leng, Sicheng Mo | Dreamland is a hybrid framework for controllable world creation combining a physics-based simulator with generative models. It aims to enhance element-wise controllability in video generation for scene editing and agent training. The method introduces a layered world abstraction (LWA) to bridge the simulator and generative model, encoding both pixel-level and object-level information. Experiments on the D3Sim dataset demonstrate Dreamland outperforms existing baselines with a 50.8% improvement in image quality and a 17.9% improvement in controllability. This approach improves adaptation of embodied agents to the real world, offering potential for downstream tasks. |
| Natural Language Processing | Cartridges: Lightweight and general-purpose long context representations
  via self-study (Read more on [arXiv](https://arxiv.org/abs/2506.06266) or [HuggingFace](https://huggingface.co/papers/2506.06266))| Dylan Zinsley, Neel Guha, Simran Arora, Ryan Ehrlich, sabrieyuboglu | The paper introduces CARTRIDGES, a method for creating lightweight, general-purpose long context representations using self-study. It addresses the memory constraints of in-context learning by training a smaller KV cache offline on each corpus using a context-distillation objective.  The key methodology involves generating synthetic conversations about the corpus and training the CARTRIDGE to mimic the conversational behavior of a model with the entire corpus in context. Results show that CARTRIDGES match ICL performance while using 38.6x less memory and enabling 26.4x higher throughput. CARTRIDGES offer AI practitioners a more efficient way to handle long contexts, reducing memory costs and improving throughput without retraining. |
| Computer Vision | Bootstrapping World Models from Dynamics Models in Multimodal Foundation
  Models (Read more on [arXiv](https://arxiv.org/abs/2506.06006) or [HuggingFace](https://huggingface.co/papers/2506.06006))| Shay B. Cohen, Anna Korhonen, Yftah Ziser, ducdauge, yfqiu-nlp | This paper introduces a method for bootstrapping world models in multimodal foundation models by leveraging dynamics models. It investigates whether VLMs implicitly store realistic world models and proposes enhancing this knowledge through fine-tuning dynamics models, given the relative difficulty of acquiring world models directly. The key methodology involves 1) weakly supervised learning from synthetic data generated using the dynamics model and 2) inference-time verification, also guided by the dynamics model. Evaluated on AURORA-BENCH, the proposed model achieves performance competitive with SOTA image editing models, improving GPT4o-as-judge scores by 15% on real-world subsets. The findings suggest a practical approach to incorporating dynamics and world understanding into VLMs for action-centric tasks. |
| Computer Vision | PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal
  Interaction and Enhancement (Read more on [arXiv](https://arxiv.org/abs/2506.07848) or [HuggingFace](https://huggingface.co/papers/2506.07848))| Yuan Zhou, Jiangning Zhang, Zhengguang Zhou, Zhentao Yu, Teng Hu | PolyVivid is a novel framework for multi-subject video customization that enables flexible and identity-consistent generation. It addresses the challenge of generating videos with user-specified subjects and interactions by establishing accurate correspondences between subject images and textual entities using a VLLM-based text-image fusion module and a 3D-RoPE-based enhancement module. The method also injects fused identity features into the video generation process via an attention-inherited identity injection module to mitigate identity drift. Experiments demonstrate superior performance in identity fidelity, video realism, and subject alignment, with PolyVivid achieving improved face similarity scores of 0.642 compared to existing methods. This approach provides AI practitioners with a customizable solution for high-fidelity video generation, enabling more control over subject identity and interaction. |
| Reinforcement Learning | Learning What Reinforcement Learning Can't: Interleaved Online
  Fine-Tuning for Hardest Questions (Read more on [arXiv](https://arxiv.org/abs/2506.07527) or [HuggingFace](https://huggingface.co/papers/2506.07527))| Xiaochen Ma, Lexiang Tang, Meiyi Qiang, Hao Liang, RoadQAQ | This paper introduces ReLIFT, a novel reinforcement learning approach that interleaves online fine-tuning on the hardest questions to overcome limitations of standard RL. The research aims to improve LLM reasoning and generalization capabilities by combining the strengths of RL and supervised fine-tuning. ReLIFT primarily trains with RL but collects high-quality solutions for challenging questions for online fine-tuning. The approach achieves a new state-of-the-art accuracy of 51.1% on competition-level math reasoning benchmarks using Qwen2.5-Math-7B. ReLIFT offers AI practitioners a scalable and effective method for enhancing LLM reasoning by selectively incorporating high-quality demonstration data to address specific weaknesses identified during RL. |
| Natural Language Processing | Overclocking LLM Reasoning: Monitoring and Controlling Thinking Path
  Lengths in LLMs (Read more on [arXiv](https://arxiv.org/abs/2506.07240) or [HuggingFace](https://huggingface.co/papers/2506.07240))| Lior Wolf, Itamar Zimerman, royeis | The paper introduces a method for monitoring and controlling the thinking path length in Large Language Models (LLMs) to improve reasoning. It investigates whether LLMs can monitor their progress and encode this information internally. The methodology involves learning progress vector projections to reveal LLMs' planning dynamics and manipulating internal progress encoding to reduce unnecessary steps. Empirical results on mathematical datasets using DeepSeek-R1 demonstrate that this "overclocking" improves answer accuracy and reduces inference latency. This implies that controlling LLM reasoning depth can mitigate overthinking patterns, enhancing both efficiency and effectiveness for AI practitioners. |
| Natural Language Processing | GeometryZero: Improving Geometry Solving for LLM with Group Contrastive
  Policy Optimization (Read more on [arXiv](https://arxiv.org/abs/2506.07160) or [HuggingFace](https://huggingface.co/papers/2506.07160))| Qipeng Guo, Zimian Peng, Dianyi Wang, Yibin Wang, LibraTree | This paper introduces GeometryZero, a novel reinforcement learning framework for improving geometry problem-solving in Large Language Models (LLMs). It addresses limitations of existing approaches by proposing Group Contrastive Policy Optimization (GCPO), which utilizes Group Contrastive Masking and Length Reward to guide auxiliary constructions. The methodology adaptively provides positive or negative reward signals based on contextual utility and promotes longer reasoning chains. Experimental results on Geometry3K and MathVista benchmarks demonstrate that GeometryZero consistently outperforms baselines, achieving an average improvement of 4.29% across all benchmarks. The implication for AI practitioners is a more effective and affordable method for training LLMs to solve geometry problems by judiciously employing auxiliary constructions. |
| Natural Language Processing | Robust Preference Optimization via Dynamic Target Margins (Read more on [arXiv](https://arxiv.org/abs/2506.03690) or [HuggingFace](https://huggingface.co/papers/2506.03690))| Xingyu Lu, Zhibo Zhu, Jiancan Wu, Junkang Wu, Sunshine279 | This paper introduces γ-PO, a dynamic target margin preference optimization algorithm for robust LLM alignment. It addresses the issue of noisy or ambiguous preference data by adjusting reward margins at the pairwise level, prioritizing high-confidence pairs while suppressing potential noise. γ-PO strategically calibrates instance-specific margins based on reward differences between preferred and less preferred responses. Evaluated across benchmarks like AlpacaEval2 and Arena-Hard, γ-PO achieves an average 4.4% improvement over baselines. This method offers a robust and efficient solution for enhancing LLM alignment with minimal code changes and negligible impact on training efficiency. |
| Multi-Modal | Play to Generalize: Learning to Reason Through Game Play (Read more on [arXiv](https://arxiv.org/abs/2506.08011) or [HuggingFace](https://huggingface.co/papers/2506.08011))| Junfei Xiao, Alan Yuille, Shiyi Lan, Yinsong Ma, Yunfei Xie | The paper introduces Visual Game Learning (ViGaL), a novel post-training paradigm for improving multimodal reasoning in large language models (MLLMs) via gameplay. It investigates how reinforcement learning (RL) on simple games enhances out-of-domain generalization to complex reasoning tasks without direct in-domain training data. A 7B-parameter MLLM trained with RL on games like Snake shows a 1.5% accuracy increase on multimodal math benchmarks and improved multi-discipline question answering. The results imply that synthetic, rule-based games can unlock generalizable multimodal reasoning abilities more effectively than task-specific training, offering a scalable pre-text task for AI practitioners. |
| Computer Vision | MegaHan97K: A Large-Scale Dataset for Mega-Category Chinese Character
  Recognition with over 97K Categories (Read more on [arXiv](https://arxiv.org/abs/2506.04807) or [HuggingFace](https://huggingface.co/papers/2506.04807))| Yixin Zhao, Peirong Zhang, lianwen, shiyx1, ZZXF | The paper introduces MegaHan97K, a new large-scale dataset for mega-category Chinese character recognition. The primary objective is to address the lack of comprehensive datasets for recognizing the vast number of Chinese characters, particularly those in the latest GB18030-2022 standard. The methodology involves curating a dataset of 97,455 categories with handwritten, historical, and synthetic subsets to mitigate long-tail distribution issues. Experiments show that models trained on the synthetic subset exhibit an average accuracy improvement of 22.43%. The MegaHan97K dataset offers AI practitioners a valuable resource for advancing Chinese character recognition, especially for cultural heritage preservation and digital applications. |
| Natural Language Processing | Improving large language models with concept-aware fine-tuning (Read more on [arXiv](https://arxiv.org/abs/2506.07833) or [HuggingFace](https://huggingface.co/papers/2506.07833))| Dacheng Tao, Jiaxing Huang, Xikun Zhang, michaelchenkj | This paper introduces Concept-Aware Fine-Tuning (CAFT), a novel method for improving large language models by enabling multi-token sequence learning during the fine-tuning phase. The research addresses the limitations of next-token prediction in forming coherent, high-level concepts. CAFT trains auxiliary heads to predict future tokens, augmenting the cross-entropy loss during fine-tuning, and demonstrates significant improvements across text summarization and de novo protein design. Experiments show that CAFT achieves superior performance compared to traditional next-token fine-tuning, including an 8.8% improvement in accuracy on HumanEval. CAFT democratizes multi-token prediction by bringing it to the post-training phase, enabling stronger concept-aware learning and broader applicability. |
| Computer Vision | Image Reconstruction as a Tool for Feature Analysis (Read more on [arXiv](https://arxiv.org/abs/2506.07803) or [HuggingFace](https://huggingface.co/papers/2506.07803))| Andrey Kuznetsov, Elizaveta Goncharova, Dmitrii Tarasov, combat-helicopter | The paper introduces a novel reconstruction-based method for interpreting vision encoder features. It aims to evaluate the information preserved within a model's internal layers by reconstructing images from hidden representations. The methodology involves training a reconstructor network to invert image features and manipulating the feature space via orthogonal transformations to observe changes in reconstructed images. Results show SigLIP2 produces higher-fidelity reconstructions than SigLIP, demonstrating that training objectives influence feature informativeness. This approach enables AI practitioners to assess and compare vision encoders by quantifying visual fidelity post-reconstruction. |
| Natural Language Processing | Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models (Read more on [arXiv](https://arxiv.org/abs/2506.07645) or [HuggingFace](https://huggingface.co/papers/2506.07645))| Karolina Seweryn, llmAttack, mchraba | This paper evaluates the robustness of large language models (LLMs) in low-resource languages like Polish against adversarial character-level and word-level perturbations. It introduces a framework leveraging proxy models and word attribution methods to generate perturbed datasets, enabling efficient robustness assessment. The key methodology involves training small proxy models to identify important words, perturbing these words, and then evaluating the impact on LLM prediction accuracy. Results show a significant Attack Success Rate (ASR) for character-level attacks, indicating a vulnerability in LLMs when faced with simple typographic errors. This implies a need for increased attention to robustness evaluations and mitigation strategies for LLMs in low-resource languages, particularly concerning simple perturbations that might bypass safety mechanisms. |
| Multi-Modal | Proactive Assistant Dialogue Generation from Streaming Egocentric Videos (Read more on [arXiv](https://arxiv.org/abs/2506.05904) or [HuggingFace](https://huggingface.co/papers/2506.05904))| Anuj Kumar, Andrea Madotto, Zhaojiang Lin, Xin Luna Dong, 594zyc | This paper addresses the challenge of generating proactive dialogue for task guidance from streaming egocentric videos. It introduces PROASSIST, a large-scale synthetic dialogue dataset created through an automated pipeline leveraging LLMs to simulate realistic assistant-user interactions based on video annotations. The authors also propose an end-to-end multimodal model that incorporates negative frame sub-sampling and iterative progress summarization techniques. Evaluations show that the model, when conditioned on task-specific knowledge, improves guidance quality, achieving promising results on the new dataset. The work provides a foundation for developing real-time AI assistants capable of guiding users through diverse tasks. |
| Natural Language Processing | EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and
  Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions (Read more on [arXiv](https://arxiv.org/abs/2505.23473) or [HuggingFace](https://huggingface.co/papers/2505.23473))| Chong Teng, Fei Li, Xin Zhang, Xiaofeng Mao, Xiaorui Wu | The paper introduces EVOREFUSE, an evolutionary algorithm to generate pseudo-malicious instructions that induce over-refusal in LLMs. The research aims to create diverse and challenging benchmarks for evaluating and mitigating LLM over-refusal. EVOREFUSE uses an evolutionary approach maximizing a variational Evidence Lower Bound (ELBO) to balance diversity and refusal-inducing capabilities. Experiments show that EVOREFUSE-TEST outperforms existing benchmarks with a 140.41% higher average refusal triggering rate across 9 LLMs. This implies that models are often overly sensitive to certain keywords rather than understanding context, informing safer and more helpful LLM development. |
