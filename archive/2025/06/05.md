

## Papers for 2025-06-05

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Machine Learning | CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark (Read more on [arXiv](https://arxiv.org/abs/2505.16968) or [HuggingFace](https://huggingface.co/papers/2505.16968))| Salman Khan, Seung Hun Eddie Han, GustavoStahl, Sarim-Hash, ahmedheakl | The paper introduces CASS, a dataset and model suite for cross-architecture GPU code transpilation, enabling CUDA to HIP and SASS to RDNA3 translation. The primary objective is to address the lack of low-level GPU code portability between Nvidia and AMD architectures. The methodology involves creating a large-scale corpus of 70k verified code pairs and fine-tuning domain-specific language models. The CASS model achieves 95% accuracy in source translation and 37.5% in assembly translation, outperforming GPT-40 and other baselines. This provides a foundation for improved GPU compiler tooling, hardware interoperability, and automated hardware translation. |
| Natural Language Processing | SuperWriter: Reflection-Driven Long-Form Generation with Large Language
  Models (Read more on [arXiv](https://arxiv.org/abs/2506.04180) or [HuggingFace](https://huggingface.co/papers/2506.04180))| Roy Ka-Wei Lee, Juanzi Li, Yushi Bai, Yuhao Wu, Zhiqiang007 | This paper introduces SuperWriter, an agent-based framework to enhance the quality and consistency of long-form text generation by large language models. The research addresses the challenge of maintaining coherence and consistency in longer sequences by incorporating explicit structured thinking through planning and refinement stages. The key methodology involves training a 7B SuperWriter-LM with supervised fine-tuning on a novel dataset and hierarchical Direct Preference Optimization (DPO) using Monte Carlo Tree Search (MCTS). Empirical results show that SuperWriter-LM achieves state-of-the-art performance, surpassing even larger-scale baseline models in both automatic and human evaluation; for instance, it demonstrates a substantial performance lead on the WritingBench benchmark. The main implication is that incorporating structured thinking steps and hierarchical DPO can significantly improve the quality of long-form text generation. |
| Machine Learning | Ψ-Sampler: Initial Particle Sampling for SMC-Based Inference-Time
  Reward Alignment in Score Models (Read more on [arXiv](https://arxiv.org/abs/2506.01320) or [HuggingFace](https://huggingface.co/papers/2506.01320))| Minhyuk Sung, Kyeongmin Yeo, Yunhong Min, Taehoon Yoon | The paper introduces Ψ-SAMPLER, a novel framework for inference-time reward alignment in score-based generative models. It aims to improve sampling efficiency by addressing the inadequate capture of reward-relevant regions by existing methods that initialize particles from the Gaussian prior. The key methodology involves a pCNL-based initial particle sampling, enabling efficient and scalable posterior sampling in high-dimensional latent spaces. Experiments demonstrate consistent performance improvements across reward alignment tasks, achieving, for example, an mIoU of 0.467 in layout-to-image generation, compared to 0.417 of base model. Ψ-SAMPLER provides AI practitioners with a more efficient method for reward alignment, enhancing sample quality under fixed compute budgets. |
| Computer Vision | Voyager: Long-Range and World-Consistent Video Diffusion for Explorable
  3D Scene Generation (Read more on [arXiv](https://arxiv.org/abs/2506.04225) or [HuggingFace](https://huggingface.co/papers/2506.04225))| Zhenwei Wang, Yuhao Liu, Tengfei Wang, Wangguandong Zheng, tyhuang | The paper introduces Voyager, a novel video diffusion framework for generating world-consistent, explorable 3D scenes from a single image and a user-defined camera path. The research aims to address the challenges of spatial inconsistency, visual hallucination, and post-hoc 3D reconstruction in existing 3D scene generation methods. Voyager jointly generates aligned RGB and depth video sequences guided by an expandable world caching mechanism for maintaining coherence and leverages a scalable video data engine for training data curation. Experiments demonstrate that Voyager achieves improved visual quality and geometric accuracy (PSNR of 18.751 on RealEstate 10K), enabling direct 3D reconstruction and infinite world expansion. This approach allows AI practitioners to generate long-range, consistent 3D environments without relying on complex 3D reconstruction pipelines. |
| Computer Vision | LayerFlow: A Unified Model for Layer-aware Video Generation (Read more on [arXiv](https://arxiv.org/abs/2506.04228) or [HuggingFace](https://huggingface.co/papers/2506.04228))| Yiyang Wang, Yuanpeng Tu, Hao Luo, Sihui Ji, xichenhku | The paper introduces LayerFlow, a unified framework for layer-aware video generation. It addresses the challenge of generating videos with transparent foregrounds, clean backgrounds, and blended scenes from layer-specific prompts. LayerFlow utilizes a DiT-based T2V model, organizing video layers as sub-clips and incorporating layer embeddings for awareness, and is trained with motion and content LoRAs. Experiments show LayerFlow achieves improved text alignment and generation quality compared to alternative methods, verified with user studies, and frame consistency scores up to 0.96 in generated blended scenes. The framework enables versatile applications like video decomposition and conditional layer generation, offering AI practitioners a tool for flexible video content creation. |
| Computer Vision | SVGenius: Benchmarking LLMs in SVG Understanding, Editing and Generation (Read more on [arXiv](https://arxiv.org/abs/2506.03139) or [HuggingFace](https://huggingface.co/papers/2506.03139))| Xingyu Wu, Xinyu Dong, yanyc, zjuxhl, xiaoooobai | The paper introduces SVGenius, a comprehensive benchmark for evaluating Large Language Models (LLMs) in SVG processing. It aims to address limitations in existing benchmarks such as limited real-world coverage and fragmented evaluation. The benchmark includes 2,377 queries across understanding, editing, and generation tasks, built on real-world data from 24 domains with complexity stratification. Experiments on 22 mainstream models revealed significant performance gaps between proprietary and open-source models, with proprietary models showing superior results in understanding tasks with approximately 80% accuracy. The authors suggest that reasoning-enhanced training is more effective than pure scaling for overcoming limitations in SVG processing. |
| Natural Language Processing | Unleashing the Reasoning Potential of Pre-trained LLMs by Critique
  Fine-Tuning on One Problem (Read more on [arXiv](https://arxiv.org/abs/2506.03295) or [HuggingFace](https://huggingface.co/papers/2506.03295))| Wenhu Chen, Lijun Wu, Kai Zou, Ping Nie, Yubo Wang | This paper explores a compute-efficient method to enhance the reasoning abilities of pre-trained LLMs using critique fine-tuning (CFT) on a single problem. The research aims to determine if critiques from a single problem can effectively unleash LLMs' reasoning potential, comparable to RLVR, but with lower cost. The key methodology involves generating diverse solutions to a problem, leveraging strong teacher LLMs to provide detailed critiques, and then fine-tuning smaller models. The results show an average improvement of 15% on six math benchmarks and 16% on three logic reasoning benchmarks with 5 GPU hours, which is comparable to or surpasses results from RL with 20x less compute. The findings imply that one-shot CFT is a simple, general, and compute-efficient approach for improving the reasoning capabilities of LLMs. |
| Natural Language Processing | TimeHC-RL: Temporal-aware Hierarchical Cognitive Reinforcement Learning
  for Enhancing LLMs' Social Intelligence (Read more on [arXiv](https://arxiv.org/abs/2505.24500) or [HuggingFace](https://huggingface.co/papers/2505.24500))| Wenqi Zhang, Xiang Huang, Yuchuan Wu, Xing Gao, Guiyang Hou | The paper introduces TimeHC-RL, a temporal-aware hierarchical cognitive reinforcement learning approach for enhancing Large Language Models' (LLMs) social intelligence. It aims to improve LLMs' cognitive development in social domains by considering temporal dynamics and diverse cognitive modes. The key methodology involves a hierarchical cognition framework encompassing intuitive reactions, surface-level thinking, and deliberate thinking, coupled with temporal-aware reward mechanisms. Experimental results show that TimeHC-RL improves the performance of a 7B backbone model, enabling it to achieve a performance score of 80.0% in In-Domain evaluation. The proposed TimeHC-RL empowers practitioners to improve LLMs' social intelligence with temporal awareness and hierarchical cognition frameworks. |
| Computer Vision | IllumiCraft: Unified Geometry and Illumination Diffusion for
  Controllable Video Generation (Read more on [arXiv](https://arxiv.org/abs/2506.03150) or [HuggingFace](https://huggingface.co/papers/2506.03150))| Ming-Hsuan Yang, Ronald Clark, Yi-Hsuan Tsai, Yi-Wen Chen, Yuanze Lin | IllumiCraft is a unified diffusion framework for controllable video generation via joint modeling of geometry and illumination. The research aims to improve video relighting by explicitly integrating geometric cues with illumination controls. IllumiCraft uses HDR maps, synthetically relit frames, and 3D point tracks within a DiT-based diffusion model. Evaluations demonstrate a 43% reduction in FVD compared to the strongest baseline in text-conditioned relighting. This approach enables high-fidelity video editing and provides better fidelity than existing controllable video generation methods. |
| Computer Vision | Image Editing As Programs with Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2506.04158) or [HuggingFace](https://huggingface.co/papers/2506.04158))| Xinchao Wang, Zhenxiong Tan, Songhua Liu, Yujia Hu, adamdad | The paper introduces Image Editing As Programs (IEAP), a diffusion-based framework for instruction-driven image editing that addresses the challenges of structurally inconsistent edits. The research aims to decompose complex editing instructions into sequences of atomic operations executed via a neural program interpreter. IEAP leverages a Diffusion Transformer (DiT) backbone with lightweight adapters specialized for each atomic operation, programmed by a vision-language model (VLM). Experiments demonstrate that IEAP outperforms state-of-the-art methods, achieving a GPT-4o score of 4.41 on the AnyEdit test set, demonstrating superior accuracy and semantic fidelity, especially for complex edits. The framework provides AI practitioners with a modular and interpretable approach to image editing, enabling robust handling of layout-altering and complex edits. |
| Multi-Modal | VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code
  Generation (Read more on [arXiv](https://arxiv.org/abs/2506.03930) or [HuggingFace](https://huggingface.co/papers/2506.03930))| Wenhu Chen, Xiang Yue, Kai Zou, Ping Nie, yuanshengni | The paper introduces VisCoder, a fine-tuned language model for generating executable Python code for data visualization. It addresses the challenge of creating visually accurate plots from natural language instructions and data previews. The methodology involves instruction tuning with a new dataset, VisCode-200K, which includes validated plotting code and multi-turn correction dialogues; evaluated on PandasPlotBench, VisCoder-3B achieves up to a 19.6 point execution pass rate improvement over baselines. VisCoder improves executable visualization generation reliability for AI practitioners. |
| Natural Language Processing | Rectified Sparse Attention (Read more on [arXiv](https://arxiv.org/abs/2506.04108) or [HuggingFace](https://huggingface.co/papers/2506.04108))| Jian Chen, Yuqing Xia, Li Dong, Tianzhu Ye, Yutao Sun | The paper introduces Rectified Sparse Attention (ReSA), a method for efficient long-sequence generation in large language models. ReSA aims to mitigate KV cache misalignment issues in sparse decoding to improve generation quality. It combines block-sparse attention with periodic dense rectification to bound error accumulation, refreshing the KV cache at fixed intervals using a dense forward pass. Experiments demonstrate that ReSA achieves near-lossless generation quality with up to 2.42x end-to-end speedup under INT4 decoding at 256K sequence length. ReSA provides a practical solution for scalable long-context inference by improving the trade-off between efficiency and generation accuracy, enabling practitioners to deploy longer sequence lengths more effectively. |
| Computer Vision | DenseDPO: Fine-Grained Temporal Preference Optimization for Video
  Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2506.03517) or [HuggingFace](https://huggingface.co/papers/2506.03517))| Ashkan Mirzaei, Willi Menapace, Ivan Skorokhodov, Anil Kag, Dazitu616 | The paper introduces DenseDPO, a novel approach for fine-grained temporal preference optimization in video diffusion models. It aims to improve the temporal consistency and visual quality of generated videos by addressing shortcomings in existing Direct Preference Optimization (DPO) methods. DenseDPO leverages structural similarity and segment-level preferences to train the model, effectively utilizing annotations by considering preferences over shorter segments. Experiments demonstrate that DenseDPO outperforms VanillaDPO, achieving a higher dynamic degree and improving visual quality. Specifically, DenseDPO improves text alignment, visual quality, temporal consistency and dynamic degree compared to VanillaDPO. The proposed method enables AI practitioners to train video diffusion models with more granular control over temporal dynamics and visual attributes, leading to improved video generation quality, but uncertainty exists regarding the dataset used. |
| Natural Language Processing | Beyond the Surface: Measuring Self-Preference in LLM Judgments (Read more on [arXiv](https://arxiv.org/abs/2506.02592) or [HuggingFace](https://huggingface.co/papers/2506.02592))| Yankai Lin, Enrui Hu, Xinyu Zhang, Hao Wang, JaxChen | This paper investigates and quantifies self-preference bias in Large Language Model (LLM) judgments. It introduces the DBG score to measure self-preference by comparing a judge model's scores to gold judgments, mitigating response quality's confounding effect. Experiments across various LLM versions, sizes, and reasoning abilities reveal that both pre-trained and post-trained models exhibit self-preference, with larger models showing less bias. The study finds that response text style and post-training data influence self-preference, and attention analysis suggests models attend more to their own outputs; for example, the DBG score of Llama-3.1-70B reduces from 3.3% to 1.4% after style modifications, and it highlights the need for careful consideration in LLM deployment as judges. Practitioners should use larger models and consider aligning response styles to mitigate this bias. |
| Natural Language Processing | Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis (Read more on [arXiv](https://arxiv.org/abs/2506.04142) or [HuggingFace](https://huggingface.co/papers/2506.04142))| Juanzi Li, Lei Hou, Zhuoran Jin, Shangqing Tu, Kejian Zhu | This paper addresses the challenge of untrustworthy LLM evaluations due to data contamination. It investigates how contamination leads to shortcut solutions acquired by LLMs during training. The study introduces a novel method for identifying shortcut neurons through comparative and causal analysis, which are then suppressed using a patching technique. Experiments show a significant accuracy decrease in contaminated models after patching, and a strong Spearman correlation (p > 0.95) with MixEval, demonstrating effective mitigation of contamination. The findings imply that understanding and suppressing shortcut behaviors can lead to more reliable LLM evaluations. |
| Natural Language Processing | Critique-GRPO: Advancing LLM Reasoning with Natural Language and
  Numerical Feedback (Read more on [arXiv](https://arxiv.org/abs/2506.03106) or [HuggingFace](https://huggingface.co/papers/2506.03106))| Chaochao Lu, Kaituo Feng, Hao Sun, Xiaoying Zhang, YipengZhang | This paper introduces Critique-GRPO, a novel reinforcement learning framework designed to enhance LLM reasoning by integrating both natural language critiques and numerical feedback. The research aims to address limitations in RL with solely numerical feedback, such as performance plateaus and persistent failures. The methodology involves fine-tuning LLMs using critiques to refine responses while maintaining exploration within an online RL setting. Experiments using Qwen2.5-7B-Base and Qwen3-8B-Base demonstrate an average pass@1 score improvement of approximately 4.5% and 5%, respectively, across eight reasoning tasks. The main implication is that incorporating natural language feedback into online RL significantly improves LLM reasoning capabilities compared to methods relying solely on numerical feedback or expert demonstrations. |
| Multi-Modal | TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via
  Autoregressive Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2506.03099) or [HuggingFace](https://huggingface.co/papers/2506.03099))| Weimin Wang, Chetwin Low | The paper introduces TalkingMachines, a framework for real-time audio-driven FaceTime-style video generation using autoregressive diffusion models. It aims to transform pretrained video generation models into efficient audio-driven character animators suitable for interactive applications. The key methodology involves adapting a SOTA image-to-video DiT into an audio-driven avatar generation model, enabling infinite video streaming without error accumulation via asymmetric knowledge distillation, and designing a high-throughput inference pipeline.  The distilled model achieves real-time latency by reducing diffusion steps to 2 and incorporating system-level optimizations.  This facilitates the creation of highly dynamic, immersive FaceTime experiences based on diverse character styles using audio as the primary driver. |
| Computer Vision | DiffDecompose: Layer-Wise Decomposition of Alpha-Composited Images via
  Diffusion Transformers (Read more on [arXiv](https://arxiv.org/abs/2505.21541) or [HuggingFace](https://huggingface.co/papers/2505.21541))| Xiangtai Li, Xuequan Lu, Qianyu Zhou, Hang Zhao, Zitong Wang | The paper introduces DiffDecompose, a novel task for layer-wise decomposition of alpha-composited images using diffusion transformers. The research aims to recover constituent layers from a single overlapped image under semi-transparent or transparent layer non-linear occlusion. It proposes a diffusion transformer-based framework that learns the posterior over layer decompositions conditioned on the input image, semantic prompts, and blending type, and introduces Layer Position Encoding Cloning to maintain pixel-level correspondence. Evaluation on the proposed AlphaBlend dataset demonstrates a 36.3% improvement in RMSE compared to other methods. The framework offers AI practitioners a way to disentangle complex alpha-blended images without explicit per-layer supervision. |
| Machine Learning | Adapt before Continual Learning (Read more on [arXiv](https://arxiv.org/abs/2506.03956) or [HuggingFace](https://huggingface.co/papers/2506.03956))| Yanan Sun, Chunhui Ding, Tao Feng, JacobYuan, Kurt1024 | The paper introduces Adapt before Continual Learning (ACL) to enhance plasticity in continual learning with pre-trained models. The research aims to address the stability-plasticity dilemma by adapting the PTM backbone before each new task. ACL refines the PTM by aligning embeddings with original class prototypes while distancing them from others using a contrastive loss. Experiments show ACL significantly improves performance, achieving up to 10.41% gains in Average Optimal Accuracy. This framework offers a versatile solution for PTM-based CL by boosting plasticity without sacrificing stability. |
| Computer Vision | RefEdit: A Benchmark and Method for Improving Instruction-based Image
  Editing Model on Referring Expressions (Read more on [arXiv](https://arxiv.org/abs/2506.03448) or [HuggingFace](https://huggingface.co/papers/2506.03448))| Chitta Baral, Yezhou Yang, Shivam Singh, Bimsara Pathiraja, mpatel57 | This paper introduces RefEdit, a benchmark and method to improve instruction-based image editing with referring expressions. The research focuses on addressing the challenge of precise image editing in complex scenes with multiple similar entities, a gap in existing methods. RefEdit-Bench, a new benchmark, is presented based on RefCOCO to evaluate this capability, alongside a synthetic data generation pipeline using GPT-40 and FlowChef to train a fine-tuned diffusion model.  Experiments demonstrate that RefEdit outperforms existing baselines, achieving state-of-the-art results and human preference by a wide margin.  The introduction of RefEdit provides AI practitioners with an effective model and a benchmark dataset to advance image editing capabilities in complex real-world scenarios. |
| Natural Language Processing | Quantitative LLM Judges (Read more on [arXiv](https://arxiv.org/abs/2506.02945) or [HuggingFace](https://huggingface.co/papers/2506.02945))| Pranchal Agarwal, Tushar Parmanand Budhwani, Jeevana Kruthi Karnuthala, Aishwarya Sahoo, Franck-Dernoncourt | The paper introduces quantitative LLM judges, a framework that enhances LLM-as-a-judge by decoupling qualitative reasoning and quantitative score prediction. It aims to improve the alignment of evaluation scores with human scores using regression models trained on the original judge's textual evaluation and score. The methodology involves training generalized linear models (GLMs) on human scores, using base judge's output as input. Experiments demonstrate that quantitative judges outperform base judges and can outperform fine-tuning on both quality and efficiency, achieving speedups of an order of magnitude while maintaining or improving predictive power. This suggests a practical and effective alternative to fine-tuning for improving LLM-based evaluation, reducing computational cost and dependence on extensive datasets. |
| Natural Language Processing | BenchHub: A Unified Benchmark Suite for Holistic and Customizable LLM
  Evaluation (Read more on [arXiv](https://arxiv.org/abs/2506.00482) or [HuggingFace](https://huggingface.co/papers/2506.00482))| Hitesh Patel, Guijin Son, Haneul Yoo, aliceoh, EunsuKim | The paper introduces BenchHub, a benchmark suite for holistic and customizable large language model (LLM) evaluation. It addresses the need for up-to-date and well-organized benchmarks by aggregating and classifying benchmark datasets from diverse domains. The study integrates 303K questions across 38 benchmarks, allowing users to tailor evaluations to specific domains or use cases. Through experiments, model performance varies significantly across domain-specific subsets, demonstrating the importance of domain-aware benchmarking. BenchHub facilitates better dataset reuse, transparent model comparisons, and easier identification of underrepresented areas, advancing LLM evaluation research. |
| Natural Language Processing | DLP: Dynamic Layerwise Pruning in Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.23807) or [HuggingFace](https://huggingface.co/papers/2505.23807))| Yingting Li, Yingying Zhang, Jiale Han, Bo Cheng, yulichen | This paper introduces Dynamic Layerwise Pruning (DLP), a novel method for adaptively pruning large language models (LLMs). The research aims to mitigate performance degradation at high sparsity levels by dynamically determining layer importance. DLP integrates model weights with input activation information to assign pruning rates, achieving a perplexity reduction of 7.79 on LLaMA2-7B at 70% sparsity compared to state-of-the-art. DLP's compatibility with existing compression techniques and parameter-efficient fine-tuning provides AI practitioners with an efficient strategy for deploying LLMs on resource-constrained devices and accelerating inference. |
| Computer Vision | Rex-Thinker: Grounded Object Referring via Chain-of-Thought Reasoning (Read more on [arXiv](https://arxiv.org/abs/2506.04034) or [HuggingFace](https://huggingface.co/papers/2506.04034))| Lei Zhang, Junzhi Yu, Zhaoyang Zeng, Xingyu Chen, Qing Jiang | The paper introduces Rex-Thinker, a novel approach to grounded object referring using chain-of-thought (CoT) reasoning. It addresses the challenge of creating robust object referring models that are both explainable and trustworthy, i.e., verifiable and minimize hallucinated outputs. The methodology involves prompting GPT-40 to generate a large-scale CoT-style referring dataset (HumanRef-CoT) and training Rex-Thinker in two stages: supervised fine-tuning and GRPO-based reinforcement learning. Experiments show Rex-Thinker achieves state-of-the-art performance on the HumanRef benchmark with fewer hallucinations, achieving an average 13.8 point improvement on rejection cases. This indicates a reduced hallucination rate and enhances the ability to reject expressions with no matching object, improving reliability for real-world applications. |
