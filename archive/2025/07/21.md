

## Papers for 2025-07-21

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges
  in Russian Speech Generative Models (Read more on [arXiv](https://arxiv.org/abs/2507.13563) or [HuggingFace](https://huggingface.co/papers/2507.13563))| Mikhail Gorodnichev, Maxim Maslov, Vasiliy Kudryavtsev, Nikita Vasiliev, Kirill Borodin | This paper introduces Balalaika, a new Russian speech dataset, to address phonetic and prosodic challenges in Russian speech synthesis. The study aims to improve the quality of Russian TTS models by creating a comprehensive dataset with annotations for stress and punctuation. They constructed the dataset from studio-quality recordings and employed state-of-the-art models for annotation. Results show that models trained on Balalaika outperform those trained on existing datasets, achieving a MOS of 4.593 compared to others. The creation of this high-quality dataset with meticulous annotations provides AI practitioners with a valuable resource for advancing Russian speech synthesis and related generative tasks. |
| Natural Language Processing | The Devil behind the mask: An emergent safety vulnerability of Diffusion
  LLMs (Read more on [arXiv](https://arxiv.org/abs/2507.11097) or [HuggingFace](https://huggingface.co/papers/2507.11097))| Ruixi Wu, Zhiyuan Liu, Dongrui Liu, Zichen Wen, Joshua999 | The paper identifies a fundamental safety vulnerability in diffusion-based large language models (dLLMs) due to the failure of existing alignment mechanisms against context-aware, masked-input adversarial prompts. It investigates how bidirectional modeling and parallel decoding in dLLMs can be exploited via adversarial prompts. The proposed DIJA framework constructs interleaved mask-text prompts that enable harmful completions, significantly outperforming existing jailbreak methods. For example, DIJA achieves up to 100% keyword-based ASR on Dream-Instruct and improves evaluator-based ASR on JailbreakBench by up to 78.5%. The findings highlight an urgent need to rethink safety alignment in this emerging class of language models. |
| Computer Vision | Franca: Nested Matryoshka Clustering for Scalable Visual Representation
  Learning (Read more on [arXiv](https://arxiv.org/abs/2507.14137) or [HuggingFace](https://huggingface.co/papers/2507.14137))| Spyros Gidaris, Lukas Knobel, Mohammadreza Salehi, Valentinos Pariza, Shashanka Venkataramanan | The paper introduces Franca, a novel open-source vision foundation model for scalable visual representation learning. The research aims to overcome limitations in SSL clustering methods by addressing semantic ambiguity. Franca employs a multi-head clustering projector based on nested Matryoshka representations and spatial disentanglement to refine image features. Experiments show Franca achieves strong results, outperforming DINOv2 by 4% on average across five OOD detection benchmarks. Franca provides a transparent, high-performance vision model, enabling reproducible and generalizable foundation models for the AI community. |
| Computer Vision | CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models (Read more on [arXiv](https://arxiv.org/abs/2507.13984) or [HuggingFace](https://huggingface.co/papers/2507.13984))| Khoi Nguyen, Anh Tran, Quang Nguyen, Minh Luu, nqbinh | The paper introduces CSD-VAR, a novel method for content-style decomposition in visual autoregressive models. It addresses the challenge of disentangling content and style in images for improved creative flexibility in visual synthesis. CSD-VAR leverages scale-aware optimization, SVD-based rectification, and augmented K-V memory to achieve better disentanglement. Experiments on the newly introduced CSD-100 dataset demonstrate that CSD-VAR outperforms prior approaches, achieving superior content preservation and stylization fidelity. CSD-VAR offers AI practitioners a new way to perform controllable text-to-image generation and creative exploration from a single image. |
| Multi-Modal | Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal
  Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2507.12566) or [HuggingFace](https://huggingface.co/papers/2507.12566))| Xue Yang, Wenhao Li, Wenhan Dou, Gen Luo, wzk1015 | This paper introduces Mono-InternVL-1.5, a monolithic multimodal large language model (MLLM) designed for improved efficiency and reduced costs. The research focuses on addressing challenges like unstable optimization and catastrophic forgetting in monolithic MLLMs through delta tuning with a new visual parameter space. The key methodology involves an innovative Endogenous Visual Pre-training (EViP++) strategy and a multimodal mixture-of-experts architecture optimized with a fused CUDA kernel. Results show Mono-InternVL-1.5 achieves competitive performance, reducing first-token latency by up to 69% compared to its modular counterpart, InternVL-1.5. The findings suggest a pathway to cheaper and faster monolithic MLLMs, enhancing their practical deployability for AI practitioners. |
| Natural Language Processing | RedOne: Revealing Domain-specific LLM Post-Training in Social Networking
  Services (Read more on [arXiv](https://arxiv.org/abs/2507.10605) or [HuggingFace](https://huggingface.co/papers/2507.10605))| Ziyan Liu, Zheyong Xie, Yue Wang, Chonggang Lu, Hiiamein | The paper introduces RedOne, a domain-specific large language model for social networking services (SNS). It aims to address performance bottlenecks in single-task baselines and establish a comprehensive foundation for various SNS tasks. RedOne is developed through a three-stage training strategy: continued pretraining, supervised fine-tuning, and preference optimization using a large-scale real-world dataset. Experiments show RedOne achieves an average improvement of 14.02% across 8 major SNS tasks compared to base models. This domain-specific LLM demonstrates improved generalization across various tasks, offering better applicability in real-world scenarios for AI practitioners in SNS content management and interaction. |
| Computer Vision | Mitigating Object Hallucinations via Sentence-Level Early Intervention (Read more on [arXiv](https://arxiv.org/abs/2507.12455) or [HuggingFace](https://huggingface.co/papers/2507.12455))| Zhuotao Tian, Li Jiang, Senqiao Yang, Shangpin Peng | The paper addresses object hallucination in Multimodal Large Language Models (MLLMs) by proposing a sentence-level early intervention strategy. The research aims to mitigate fabricated content contradicting visual inputs by intervening at the early stages of text generation. The key methodology involves bootstrapping high-quality in-domain preference pairs and training models using a context-aware preference loss. Experimental results demonstrate a 90% reduction in hallucinations compared to the original model. This method provides a robust and efficient solution for reducing hallucination in MLLMs without relying on extensive external resources. |
| Natural Language Processing | The Generative Energy Arena (GEA): Incorporating Energy Awareness in
  Large Language Model (LLM) Human Evaluations (Read more on [arXiv](https://arxiv.org/abs/2507.13302) or [HuggingFace](https://huggingface.co/papers/2507.13302))| Pedro Reviriego, Javier Conde, Eneko Sendin, Gonzalo Mart√≠nez, Carlos Arriaga | This paper presents the Generative Energy Arena (GEA) for evaluating the impact of energy awareness on human evaluations of large language models (LLMs). The primary objective is to understand how providing users with information on relative energy consumption influences their model preferences. GEA users evaluate model responses and then indicate whether they would change their choice given energy consumption differences. Results show that users change their votes 41% to 52% of the time when informed of energy consumption, favoring smaller, more energy-efficient models. This suggests that incorporating energy awareness is an important factor in LLM evaluation methodologies, and simpler models are often preferred by users if energy use is low. |
| Reinforcement Learning | Inverse Reinforcement Learning Meets Large Language Model Post-Training:
  Basics, Advances, and Opportunities (Read more on [arXiv](https://arxiv.org/abs/2507.13158) or [HuggingFace](https://huggingface.co/papers/2507.13158))| Mihaela van der Schaar, Hao Sun | This paper reviews recent advances in aligning Large Language Models (LLMs) through Inverse Reinforcement Learning (IRL). It focuses on distinctions between traditional RL and RL used in LLM alignment, emphasizing the construction of neural reward models from human data.  The paper explores challenges and opportunities in conducting IRL for LLM alignment, including the need for efficient reward modeling. It synthesizes findings from diverse studies to provide a structured overview of the field. The main implication for AI practitioners is a structured and critical overview of the field for improving LLM alignment through RL and IRL techniques, potentially leading to more reliable and controllable LLMs. |
| Machine Learning | Quantitative Risk Management in Volatile Markets with an Expectile-Based
  Framework for the FTSE Index (Read more on [arXiv](https://arxiv.org/abs/2507.13391) or [HuggingFace](https://huggingface.co/papers/2507.13391))| 0xnu | This paper introduces an expectile-based framework for quantitative risk management in volatile markets, specifically the FTSE 100 index. The research aims to overcome limitations in traditional Value-at-Risk (VaR) measures by enhancing sensitivity to tail losses. It employs novel expectile regression models and time series analysis on two decades of FTSE 100 returns. Empirical results demonstrate that expectile-based VaR (EVaR) consistently outperforms traditional VaR measures, achieving a 5.0% violation rate at the 95% confidence level. The framework offers AI practitioners enhanced tools for risk assessment and potential improvements in capital efficiency within volatile market environments. |
