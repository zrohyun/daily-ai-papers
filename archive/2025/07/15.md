

## Papers for 2025-07-15

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Computer Vision | SpeakerVid-5M: A Large-Scale High-Quality Dataset for Audio-Visual
  Dyadic Interactive Human Generation (Read more on [arXiv](https://arxiv.org/abs/2507.09862) or [HuggingFace](https://huggingface.co/papers/2507.09862))| Deyu Zhou, Jiahe Zhang, Duomin Wang, Zhaoyang Li, Youliang Zhang | The paper introduces SpeakerVid-5M, a large-scale, high-quality dataset for audio-visual dyadic interactive human generation. It addresses the need for specialized training data in interactive virtual human research. The dataset comprises 8.7K hours of single-speaker and 1.8K hours of dyadic interaction video clips, enriched with multi-modal annotations like skeletal sequences and ASR transcriptions, with 93% of videos in 1080P or higher. An autoregressive baseline model achieves promising results, as measured by FID on the VidChatBench benchmark, enhancing realism. The dataset's structure and comprehensive annotations facilitate research in audio-visual human interaction and related tasks, promoting advancements in AI applications. |
| Computer Vision | EmbRACE-3K: Embodied Reasoning and Action in Complex Environments (Read more on [arXiv](https://arxiv.org/abs/2507.10548) or [HuggingFace](https://huggingface.co/papers/2507.10548))| Kui Wu, Chengjie Jiang, Yitang Li, Wei Huang, Mingxian Lin | EmbRACE-3K is introduced as a new dataset for evaluating embodied reasoning in complex environments. The paper aims to address the limitations of current VLMs in interactive settings by providing a benchmark for tasks involving navigation, object manipulation, and multi-stage goal execution. EmbRACE-3K contains over 3,000 language-guided tasks and 26,000 decision steps with multimodal context and step-wise reasoning. Zero-shot evaluations show state-of-the-art models achieve success rates below 20%, while fine-tuning Qwen2.5-VL-7B on the dataset yields substantial improvements, demonstrating its effectiveness in enabling embodied reasoning capabilities.  The dataset's detailed annotations facilitate the development of embodied agents that can effectively reason and act in dynamic, interactive environments. |
| Reinforcement Learning | Reasoning or Memorization? Unreliable Results of Reinforcement Learning
  Due to Data Contamination (Read more on [arXiv](https://arxiv.org/abs/2507.10532) or [HuggingFace](https://huggingface.co/papers/2507.10532))| Jun Zhao, Zhiheng Xi, Qiaole Dong, Zhihao Zhang, Mingqi Wu | This paper investigates the reliability of reinforcement learning (RL) results in large language models (LLMs) due to potential data contamination. It examines the Qwen 2.5 model family's performance on mathematical reasoning tasks and identifies vulnerability to data contamination in benchmarks like MATH-500. The methodology involves a leakage audit and the introduction of a clean, synthetically generated dataset (RandomCalculation) for out-of-distribution RLVR evaluation. Results show that Qwen 2.5 achieves high regeneration and answer accuracy rates (54.60% and 53.6%, respectively) due to memorization, and only accurate reward signals yield consistent performance improvements on the leakage-free dataset. The findings suggest that AI practitioners should prioritize evaluations on uncontaminated benchmarks and across various model series to ensure the robustness of RL methods. |
| Natural Language Processing | REST: Stress Testing Large Reasoning Models by Asking Multiple Problems
  at Once (Read more on [arXiv](https://arxiv.org/abs/2507.10541) or [HuggingFace](https://huggingface.co/papers/2507.10541))| Zinan Tang, Qiyao Sun, Yu Li, Qizhi Pei, Zhuoshi Pan | The paper introduces REST, a stress-testing framework for evaluating Large Reasoning Models (LRMs) by presenting multiple problems simultaneously to assess contextual priority allocation, interference resistance, and cognitive load management. REST transforms existing benchmarks by concatenating multiple questions into a single prompt, evaluating LRM performance under increased reasoning load. Evaluation of 34 LRMs on 7 benchmarks revealed significant performance degradation under stress testing, with a 29.1% accuracy drop on AIME24 for DeepSeek-R1, indicating limitations in multi-problem-solving robustness. The framework shows enhanced discriminative power and revitalizes existing benchmarks by making them challenging again for top-tier models. REST offers a cost-efficient evaluation paradigm that reflects real-world reasoning demands, reducing reliance on continuous human annotation. |
| Natural Language Processing | Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive
  Token-Level Computation (Read more on [arXiv](https://arxiv.org/abs/2507.10524) or [HuggingFace](https://huggingface.co/papers/2507.10524))| Jiyoun Ha, Sungnyun Kim, Reza Bayat, Yujin Kim, Sangmin Bae | The paper introduces Mixture-of-Recursions (MoR), a framework for efficient Transformer-based language models. MoR aims to reduce computational and memory costs by unifying parameter sharing and adaptive computation. The key methodology involves a Recursive Transformer architecture with dynamic token-level recursion depths assigned by lightweight routers, along with a recursion-wise key-value caching strategy. Results show that MoR achieves lower validation perplexity and improved few-shot accuracy compared to vanilla Transformers at equal training FLOPs and smaller model sizes. The framework enables practitioners to achieve large-model quality with reduced computational overhead, offering a pathway toward more efficient language modeling. |
| Natural Language Processing | LayerCake: Token-Aware Contrastive Decoding within Large Language Model
  Layers (Read more on [arXiv](https://arxiv.org/abs/2507.04404) or [HuggingFace](https://huggingface.co/papers/2507.04404))| Yanqiang Zheng, Jiawang Cao, Wenbo Zhu, Yongliang Wu, Jingze Zhu | The paper introduces LayerCake, a token-aware contrastive decoding method to improve the factuality of large language models (LLMs). It aims to align specific token types with influential transformer layers to mitigate factual errors. The methodology involves selectively suppressing attention to punctuation and conceptual tokens at specific depths, deriving contrastive signals to guide factual decoding. Experiments on LLaMA models demonstrate improved factuality, achieving up to a 5.45% increase on TruthfulQA (MC1) compared to greedy decoding. This suggests that practitioners can use token-aware contrastive decoding to enhance the reliability of LLMs without retraining or model modification. |
| Natural Language Processing | CompassJudger-2: Towards Generalist Judge Model via Verifiable Rewards (Read more on [arXiv](https://arxiv.org/abs/2507.09104) or [HuggingFace](https://huggingface.co/papers/2507.09104))| Kai Chen, Songyang Zhang, Alexander Lam, Maosong Cao, Taolin Zhang | The paper introduces CompassJudger-2, a generalist judge model for evaluating large language models. It aims to address the limitations of narrow specialization and limited robustness in existing judge models. The approach involves task-driven data curation, supervision with verifiable rewards, rejection sampling for critical reasoning, and a margin policy gradient loss for enhanced performance. CompassJudger-2 achieves superior results across judge and reward benchmarks, with the 7B model demonstrating competitive accuracy against significantly larger models; JudgerBenchV2 is also introduced to standardize cross-domain judgement. The work advances scalable LLM judgment and establishes new performance and evaluation standards. |
| Computer Vision | MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second (Read more on [arXiv](https://arxiv.org/abs/2507.10065) or [HuggingFace](https://huggingface.co/papers/2507.10065))| Honglei Yan, Yifan Yu, Panwang Pan, Yuchen Lin, Chenguo Lin | MoVieS is a feed-forward model for synthesizing 4D dynamic novel views from monocular videos in one second. The research focuses on unifying appearance, geometry, and motion modeling for dynamic scenes. It achieves this by representing dynamic 3D scenes using dynamic splatter pixels and a differentiable 3D Gaussian rendering framework, with explicit supervision of time-varying motion. Experiments show that MoVieS achieves competitive performance in 4D perception tasks with significant speedups, for example on the RealEstate10K dataset it achieved PSNR 26.98. This approach enables efficient and generalizable 4D reconstruction and view synthesis for a variety of zero-shot applications such as scene flow estimation and moving object segmentation. |
| Natural Language Processing | From KMMLU-Redux to KMMLU-Pro: A Professional Korean Benchmark Suite for
  LLM Evaluation (Read more on [arXiv](https://arxiv.org/abs/2507.08924) or [HuggingFace](https://huggingface.co/papers/2507.08924))| Yeonjung Hong, Soyeon Kim, Guijin Son, Sunkyoung Kim, Seokhee Hong | This paper introduces two Korean expert-level benchmarks, KMMLU-REDUX and KMMLU-PRO, for evaluating Large Language Models (LLMs) in industrial contexts. It aims to address issues of reliability, contamination, and lack of professional knowledge representation in existing benchmarks. KMMLU-REDUX is a refined version of KMMLU, while KMMLU-PRO is based on Korean National Professional Licensure exams. Experiments demonstrate that LLMs with reasoning capabilities perform better, with the 01 model achieving the highest average accuracy of 79.55%; Claude 3.7 with Thinking succeeds in 12 out of 14 KNPL licensure exams. The benchmarks enable a more practical assessment of LLMs' capabilities in Korea-specific professional fields. |
| Machine Learning | A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy
  with SFT and Efficiency with Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2507.08267) or [HuggingFace](https://huggingface.co/papers/2507.08267))| Yuichi Inoue, Taiki Yamaguchi, Hiroshi Yoshihara | This paper introduces a practical two-stage training recipe for mathematical LLMs to maximize both accuracy and efficiency. The research aims to strategically integrate Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO). The methodology involves an extended SFT phase to push accuracy, followed by GRPO to enhance token efficiency. Experiments show that extending SFT to 10 epochs is crucial, and GRPO primarily optimizes solution length, achieving high rank among over 2,200 teams in the AIMO competition. The findings provide a blueprint for developing high-performing and efficient mathematical reasoners, which the authors intend to open-source. |
| Computer Vision | DreamPoster: A Unified Framework for Image-Conditioned Generative Poster
  Design (Read more on [arXiv](https://arxiv.org/abs/2507.04218) or [HuggingFace](https://huggingface.co/papers/2507.04218))| Dexiang Hong, Hui Zhang, Zhongqi Qi, Haokun Chen, Xiwei Hu | The paper introduces DreamPoster, a unified text-to-image framework for generating high-quality posters conditioned on user-provided images and text. It addresses the challenge of integrating visual and textual information into cohesive poster designs. The framework utilizes a transformer-based diffusion model, trained with a progressive strategy and a curated poster dataset, to hierarchically acquire multi-task generation capabilities. Evaluations show that DreamPoster achieves a high usability rate of 88.55%, outperforming existing methods like GPT-40. DreamPoster enables AI practitioners to generate professional-grade posters from minimal inputs, facilitating creative applications. |
| Other | Favicon Trojans: Executable Steganography Via Ico Alpha Channel
  Exploitation (Read more on [arXiv](https://arxiv.org/abs/2507.09074) or [HuggingFace](https://huggingface.co/papers/2507.09074))| Forrest McKee, David Noever | The paper introduces a novel steganographic technique to embed executable JavaScript payloads within ICO image files, specifically leveraging the alpha transparency channel. It investigates how these payloads can be delivered and executed in web browsers via favicon exploitation. The methodology involves compressing JavaScript code, hiding it within the least significant bit (LSB) of non-transparent alpha layer image values, and extracting/executing it using native JavaScript APIs. A proof-of-concept implementation showed that a 64x64 ICO image can embed up to 0.8 kilobytes of compressed data. This research implies that static image resources can serve as vectors for malicious code injection, necessitating more comprehensive security measures. |
