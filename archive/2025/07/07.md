

## Papers for 2025-07-07

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | Eka-Eval : A Comprehensive Evaluation Framework for Large Language
  Models in Indian Languages (Read more on [arXiv](https://arxiv.org/abs/2507.01853) or [HuggingFace](https://huggingface.co/papers/2507.01853))| Mayank Singh, Abhishek Upperwal, Samridhi Raj Sinha, RajveeSheth | Eka-Eval is a comprehensive evaluation framework for large language models (LLMs) in Indian languages. It addresses the need for evaluation benchmarks beyond English-centric tasks by integrating over 35 benchmarks, including 10 Indic-specific datasets. The framework supports reasoning, mathematics, tool use, long-context understanding, and reading comprehension. Compared to existing Indian language evaluation tools, Eka-Eval offers broader benchmark coverage and built-in support for distributed inference and quantization. It positions itself as an end-to-end evaluation suite tailored for both global and Indic LLMs, significantly lowering the barrier to multilingual benchmarking. |
| Computer Vision | How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation
  Models on Standard Computer Vision Tasks (Read more on [arXiv](https://arxiv.org/abs/2507.01955) or [HuggingFace](https://huggingface.co/papers/2507.01955))| OÄŸuzhan Fatih Kar, Andrei Atanov, Roman Bachmann, Ali Garjani, Rahul Ramachandran | This paper benchmarks the performance of multimodal foundation models (MFMs) on standard computer vision tasks to assess their visual understanding capabilities. It evaluates models like GPT-4o on tasks including image classification, object detection, and semantic segmentation using prompt chaining to translate tasks into text-promptable formats. The results show that MFMs achieve respectable generalization but still lag behind task-specific specialist models, particularly in geometric tasks; GPT-4o performs best among non-reasoning models, securing top position in 4 out of 6 tasks. The study implies that while MFMs exhibit promising vision capabilities, further development is needed to match the performance of specialized vision models. |
