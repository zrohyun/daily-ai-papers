

## Papers for 2025-07-22

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | MiroMind-M1: An Open-Source Advancement in Mathematical Reasoning via
  Context-Aware Multi-Stage Policy Optimization (Read more on [arXiv](https://arxiv.org/abs/2507.14683) or [HuggingFace](https://huggingface.co/papers/2507.14683))| Yao Xiao, LidongBing, ZonglinY, binwang, veggiebird | The paper introduces MiroMind-M1, an open-source reasoning language model (RLM) for mathematical problem-solving. The primary objective is to improve transparency and reproducibility in RLM development. They employ a context-aware multi-stage policy optimization (CAMPO) method during reinforcement learning with verifiable rewards (RLVR). MiroMind-M1 achieves state-of-the-art or competitive performance among Qwen-2.5-based models on benchmarks like AIME24, AIME25, and MATH, demonstrating strong token efficiency and reaching 60.4 on AIME24. This work offers AI practitioners a fully open-source RLM and detailed training configurations, facilitating further research and community advancement. |
| Reinforcement Learning | GUI-G^2: Gaussian Reward Modeling for GUI Grounding (Read more on [arXiv](https://arxiv.org/abs/2507.15846) or [HuggingFace](https://huggingface.co/papers/2507.15846))| Xuyang Liu, Zhangxuan Gu, Fei Tang, tricktreat, LZXzju | The paper introduces GUI-G^2, a novel Gaussian reward modeling framework for improving GUI grounding in reinforcement learning. It addresses the limitations of sparse binary rewards by modeling GUI elements as continuous Gaussian distributions, incorporating Gaussian point and coverage rewards with adaptive variance. Experiments on ScreenSpot benchmarks demonstrate a substantial performance improvement, with a 24.7% increase on ScreenSpot-Pro. This continuous reward approach provides richer gradient signals, leading to more robust and generalizable GUI interaction models. GUI-G^2 offers a new paradigm for spatial reasoning, potentially enhancing autonomous GUI agents by providing a more nuanced reward system. |
| Reinforcement Learning | The Invisible Leash: Why RLVR May Not Escape Its Origin (Read more on [arXiv](https://arxiv.org/abs/2507.14843) or [HuggingFace](https://huggingface.co/papers/2507.14843))| Yejin Choi, Zaid Harchaoui, Ximing Lu, Fang Wu, weihao1115 | This paper investigates the limitations of Reinforcement Learning with Verifiable Rewards (RLVR) in expanding the reasoning capabilities of large language models. It questions whether RLVR primarily reinforces existing knowledge or truly enables novel reasoning, theoretically framing RLVR as a conservative reweighting mechanism constrained by the base model's support. Empirically, while RLVR improves pass@1 accuracy, it often shrinks empirical support, failing to recover previously accessible correct answers; for instance, there's a significant dominance of support preservation with limited expansion across multiple tasks. The study suggests that current RLVR approaches might enhance precision but limit exploration and diversity. The main implication is that algorithmic innovations, such as explicit exploration, are needed to overcome RLVR's inherent limitations and enable genuine reasoning expansion. |
| Natural Language Processing | WebShaper: Agentically Data Synthesizing via Information-Seeking
  Formalization (Read more on [arXiv](https://arxiv.org/abs/2507.15061) or [HuggingFace](https://huggingface.co/papers/2507.15061))| Baixuan Li, Junkai Zhang, Wenbiao Yin, Jialong Wu, Zhengwei Tao | The paper introduces WebShaper, a formalization-driven framework for synthesizing high-quality training data for information-seeking agents. It addresses the scarcity of such data by systematically formalizing information-seeking tasks using set-theoretic Knowledge Projections to control reasoning structure. A multi-step expansion process, guided by an agentic Expander, creates diverse and complex task instances. Experiments demonstrate that models trained with WebShaper achieve state-of-the-art performance on GAIA and WebWalkerQA benchmarks. The framework enables systematic generation of IS instances and precise question-answer pairs which deeply stimulates the ability of DR Agents. |
| Computer Vision | Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with
  Regularized Score Distillation Sampling (Read more on [arXiv](https://arxiv.org/abs/2507.11061) or [HuggingFace](https://huggingface.co/papers/2507.11061))| Se Young Chun, jeeit17, yeonE | The paper introduces RoMaP, a novel framework for robust part-level editing in 3D Gaussian Splatting. It addresses the challenge of precise local 3D edits by employing a 3D-geometry aware label prediction module for consistent segmentation and a regularized score distillation sampling loss for targeted modifications. The method achieves state-of-the-art local 3D editing, demonstrated qualitatively and quantitatively on both reconstructed and generated Gaussian scenes/objects; specifically, CLIP similarity reaches 0.277, showing improvements in text-image alignment.  RoMaP enables AI practitioners to achieve more robust and flexible part-level editing in 3D Gaussian splatting. |
| Computer Vision | SeC: Advancing Complex Video Object Segmentation via Progressive Concept
  Construction (Read more on [arXiv](https://arxiv.org/abs/2507.15852) or [HuggingFace](https://huggingface.co/papers/2507.15852))| Jianfan Lin, Songxin He, Xiaoyi Dong, Shuangrui Ding, rookiexiong | The paper introduces Segment Concept (SeC), a novel video object segmentation framework that leverages high-level concept construction for improved performance in complex scenarios. It addresses the limitation of current VOS techniques in handling drastic visual variations by incorporating conceptual understanding. SeC uses LVLMs to construct robust conceptual priors by integrating visual cues and adaptively balances semantic reasoning with enhanced feature matching. Evaluations on the proposed Semantic Complex Scenarios Video Object Segmentation benchmark (SeCVOS) demonstrate that SeC achieves an 11.8-point improvement over SAM 2.1. This work offers a new approach to concept-aware video object segmentation, providing AI practitioners with an effective method for handling complex scenarios. |
| Reinforcement Learning | GR-3 Technical Report (Read more on [arXiv](https://arxiv.org/abs/2507.15493) or [HuggingFace](https://huggingface.co/papers/2507.15493))| Yingdong Hu, Zhongren Cui, Chilam Cheang, melony, CH3COOK | The paper introduces GR-3, a large-scale vision-language-action model for generalist robot policies. It aims to develop a robot policy capable of generalizing to novel objects, environments, and instructions with efficient fine-tuning. GR-3 employs a multi-faceted training recipe including co-training with web-scale vision-language data, VR device-collected human trajectory data, and robot trajectory data. The model achieves state-of-the-art performance, surpassing a baseline by improving the success rate in unseen instruction following from 40% to 77.1%. GR-3 offers a promising step towards building generalist robots capable of assisting humans in daily life. |
| Reinforcement Learning | Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for
  RLVR (Read more on [arXiv](https://arxiv.org/abs/2507.15778) or [HuggingFace](https://huggingface.co/papers/2507.15778))| Guorui Zhou, Xiu Li, Fuzheng Zhang, Jiakang Wang, RyanLiu112 | This paper introduces Archer, a novel reinforcement learning with verifiable rewards (RLVR) approach to improve the reasoning abilities of large language models (LLMs). The study aims to address the limitations of previous RLVR algorithms that uniformly treat all tokens, neglecting the different roles of knowledge-related and reasoning-related tokens. Archer applies dual-token constraints with weaker KL regularization and higher clipping thresholds for reasoning tokens while using stronger constraints on knowledge tokens. Experimental results on benchmarks such as AIME24 show a pass@1 improvement of 6.6 compared to DAPO, indicating improved reasoning performance. The key implication is that differentiating token treatment in RLVR training, with entropy-aware constraints, stabilizes knowledge and promotes reasoning in LLMs. |
| Multi-Modal | Being-H0: Vision-Language-Action Pretraining from Large-Scale Human
  Videos (Read more on [arXiv](https://arxiv.org/abs/2507.15597) or [HuggingFace](https://huggingface.co/papers/2507.15597))| Sipeng Zheng, Yicheng Feng, Hao Luo, Yaya041, zawnpn | The paper introduces Being-HO, a vision-language-action (VLA) model pretrained on large-scale human videos for dexterous manipulation. It addresses the data bottleneck of existing VLAs by proposing physical instruction tuning and part-level motion tokenization, enabling learning from human videos and transfer to robotic tasks. Being-HO achieves millimeter-level hand trajectory reconstruction accuracy and demonstrates strong performance in hand motion generation and instruction following. The model also shows real-world robotic manipulation gains when physical instruction tuning is applied, but the extent of these gains is not quantitatively specified. The research implies a viable route for developing capable dexterous robotic systems by leveraging human hand motion data and physical instruction tuning. |
| Computer Vision | Gaussian Splatting with Discretized SDF for Relightable Assets (Read more on [arXiv](https://arxiv.org/abs/2507.15629) or [HuggingFace](https://huggingface.co/papers/2507.15629))| Beibei Wang, Jian Yang, Zuo-Liang Zhu | This paper introduces a novel relightable Gaussian splatting framework to improve decomposition quality by leveraging a discretized signed distance field (SDF). The research aims to enhance inverse rendering within Gaussian splatting by effectively regularizing geometry without increasing memory usage or complicating training. The key methodology involves encoding discretized SDF values within each Gaussian primitive and using a projection-based consistency loss to regularize the SDF. Experiments demonstrate high relighting quality, with an average PSNR of 24.52 on the Glossy Blender dataset, while using significantly less memory than previous methods. The approach offers AI practitioners a more lightweight and efficient method for creating relightable 3D assets. |
| Computer Vision | NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining (Read more on [arXiv](https://arxiv.org/abs/2507.14119) or [HuggingFace](https://huggingface.co/papers/2507.14119))| Bulat Suleimanov, Georgii Fedorov, Grigorii Alekseenko, Maksim Kuprashevich, iitolstykh | The paper introduces an autonomous pipeline for mining high-quality image editing triplets for supervised training of generative models. It addresses the lack of robust automated edit-quality metrics using a task-tuned Gemini validator to score instruction adherence and aesthetics. The pipeline incorporates inversion and compositional bootstrapping to enlarge the mined dataset by ≈2.2×. Evaluation of the released NHR-Edit dataset (358k triplets) shows it surpasses all public alternatives in cross-dataset evaluations. The release of the dataset and a fine-tuned Bagel model democratizes research in image editing by automating the data creation process. |
| Computer Vision | Towards Video Thinking Test: A Holistic Benchmark for Advanced Video
  Reasoning and Understanding (Read more on [arXiv](https://arxiv.org/abs/2507.15028) or [HuggingFace](https://huggingface.co/papers/2507.15028))| Bo Hu, Aria Leo, Yuhao Dong, yunicechew, ZhangYuanhan | This paper introduces the Video Thinking Test (Video-TT), a novel benchmark designed to evaluate advanced video reasoning and understanding capabilities in AI models. Video-TT assesses correctness in understanding complex visual narratives and robustness against natural adversarial questions using 1,000 YouTube Shorts videos. The key methodology involves assessing model accuracy and robustness on both open-ended and adversarial questions, uncovering vulnerabilities. Results show a significant gap between human (84.3% accuracy) and model (36.6% accuracy) performance, particularly in open-ended reasoning. The benchmark highlights the need for improved reasoning and resilience in video understanding models for real-world applications. |
| Machine Learning | Inverse Scaling in Test-Time Compute (Read more on [arXiv](https://arxiv.org/abs/2507.14417) or [HuggingFace](https://huggingface.co/papers/2507.14417))| Jacob Goldman-Wetzler, Andy Arditi, Runjin Chen, Alexander Hägele, Aryo Pradipta Gema | This paper identifies inverse scaling effects in Large Reasoning Models (LRMs) where increased test-time compute leads to decreased accuracy on specific tasks. The study investigates how extended reasoning deteriorates performance across tasks like counting with distractors, regression with spurious features, and deduction with constraint tracking.  Methodology includes designing evaluations to test failure modes, examining models' reasoning traces, and quantifying accuracy changes with increasing reasoning tokens. Results demonstrate that longer reasoning can amplify flaws, with specific LRMs showing distinct failure modes such as distraction or overfitting, supported by quantitative data from the task-specific metrics (accuracy/RMSE). The implication is that test-time compute scaling, while beneficial, requires careful evaluation to avoid inadvertently reinforcing problematic reasoning patterns. |
| Natural Language Processing | STITCH: Simultaneous Thinking and Talking with Chunked Reasoning for
  Spoken Language Models (Read more on [arXiv](https://arxiv.org/abs/2507.15375) or [HuggingFace](https://huggingface.co/papers/2507.15375))| Kevin Lin, Chung-Ching Lin, Linjie Li, xiaofei-wang, dcml0714 | The paper introduces STITCH, a novel generation framework for Spoken Language Models (SLMs) that enables simultaneous thinking and talking by interleaving unspoken reasoning chunks with spoken response chunks. It addresses the challenge of incorporating internal reasoning processes into SLMs without incurring excessive latency. The key methodology involves alternating between generating fixed-length reasoning spans, text token spans, and speech token spans, utilizing the audio duration of speech chunks to generate additional reasoning tokens. Experiments on math reasoning datasets show that STITCH achieves a 15% improvement over baselines that lack explicit reasoning, while maintaining comparable performance on non-reasoning tasks.  STITCH's low latency and high performance suggest a promising approach for enhancing spoken language models. |
| Computer Vision | Streaming 4D Visual Geometry Transformer (Read more on [arXiv](https://arxiv.org/abs/2507.11539) or [HuggingFace](https://huggingface.co/papers/2507.11539))| Jie Zhou, Yuqi Wu, Wenzhao Zheng, lch01, paryi | The paper introduces StreamVGGT, a streaming 4D visual geometry transformer for efficient online 4D reconstruction. It addresses the challenge of real-time 4D reconstruction by proposing a causal transformer architecture with cached token memory. The method uses temporal causal attention to process video frames incrementally, maintaining spatial consistency with a distillation-based training strategy. Experimental results on the ETH3D dataset show StreamVGGT achieves an overall quality score of 0.577, comparable to offline methods, while significantly reducing inference time. This enables practical, real-time applications of 4D vision systems. |
| Computer Vision | Latent Denoising Makes Good Visual Tokenizers (Read more on [arXiv](https://arxiv.org/abs/2507.15856) or [HuggingFace](https://huggingface.co/papers/2507.15856))| Yue Wang, Yonglong Tian, Lijie Fan, Tianhong Li, Jiawei Yang | The paper introduces Latent Denoising Tokenizer (l-DeTok) for enhanced visual generative modeling. It investigates how aligning tokenizer embeddings with downstream denoising objectives improves generative performance. L-DeTok trains tokenizers to reconstruct clean images from latent embeddings corrupted by interpolative noise and masking. Experiments on ImageNet 256x256 demonstrate consistent outperformance of l-DeTok over standard tokenizers across six generative models, for example, improving the FID score for MAR-B from 2.31 to 1.55. The research suggests denoising as a fundamental principle for tokenizer design, potentially motivating new perspectives in this area. |
| Reinforcement Learning | LLM Economist: Large Population Models and Mechanism Design in
  Multi-Agent Generative Simulacra (Read more on [arXiv](https://arxiv.org/abs/2507.15815) or [HuggingFace](https://huggingface.co/papers/2507.15815))| Yu Bai, Samuel Kleiner, Zihan Ding, Wenzhe Li, milkkarten | The paper introduces LLM Economist, a framework for agent-based modeling to design and assess economic policies. It investigates optimal tax policies in strategic environments using hierarchical decision-making within multi-agent generative simulacra. The methodology employs in-context reinforcement learning to optimize piecewise-linear marginal tax schedules with worker agents instantiating persona-conditioned prompts. Results show the planner converges near Stackelberg equilibria, improving social welfare relative to Saez solutions by 10% in a seven-bracket bounded case. The framework provides a tractable test bed for policy evaluation at a societal scale using large language model-based agents. |
| Machine Learning | Data Mixing Agent: Learning to Re-weight Domains for Continual
  Pre-training (Read more on [arXiv](https://arxiv.org/abs/2507.15640) or [HuggingFace](https://huggingface.co/papers/2507.15640))| Yeyun Gong, Hao Li, Lei Ji, lx865712528, klyang | The paper introduces Data Mixing Agent, a novel framework for continual pre-training that learns to re-weight data domains to mitigate catastrophic forgetting. The research aims to develop an end-to-end, model-based approach using reinforcement learning to dynamically adjust domain mixing proportions during pre-training. The method trains an agent on data mixing trajectories, using feedback from an evaluation environment, and employs conservative Q-learning for optimization. Experiments demonstrate a 3.02% performance improvement on math reasoning benchmarks compared to strong baselines while maintaining general capabilities. The implication is a more balanced and efficient continual pre-training strategy, enabling superior model performance with reduced reliance on source-field data. |
| Computer Vision | "PhyWorldBench": A Comprehensive Evaluation of Physical Realism in
  Text-to-Video Models (Read more on [arXiv](https://arxiv.org/abs/2507.13428) or [HuggingFace](https://huggingface.co/papers/2507.13428))| Fangrui Zhu, Ashwin Nagarajan, Yu Zeng, Xian Liu, Jing Gu | The paper introduces PhyWorldBench, a comprehensive benchmark for evaluating physical realism in text-to-video models.  It investigates the ability of these models to accurately simulate various physical phenomena, from fundamental principles to complex interactions. The benchmark includes a novel "Anti-Physics" category to assess if models understand physics beyond pattern reproduction.  Evaluation of 12 state-of-the-art models across 1,050 prompts reveals challenges in temporal consistency, motion realism, and physical plausibility, with the best model achieving a success rate of 0.262. The findings emphasize the need for improvements in physically accurate video generation, offering insights into prompt design strategies. |
| Machine Learning | A Simple "Try Again" Can Elicit Multi-Turn LLM Reasoning (Read more on [arXiv](https://arxiv.org/abs/2507.14295) or [HuggingFace](https://huggingface.co/papers/2507.14295))| Yiping Lu, Chenwei Xu, Linjie Li, Zihan Wang, Licheng Liu | This paper introduces Unary Feedback as Observation (UFO), a reinforcement learning method to improve multi-turn reasoning in Large Language Models (LLMs). The research aims to address the limitation of single-turn RL training, which hinders models' ability to revise answers based on contextual feedback, often leading to repetitive responses. UFO uses only unary feedback (e.g., "try again") during training, framing interactive problem-solving as a Markov Decision Process. Experimental results show that RL training with UFO improves multi-turn reasoning accuracy by up to 14%, enabling language models to react better to feedback. The implication is that minimal feedback can unlock improved multi-turn reasoning capabilities in LLMs, enhancing their interactive problem-solving abilities. |
| Computer Vision | GeoDistill: Geometry-Guided Self-Distillation for Weakly Supervised
  Cross-View Localization (Read more on [arXiv](https://arxiv.org/abs/2507.10935) or [HuggingFace](https://huggingface.co/papers/2507.10935))| Yujiao Shi, Xuming He, Alexandre Alahi, Zimin Xia, tsw200027 | The paper introduces GeoDistill, a geometry-guided self-distillation framework for weakly supervised cross-view localization. The primary objective is to enhance local feature learning for robust pose estimation using only ground-satellite image pairs. GeoDistill employs a teacher-student model with Field-of-View (FoV)-based masking, encouraging the student to focus on key local features by aligning its predictions with the teacher's. Results on the VIGOR dataset show GeoDistill improves localization performance, reducing mean error by over 10% compared to baseline methods. This provides a scalable solution for cross-view localization by diminishing the reliance on costly ground truth annotations. |
| Computer Vision | UGPL: Uncertainty-Guided Progressive Learning for Evidence-Based
  Classification in Computed Tomography (Read more on [arXiv](https://arxiv.org/abs/2507.14102) or [HuggingFace](https://huggingface.co/papers/2507.14102))| Chandrakala S, Rakesh Raj Madavan, Pavan Kumar S, Shravan Venkatraman | The paper introduces UGPL, an uncertainty-guided progressive learning framework for improved medical image classification in computed tomography. It addresses the challenge of detecting subtle and spatially diverse pathological features by performing a global-to-local analysis, focusing on regions of diagnostic ambiguity identified via evidential deep learning. The approach employs a non-maximum suppression mechanism to extract informative patches and combines global and local predictions through adaptive fusion. Experimental results on three CT datasets demonstrate that UGPL outperforms state-of-the-art methods, achieving an 8.08% accuracy improvement for COVID-19 detection; this implies that AI practitioners can leverage uncertainty-guided progressive learning for enhanced performance in medical image classification tasks. |
