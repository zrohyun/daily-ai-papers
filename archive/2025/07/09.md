

## Papers for 2025-07-09

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Machine Learning | SingLoRA: Low Rank Adaptation Using a Single Matrix (Read more on [arXiv](https://arxiv.org/abs/2507.05566) or [HuggingFace](https://huggingface.co/papers/2507.05566))| Ron Kimmel, Daniel Bensaïd, David Bensaïd, royve, noamrot | The paper introduces SingLoRA, a novel low-rank adaptation technique for parameter-efficient fine-tuning using a single matrix decomposition. It addresses the scale disparity issue in LoRA by learning a single low-rank matrix update multiplied by its transpose, thus promoting stable optimization and halving the parameter count. Experiments on MNLI with Llama 7B show SingLoRA achieves 91.3% accuracy, surpassing LoRA's 89.1% and LoRA+'s 90.2%, with only 60% of their parameter budget. This suggests SingLoRA enables more efficient and stable fine-tuning for large models, enhancing performance across tasks, without requiring specialized optimization techniques. |
| Computer Vision | OmniPart: Part-Aware 3D Generation with Semantic Decoupling and
  Structural Cohesion (Read more on [arXiv](https://arxiv.org/abs/2507.06165) or [HuggingFace](https://huggingface.co/papers/2507.06165))| Yukun Huang, Zi-Xin Zou, Yuan-Chen Guo, Yufan Zhou, Yunhan Yang | The paper introduces OmniPart, a novel framework for part-aware 3D object generation with semantic decoupling and structural cohesion. It addresses the challenge of creating 3D assets with editable part structures by decoupling structural planning from detailed part synthesis. The method uses an autoregressive model guided by 2D part masks to plan a 3D part structure and then employs a spatially-conditioned rectified flow model to generate high-quality, textured parts. Experiments demonstrate state-of-the-art performance, with voxel recall reaching 85.96% in bounding box generation. OmniPart enables enhanced editing, customization, and animation, offering AI practitioners a tool for creating more interpretable and versatile 3D content. |
| Multi-Modal | StreamVLN: Streaming Vision-and-Language Navigation via SlowFast Context
  Modeling (Read more on [arXiv](https://arxiv.org/abs/2507.05240) or [HuggingFace](https://huggingface.co/papers/2507.05240))| Yuqiang Yang, Tai Wang, Xiqian Yu, Meng Wei, cywan | The paper introduces StreamVLN, a streaming vision-and-language navigation framework for real-time interaction. It addresses the need for fine-grained visual understanding and long-term context modeling by employing a hybrid slow-fast context modeling strategy over interleaved vision, language, and action inputs. StreamVLN uses a fast-streaming dialogue context with a sliding-window KV cache and a slow-updating memory via token pruning. Experiments on VLN-CE benchmarks demonstrate state-of-the-art performance with a success rate of 56.9% and SPL of 51.9% on R2R Val-Unseen and 52.9% SR and 46.0% SPL on RxR Val-Unseen, suggesting improved robustness and efficiency for real-world deployment. The slow-fast design allows for efficient KV cache reuse, supporting long video streams with bounded context size and inference cost. |
| Reinforcement Learning | RLVER: Reinforcement Learning with Verifiable Emotion Rewards for
  Empathetic Agents (Read more on [arXiv](https://arxiv.org/abs/2507.03112) or [HuggingFace](https://huggingface.co/papers/2507.03112))| Zhiwei He, Xingyu Chen, Bang Zhang, vvibt, CedarWang | The paper introduces RLVER, a reinforcement learning framework for enhancing empathetic abilities in LLMs using verifiable emotion rewards. It addresses the challenge of creating emotionally intelligent dialogue agents by leveraging self-consistent affective simulated users to provide reward signals. RLVER fine-tunes a Qwen2.5-7B model using PPO, achieving a Sentient-Benchmark score increase from 13.3 to 79.2, while preserving mathematical and coding competence. Experiments demonstrate that RLVER consistently improves dialogue capabilities and reveals distinct developmental patterns between thinking and non-thinking models. The results suggest that RLVER is a practical approach for developing emotionally intelligent language agents, though the details of the user simulator remain unclear. |
| Computer Vision | MedGen: Unlocking Medical Video Generation by Scaling
  Granularly-annotated Medical Videos (Read more on [arXiv](https://arxiv.org/abs/2507.05675) or [HuggingFace](https://huggingface.co/papers/2507.05675))| Shunian Chen, Zhenyang Cai, Ke Ji, Junying Chen, wangrongsheng | The paper introduces MedGen, a novel approach to medical video generation. It addresses the lack of large-scale, high-quality medical video datasets by creating MedVideoCap-55K, containing over 55,000 curated clips with detailed captions. Using this dataset, they train MedGen, a specialized video generation model, to enhance both visual quality and medical accuracy in generated videos. MedGen achieves leading performance among open-source models, rivaling commercial systems, demonstrated by an improved performance on the Med-VBench benchmark with a warping error of 38.50. The introduction of MedVideoCap-55K and MedGen provides a valuable resource for AI practitioners, enabling more faithful and diverse medical video generation. |
| Robotic Manipulation | Is Diversity All You Need for Scalable Robotic Manipulation? (Read more on [arXiv](https://arxiv.org/abs/2507.06219) or [HuggingFace](https://huggingface.co/papers/2507.06219))| Jin Chen, Li Chen, sundrops, yxlu0, ModiShi | This research investigates the role of data diversity in scalable robotic manipulation. The study challenges the conventional wisdom that “more diverse is better” by examining task, embodiment, and expert diversity. The methodology includes a comprehensive evaluation in simulation and real-world environments using a custom manipulation setup. The results show that task diversity is more critical than per-task demonstration quantity, and expert diversity can confound policy learning. Specifically, the proposed GO-1-Pro achieves a 15% performance gain by distribution debiasing, equivalent to using 2.5x more pre-training data, thus providing practical guidance for effective robotic manipulation datasets. |
| Natural Language Processing | Coding Triangle: How Does Large Language Model Understand Code? (Read more on [arXiv](https://arxiv.org/abs/2507.06138) or [HuggingFace](https://huggingface.co/papers/2507.06138))| Songyang Zhang, Maosong Cao, Taolin Zhang, jnanliu, MichaelErchi | The paper introduces the "Code Triangle" framework for evaluating LLMs' coding capabilities across editorial analysis, code implementation, and test case generation. It investigates how LLMs interpret coding problems within each dimension and explores interactions across them, revealing inconsistencies between model cognition and human expertise. Experiments on competitive programming benchmarks show LLMs can form self-consistent systems but lack human diversity and robustness; ensembling models and incorporating human data improves performance.  Notably, self-generated editorials do not significantly enhance coding performance, indicating self-consistency between analysis and implementation. The framework offers a potential direction for developing more powerful coding models by revealing consistency and inconsistency in LLMs' cognition. |
| Reinforcement Learning | GTA1: GUI Test-time Scaling Agent (Read more on [arXiv](https://arxiv.org/abs/2507.05791) or [HuggingFace](https://huggingface.co/papers/2507.05791))| Yuhao Yang, Yutong Dai, Dongxu Li, Yan Yang, Ziyang | This paper introduces GTA1, a GUI test-time scaling agent, to enhance planning and grounding in GUI environments. The research aims to address planning ambiguity and improve grounding accuracy through test-time scaling and reinforcement learning. The agent samples multiple action proposals and uses a judge model for selection, coupled with an RL-based grounding model for precise interaction. GTA1-7B achieves 50.1% accuracy on Screenspot-Pro, outperforming existing methods.  The work provides an effective approach to address critical challenges in autonomous GUI interaction. |
| Natural Language Processing | Nile-Chat: Egyptian Language Models for Arabic and Latin Scripts (Read more on [arXiv](https://arxiv.org/abs/2507.04569) or [HuggingFace](https://huggingface.co/papers/2507.04569))| Mohamed Anwar, Amr Mohamed, Ahmad Chamma, Hadi Abdine, guokan-shang | The paper introduces Nile-Chat, a family of large language models for the Egyptian Arabic dialect, supporting both Arabic and Latin scripts. It aims to address the lack of adequate support for dual-script usage in existing Arabic LLMs by creating models that natively handle texts in both scripts. The study employs a Branch-Train-MiX strategy to merge script-specialized experts into a single Mixture-of-Experts (MoE) model, enhancing performance without sacrificing efficiency. Results show that the 12B Nile-Chat model improves Latin-script benchmark performance by 14.4% over Qwen2.5-14B-Instruct. This work provides a methodology for adapting LLMs to dual-script languages, potentially filling a gap in modern LLM development. |
| Natural Language Processing | Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers (Read more on [arXiv](https://arxiv.org/abs/2507.06223) or [HuggingFace](https://huggingface.co/papers/2507.06223))| Yi Fang, Ting-ruen Wei, Zhiyuan Peng, yilunzhao, songtingyu | This paper proposes E2R-FLOPs, a metric for evaluating the efficiency-effectiveness tradeoff of LLM-based rerankers using ranking metrics per PetaFLOP (RPP) and queries per PetaFLOP (QPP). The research aims to address the lack of hardware-agnostic computational granularity in existing evaluation metrics. The authors build an interpretable FLOPs estimator and conduct experiments across various LLM architectures. The results show that pointwise methods achieve high RPP, reaching up to 72.67 on TREC DL19. The work provides practitioners with a means to fairly compare LLM-based reranking methods, considering both relevance and compute costs. |
| Machine Learning | PRING: Rethinking Protein-Protein Interaction Prediction from Pairs to
  Graphs (Read more on [arXiv](https://arxiv.org/abs/2507.05101) or [HuggingFace](https://huggingface.co/papers/2507.05101))| Zhiyuan Liu, Fanding Xu, Hao Du, JinzheFudan, piaolaidangqu | The paper introduces PRING, a novel benchmark for evaluating protein-protein interaction (PPI) prediction models from a graph-level perspective. It addresses the limitation of existing benchmarks that focus on isolated pairwise evaluations by assessing a model's capability to reconstruct biologically meaningful PPI networks. The research aims to evaluate how current PPI models recapitulate structural and functional features of PPI networks. PRING curates a high-quality, multi-species PPI network dataset and establishes topology-oriented and function-oriented evaluation paradigms, revealing potential limitations of current PPI models in recovering structural and functional properties, achieving a best graph similarity score of 0.491 with PLM-interact (650M) in intra-species network construction. PRING offers a reliable platform for developing more effective PPI prediction models to better support real-world biological applications. |
| Computer Vision | SAMed-2: Selective Memory Enhanced Medical Segment Anything Model (Read more on [arXiv](https://arxiv.org/abs/2507.03698) or [HuggingFace](https://huggingface.co/papers/2507.03698))| Rong Zhou, Yiwei Li, Sifan Song, Zhiling Yan, songdj | SAMed-2 is a novel medical image segmentation foundation model that enhances the SAM-2 architecture. The research aims to improve medical image segmentation by addressing challenges related to data complexity, noisy annotations, and continual learning. SAMed-2 incorporates a temporal adapter for capturing image correlations and a confidence-driven memory mechanism for retaining high-certainty features, mitigating noise and catastrophic forgetting. Experiments on MedBank-100k, a new dataset with seven modalities and 21 tasks, show improved performance over state-of-the-art methods. Specifically, SAMed-2 improves external zero-shot performance by 10.53%, enabling more robust and adaptable medical image segmentation. |
| Computer Vision | Tora2: Motion and Appearance Customized Diffusion Transformer for
  Multi-Entity Video Generation (Read more on [arXiv](https://arxiv.org/abs/2507.05963) or [HuggingFace](https://huggingface.co/papers/2507.05963))| Weizhi Wang, Long Qin, Xiangyu Meng, Junchao Liao, Zhenghao Zhang | The paper presents Tora2, a diffusion transformer for multi-entity video generation with customized motion and appearance. It addresses the challenge of simultaneously controlling the appearance and motion of multiple entities in a video. Tora2 introduces a decoupled personalization extractor, a gated self-attention mechanism, and a contrastive learning framework to achieve this. Experiments on the MSRVTT-Personalization benchmark demonstrate competitive performance with state-of-the-art methods and trajectory error of 13.52. The ability to control both motion and appearance for multiple entities offers AI practitioners advanced control in video generation tasks. |
| Natural Language Processing | LOOM-Scope: a comprehensive and efficient LOng-cOntext Model evaluation
  framework (Read more on [arXiv](https://arxiv.org/abs/2507.04723) or [HuggingFace](https://huggingface.co/papers/2507.04723))| Ruoxi Sun, Baibei Ji, Haitian Wang, Zecheng Tang, QQTang1223 | The paper introduces LOOM-Scope, a comprehensive and efficient framework for evaluating long-context language models (LCLMs). It addresses the inconsistent evaluation settings and high computational costs associated with existing benchmarks by standardizing evaluation, supporting inference acceleration, and offering a lightweight benchmark suite. LOOM-Scope achieves a full capability assessment of 8B scale models with only approximately 50 H20 GPU hours on LOOMBENCH. The framework provides AI practitioners with a unified and extensible platform to assess LCLM capabilities and optimize performance. |
| Reinforcement Learning | How to Train Your LLM Web Agent: A Statistical Diagnosis (Read more on [arXiv](https://arxiv.org/abs/2507.04103) or [HuggingFace](https://huggingface.co/papers/2507.04103))| Megh Thakkar, Hadi Nekoei, Emiliano Penaloza, Santhoshi Ravichandran, Dheeraj Vattikonda | The paper presents a statistical diagnosis of compute allocation for training LLM web agents. It investigates how to optimally allocate compute between supervised fine-tuning (SFT) and on-policy reinforcement learning (RL) for a Llama 3.1 8B student imitating a Llama 3.3 70B teacher. By sampling 1,370 configurations and using bootstrapping, the study finds that combining SFT with on-policy RL outperforms either approach alone, achieving similar performance to pure SFT with 55% of the compute on MiniWoB++. This approach closes the gap with closed-source models, demonstrating the importance of balancing sample efficiency and compute efficiency for scaling LLM-agent training. |
| Natural Language Processing | Differential Mamba (Read more on [arXiv](https://arxiv.org/abs/2507.06204) or [HuggingFace](https://huggingface.co/papers/2507.06204))| Eliya Nachmani, Itamar Zimerman, Nadav Schneider | The paper introduces Differential Mamba, a modification of the Mamba architecture designed to mitigate the over-allocation of attention to irrelevant context in language models. It aims to improve the robustness of Mamba models by reducing noisy representations in hidden layers. The proposed method involves a novel differential mechanism for Mamba, validated on language modeling benchmarks. Empirical results show Diff-Mamba achieves improved retrieval capabilities and superior perplexity scores (e.g., a decrease of 0.4 perplexity on WikiText-103 with a 12-layer model) compared to vanilla Mamba. The research suggests that differential design can enhance Mamba-based models, leading to more reliable and robust language processing. |
| Machine Learning | any4: Learned 4-bit Numeric Representation for LLMs (Read more on [arXiv](https://arxiv.org/abs/2507.04610) or [HuggingFace](https://huggingface.co/papers/2507.04610))| Jeff Johnson, melhoushi | The paper introduces any4, a learned 4-bit weight quantization solution for large language models (LLMs). It aims to improve quantization accuracy without requiring pre-processing of weights or activations. The methodology involves a K-means-style alternating optimization procedure to determine optimal quantization configurations for each row of the weight matrix. Results show any4 achieves higher accuracy compared to other 4-bit numeric representations like int4, fp4, and nf4, and is competitive with AWQ/GPTQ while simplifying the quantization procedure. This work offers AI practitioners a more efficient quantization scheme for deploying LLMs, yielding benefits in memory footprint and inference speed. |
| Computer Vision | High-Resolution Visual Reasoning via Multi-Turn Grounding-Based
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2507.05920) or [HuggingFace](https://huggingface.co/papers/2507.05920))| Rui Feng, Bo Li, Weiwei Tian, Yuhao Dong, Xinyu Huang | The paper addresses the challenge of processing high-resolution images in large multi-modal models (LMMs) by proposing a Multi-turn Grounding-based Policy Optimization (MGPO) framework. It aims to enable LMMs to iteratively focus on key visual regions by automatically cropping sub-images based on model-predicted grounding coordinates within a multi-turn conversation framework. MGPO is an end-to-end reinforcement learning approach that only requires a binary reward function. Experimental results demonstrate a 5.4% improvement on in-distribution MME-Realworld and a 5.2% improvement on the out-of-distribution V* Bench when applied to Qwen2.5-VL-7B. The implication is that LMMs can emerge robust grounding abilities during RL training, leveraging only a binary reward, reducing the need for costly grounding annotations. |
| Natural Language Processing | The Landscape of Memorization in LLMs: Mechanisms, Measurement, and
  Mitigation (Read more on [arXiv](https://arxiv.org/abs/2507.05578) or [HuggingFace](https://huggingface.co/papers/2507.05578))| Dawn Song, Aneesh Pappu, Xuandong Zhao, Alexander Xiong | This paper examines memorization in Large Language Models (LLMs), focusing on its mechanisms, measurement, and mitigation. It investigates factors such as training data duplication, training dynamics, and fine-tuning's impact on memorization. Methods like prefix-based extraction and membership inference are analyzed for detecting memorized content. Mitigation strategies, including data cleaning and differential privacy, are discussed alongside open challenges, such as balancing memorization minimization with utility, which could be improved using activation steering. This paper offers a comprehensive overview of LLM memorization, providing insights for practitioners to address privacy and security vulnerabilities. |
| Machine Learning | FAROS: Fair Graph Generation via Attribute Switching Mechanisms (Read more on [arXiv](https://arxiv.org/abs/2507.03728) or [HuggingFace](https://huggingface.co/papers/2507.03728))| Fragkiskos D. Malliaros, Daniele Malitesta, Hatim Mrabet, Oussama Kharouiche, badaoui | The paper introduces FAROS, a novel framework for fair graph generation that leverages attribute switching mechanisms. It addresses the challenge of bias amplification in graph diffusion models (GDMs) by altering sensitive node attributes during generation. FAROS calculates the optimal fraction of nodes for switching and selects the diffusion step by preserving the node-topology profile and ensuring edge independence on sensitive attributes. Experiments on link prediction tasks demonstrate that FAROS effectively reduces fairness discrepancies while maintaining or improving accuracy, achieving better accuracy-fairness trade-offs than other baselines with competitive or higher accuracy. Specifically, experiments showed an increase in AUC score, suggesting enhanced utility compared to other baselines. FAROS provides a practical approach for AI practitioners to mitigate unfairness in graph data generated by diffusion models without retraining. |
| Machine Learning | AXLearn: Modular Large Model Training on Heterogeneous Infrastructure (Read more on [arXiv](https://arxiv.org/abs/2507.05411) or [HuggingFace](https://huggingface.co/papers/2507.05411))| Hanzhi Zhou, John Peebles, Chang Lan, Tom Gunter, Mark Lee | The paper introduces AXLearn, a production deep learning system designed for scalable and high-performance large model training on heterogeneous infrastructure. AXLearn prioritizes modularity through strict encapsulation to facilitate rapid experimentation across diverse hardware. The research focuses on quantifying modularity via Lines-of-Code (LoC)-complexity, demonstrating that AXLearn maintains constant complexity when scaling components. The system achieves equivalent performance to state-of-the-art training systems while supporting features like Rotary Position Embeddings (ROPE) with minimal code changes. The implication is a framework enabling practitioners to easily integrate features and customize parallelization across various compute resources (GPU, TPU, AWS Trainium). |
