

## Papers for 2025-10-07

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Computer Vision | Paper2Video: Automatic Video Generation from Scientific Papers (Read more on [arXiv](https://arxiv.org/abs/2510.05096) or [HuggingFace](https://huggingface.co/papers/2510.05096))|  | The paper introduces Paper2Video, a benchmark and framework for automatic presentation video generation from scientific papers. It addresses the challenge of generating informative and faithful videos by proposing a multi-agent framework, PaperTalker, that integrates slide generation, subtitling, cursor grounding, speech synthesis, and talking-head rendering. Paper2Video includes 101 research papers with corresponding author-created presentation videos and four tailored evaluation metrics (Meta Similarity, PresentArena, PresentQuiz, and IP Memory). Experiments show that videos generated by PaperTalker achieve 10% higher PresentQuiz accuracy than human-made presentations, demonstrating improved knowledge conveyance. The system significantly reduces production time compared to manual video creation, enhancing the scalability of scholarly communication. |
| Multi-Modal | Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large
  Multimodal Models (Read more on [arXiv](https://arxiv.org/abs/2510.05034) or [HuggingFace](https://huggingface.co/papers/2510.05034))| Zhangyun Tan, Zhenyu Pan, Pinxin Liu, Jing Bi, Yunlong Tang | This survey comprehensively examines post-training methodologies for Video-Large Multimodal Models (Video-LMMs) to enhance video reasoning. The objective is to provide a structured understanding of how models transition from basic perception to sophisticated reasoning engines. The study categorizes post-training techniques into supervised fine-tuning (SFT), reinforcement learning (RL), and test-time scaling (TTS), analyzing their roles and video-specific adaptations. Although specific quantitative metrics are not provided in the abstract, the paper identifies key design principles and evaluation protocols for these methods. It aims to provide a unified framework for researchers and practitioners to advance Video-LMM capabilities by addressing unique challenges such as temporal localization and multimodal evidence integration. |
| Computer Vision | VChain: Chain-of-Visual-Thought for Reasoning in Video Generation (Read more on [arXiv](https://arxiv.org/abs/2510.05094) or [HuggingFace](https://huggingface.co/papers/2510.05094))| Paul Debevec, Haonan Qiu, Gordon Chen, Ning Yu, Ziqi Huang | The paper introduces VChain, a novel inference-time tuning framework for enhancing reasoning in video generation. It addresses the challenge of generating videos with complex dynamics and coherent consequences by leveraging large multimodal models to create a sparse set of critical keyframes, termed Visual Thoughts, which guide the video generator. Sparse Inference-Time Tuning, adapting a pre-trained video generator via LoRA only at these key moments, is employed. Experiments demonstrate that VChain significantly enhances the quality of generated videos, achieving a 71.67% VBench Quality Score. VChain offers a method for improving the reasoning capabilities of video generation models by integrating high-level reasoning signals from multimodal models at inference time. |
| Natural Language Processing | Imperceptible Jailbreaking against Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2510.05025) or [HuggingFace](https://huggingface.co/papers/2510.05025))|  | This paper introduces imperceptible jailbreaks for large language models (LLMs) by exploiting Unicode variation selectors. The research aims to demonstrate that LLMs can be manipulated through invisible modifications to malicious questions. The methodology involves a chain-of-search pipeline to generate adversarial suffixes of variation selectors, maximizing the likelihood of target-start tokens for harmful responses. Experiments show that the imperceptible jailbreaks achieve high attack success rates (up to 100% on certain models) against four aligned LLMs and generalize to prompt injection attacks without visible prompt modifications. The study implies that current LLM alignment mechanisms are vulnerable to subtle, encoding-based attacks, necessitating enhanced security measures. |
| Natural Language Processing | MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual
  Information (Read more on [arXiv](https://arxiv.org/abs/2510.03632) or [HuggingFace](https://huggingface.co/papers/2510.03632))|  | The paper introduces Mutual Information Tree Search (MITS), a novel framework for enhancing reasoning in Large Language Models (LLMs) using information-theoretic principles. It addresses the challenge of efficiently searching through vast reasoning paths by introducing Pointwise Mutual Information (PMI) as a scoring function for intermediate reasoning steps. MITS employs an entropy-based dynamic sampling strategy to allocate computational resources and a weighted voting scheme to combine PMI scores with prediction consensus. Experiments across diverse reasoning benchmarks demonstrate that MITS surpasses baseline methods, achieving, for instance, 92.55% accuracy on the ARC-Challenge dataset with QWEN2.5-7B, implying a principled and efficient framework for LLM reasoning. The method offers AI practitioners a computationally efficient approach to improve LLM reasoning by leveraging information-theoretic guidance in tree search. |
| Natural Language Processing | Hybrid Architectures for Language Models: Systematic Analysis and Design
  Insights (Read more on [arXiv](https://arxiv.org/abs/2510.04800) or [HuggingFace](https://huggingface.co/papers/2510.04800))|  | This paper systematically analyzes hybrid language model architectures combining self-attention with structured state space models. The research investigates inter-layer (sequential) and intra-layer (parallel) fusion strategies to optimize performance and efficiency. The methodology involves evaluating language modeling performance, long-context capabilities, and scaling properties of different hybrid designs. Results show that hybrid models outperform homogeneous architectures by up to 2.9% in accuracy. The analysis provides practical guidance for AI practitioners to facilitate architectural configuration optimization in hybrid language models. |
| Computer Vision | Factuality Matters: When Image Generation and Editing Meet Structured
  Visuals (Read more on [arXiv](https://arxiv.org/abs/2510.05091) or [HuggingFace](https://huggingface.co/papers/2510.05091))| Sayak Paul, Boxiang Qiu, Yuandong Pu, Songhao Han, Le Zhuo | This paper addresses the challenge of generating and editing structured visuals like charts and diagrams, where factual accuracy is critical. The research introduces a comprehensive framework including a large-scale dataset, a unified model, and a novel benchmark for this domain. The model integrates a VLM with FLUX.1 Kontext and is trained with a three-stage curriculum, achieving competitive performance. Evaluations on the StructBench benchmark demonstrate the model's effectiveness, with the best performing model achieving around 55% accuracy on the StructEditBench, but leaving substantial room for improvement. The release of the dataset, model, and benchmark aims to advance unified multimodal foundations for structured visuals. |
| Natural Language Processing | Reactive Transformer (RxT) -- Stateful Real-Time Processing for
  Event-Driven Reactive Language Models (Read more on [arXiv](https://arxiv.org/abs/2510.03561) or [HuggingFace](https://huggingface.co/papers/2510.03561))|  | The paper introduces the Reactive Transformer (RxT), a novel architecture for stateful real-time processing in event-driven language models. It addresses the limitations of stateless Transformers in conversational AI by maintaining context in a fixed-size Short-Term Memory (STM) system. RxT processes each turn as a discrete event, decoupling response generation from asynchronous memory updates, enabling linear scaling. Experiments demonstrate superior performance, with the smallest RxT model (12M parameters) achieving a perplexity of 2.74, significantly outperforming a 22M parameter stateless LLM baseline (perplexity 4.37). RxT enables economically viable, low-latency, stateful long-form conversations, offering a paradigm shift toward more interactive AI systems. |
| Natural Language Processing | Judging with Confidence: Calibrating Autoraters to Preference
  Distributions (Read more on [arXiv](https://arxiv.org/abs/2510.00263) or [HuggingFace](https://huggingface.co/papers/2510.00263))|  | This paper addresses the problem of discrete preference labels in autoraters, which overlooks the nuances of human judgment. The research aims to calibrate probabilistic autoraters to model the full preference distribution from a target population.  The paper introduces supervised fine-tuning and reinforcement learning methods to align autoraters with target preference distributions.  Results show that the proposed methods achieve an 18-51% reduction in Mean Squared Error (MSE) in alignment with target distributions.  The implication for AI practitioners is a more reliable and calibrated approach to autoraters, improving fairness, robustness, and risk management in alignment systems. |
| Reinforcement Learning | Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM
  Training (Read more on [arXiv](https://arxiv.org/abs/2510.04996) or [HuggingFace](https://huggingface.co/papers/2510.04996))|  | This paper introduces REINFORCE-ADA, an adaptive sampling framework to improve the stability and efficiency of reinforcement learning for large language models. The research aims to mitigate unstable gradient estimates due to uniform sampling by dynamically allocating inference budget to prompts based on uncertainty or learning potential. REINFORCE-ADA interleaves estimation and sampling in an online successive elimination process, forming fixed-size groups with enforced reward diversity and global advantage baselines. Empirical results across multiple model architectures and reasoning benchmarks demonstrate that REINFORCE-ADA accelerates convergence and improves final performance compared to GRPO, achieving up to a +2.3 average@32 improvement. The implication for AI practitioners is a more efficient and reliable method for reinforcement learning of reasoning-capable LLMs through variance-aware, adaptive data curation. |
| Machine Learning | Optimal Scaling Needs Optimal Norm (Read more on [arXiv](https://arxiv.org/abs/2510.03871) or [HuggingFace](https://huggingface.co/papers/2510.03871))| Stefan Kesselheim, Jan Ebert, Jiangtao Wang, Oleg Filatov | This paper investigates optimal hyperparameter scaling in large language models, unifying model and dataset scaling via the operator norm of the output layer. It explores the hypothesis that the optimal learning rate/batch size configuration maintains a constant output layer norm across varying model and dataset sizes. The methodology involves tracking layer norms across numerous experiments using the Scion optimizer, discovering a "norm transfer" phenomenon. Empirical results demonstrate a scaling rule of n*(B, D) × B^0.62 D^-0.56, and a finding that tuning per-layer-group learning rates improves model performance. The study implies that practitioners can leverage norm-guided scaling to optimize LLM training, suggesting norm transfer acts as a unifying invariant. |
| Machine Learning | Code4MeV2: a Research-oriented Code-completion Platform (Read more on [arXiv](https://arxiv.org/abs/2510.03755) or [HuggingFace](https://huggingface.co/papers/2510.03755))|  | The paper introduces Code4Me V2, an open-source, research-oriented code completion platform designed for JetBrains IDEs. The primary objective is to provide researchers with a transparent and controllable environment for studying human-AI interaction in software development. The platform uses a client-server architecture with a modular data collection framework, allowing fine-grained control over telemetry and context gathering. Experimental results show that Code4Me V2 achieves industry-comparable performance in code completion, with an average latency of 200ms. This platform enables AI practitioners to conduct reproducible research and large-scale data analysis in the field of AI-assisted software engineering. |
| Natural Language Processing | Self-Reflective Generation at Test Time (Read more on [arXiv](https://arxiv.org/abs/2510.02919) or [HuggingFace](https://huggingface.co/papers/2510.02919))| Shuang Qiu, Menglin Yang, Zhiyong Wang, Qixin Zhang, Jian Mu | This paper introduces Self-Reflective Generation at Test Time (SRGen), a lightweight framework that enhances the reliability of large language model reasoning. The research focuses on proactive error prevention by intervening at uncertain points during token generation using dynamic entropy thresholding. SRGen optimizes a corrective vector by retrospective context analysis to refine token probability distribution. Experiments on mathematical reasoning benchmarks demonstrate consistent improvement, with a 12% Pass@1 improvement on AIME2024 using DeepSeek-R1-Distill-Qwen-7B. SRGen provides a plug-and-play method to improve LLM reasoning by addressing the error amplification without introducing excessive computational costs. |
| Natural Language Processing | SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior
  Reasoning LLMs (Read more on [arXiv](https://arxiv.org/abs/2510.05069) or [HuggingFace](https://huggingface.co/papers/2510.05069))|  | The paper introduces SwiReasoning, a training-free framework for improving the reasoning capabilities of large language models (LLMs). It aims to enhance both accuracy and token efficiency by dynamically switching between explicit and latent reasoning modes. SwiReasoning uses block-wise confidence estimates based on entropy trends in next-token distributions to guide the switching, and a switch count controller to limit overthinking. Evaluations on mathematics and STEM benchmarks demonstrate consistent accuracy improvements of 1.5%-2.8% and token efficiency gains of 56%-79% across various LLMs. The framework offers AI practitioners a method to achieve Pareto-superior reasoning performance with existing LLMs without retraining. |
| Machine Learning | Agentic Context Engineering: Evolving Contexts for Self-Improving
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2510.04618) or [HuggingFace](https://huggingface.co/papers/2510.04618))| Fenglu Hong, Boyuan Ma, Shubhangi Upasani, Changran Hu, Qizheng Zhang | The paper introduces Agentic Context Engineering (ACE), a framework for automatically refining LLM contexts for improved agent and domain-specific reasoning. ACE treats contexts as evolving playbooks, iteratively accumulating and organizing strategies through generation, reflection, and curation. The framework aims to mitigate brevity bias and context collapse issues prevalent in existing context adaptation methods by using structured, incremental updates.  ACE optimizes contexts both offline and online, outperforming strong baselines by +10.6% on agents and +8.6% on finance tasks. ACE can adapt without labelled supervision, leveraging execution feedback and achieves 86.9% lower adaptation latency than existing methods, demonstrating its potential for scalable, efficient, and self-improving LLM systems. |
| Machine Learning | Watch and Learn: Learning to Use Computers from Online Videos (Read more on [arXiv](https://arxiv.org/abs/2510.04673) or [HuggingFace](https://huggingface.co/papers/2510.04673))| Oriana Riva, Yu Su, Palash Goyal, Yiwen Song, Chan Hee Song | This paper introduces Watch & Learn (W&L), a framework to convert online human demonstration videos into executable UI trajectories for training computer use agents (CUAs). The research aims to overcome the scarcity of high-quality training data for CUAs by using an inverse dynamics objective to predict user actions from screen states. W&L generates over 53k UI trajectories and, on the OSWorld benchmark, improves general-purpose models by up to 3 percentage points in-context and open-weight models by up to 11 percentage points under supervised training. Web-scale human demonstration videos can serve as a scalable foundation for advancing CUAs towards real-world deployment by providing practical training and in-context examples. |
| Computer Vision | ChronoEdit: Towards Temporal Reasoning for Image Editing and World
  Simulation (Read more on [arXiv](https://arxiv.org/abs/2510.04290) or [HuggingFace](https://huggingface.co/papers/2510.04290))|  | The paper introduces ChronoEdit, a framework for image editing that leverages temporal reasoning to ensure physical consistency, particularly for world simulation tasks. The research addresses the challenge of maintaining object coherence during image editing by reframing the task as video generation and introducing a temporal reasoning stage. ChronoEdit surpasses state-of-the-art baselines in both visual fidelity and physical plausibility on the introduced PBench-Edit benchmark, achieving an overall score of 4.43. The framework's use of video generative models and reasoning tokens enables more physically viable transformations. ChronoEdit provides AI practitioners a novel approach to image editing that ensures greater realism and coherence, which is critical in simulation-related applications. |
| Machine Learning | Front-Loading Reasoning: The Synergy between Pretraining and
  Post-Training Data (Read more on [arXiv](https://arxiv.org/abs/2510.03264) or [HuggingFace](https://huggingface.co/papers/2510.03264))|  | This paper investigates the optimal allocation of reasoning data across the pretraining and supervised fine-tuning (SFT) stages of large language models (LLMs). The core research question revolves around determining the best balance of reasoning data between these two phases to maximize downstream accuracy. The methodology involves systematically injecting reasoning data of varying scale, diversity, and quality into pretraining and SFT, followed by evaluation on reasoning benchmarks. The key finding reveals that front-loading reasoning data into pretraining is critical, yielding a 19% average gain, and pretraining benefits most from broad diversity (11% average gain) while SFT is more sensitive to data quality (15% average gain). The findings challenge the conventional separation of language modeling and reasoning, advocating for reasoning-aware pretraining for building more capable models. |
| Natural Language Processing | Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where? (Read more on [arXiv](https://arxiv.org/abs/2510.04434) or [HuggingFace](https://huggingface.co/papers/2510.04434))| Denis Peskoff, Jason Jewell, Adam Leif, Qingcheng Zeng, Grace LeFevre | This paper investigates the landscape of NLP for Social Good (NLP4SG) research, examining author and venue characteristics.  It aims to quantify NLP4SG work both within and outside the ACL community. The study uses a scientometric approach, augmenting a corpus with metadata on author affiliation, venue type, and social good relevance based on UN SDGs, classifying papers as ACL or non-ACL authored.  The results show that ACL authors are more likely to publish NLP4SG work outside of ACL venues, and a majority of NLP4SG work is conducted by non-ACL authors in external venues, with ACL authors being three times more likely to publish in external venues compared to internal. The findings highlight a need for agenda-setting considerations within the ACL community regarding support and recognition for NLP4SG research. |
| Natural Language Processing | Thai Semantic End-of-Turn Detection for Real-Time Voice Agents (Read more on [arXiv](https://arxiv.org/abs/2510.04016) or [HuggingFace](https://huggingface.co/papers/2510.04016))| Saksorn Ruangtanusak, Monthol Charattrakool, Natthapath Rungseesiripak, Thanapol Popit | The paper introduces the first systematic study of Thai text-only end-of-turn (EOT) detection for real-time voice agents. It addresses the need for low-latency EOT detection in Thai to improve human-computer interaction by comparing zero-shot/few-shot prompting of compact LLMs against fine-tuning of lightweight transformers. The methodology uses transcribed subtitles from the YODAS corpus and Thai-specific linguistic cues to formulate EOT as a binary decision over token boundaries. Primary results show a clear accuracy-latency trade-off, with a fine-tuned Llama3.2-Typhoon2-1B model achieving an F1-score of 0.881 with 110ms latency. This provides AI practitioners with optimized models and guidelines for implementing efficient, near-instant EOT decisions suitable for on-device applications in Thai voice agents. |
| Machine Learning | EvolProver: Advancing Automated Theorem Proving by Evolving Formalized
  Problems via Symmetry and Difficulty (Read more on [arXiv](https://arxiv.org/abs/2510.00732) or [HuggingFace](https://huggingface.co/papers/2510.00732))| Xuanwu Wang, Ruiyuan Huang, Yuchen Tian, danielhzlin, Ziyang | The paper introduces EvolProver, a novel data augmentation pipeline to enhance the robustness of formal theorem proving models. It addresses limitations in generalizability by evolving formalized problems via symmetry (syntactic and semantic) and difficulty using Abstract Syntax Trees and LLMs. EvolProver achieves a new state-of-the-art on FormalMATH-Lite with a 53.8% pass@32 rate, surpassing comparable models. The enhanced robustness implies improved generalizability for theorem proving models when trained with data augmented through symmetry and difficulty evolution, potentially impacting AI practitioners in formal reasoning and verification. |
| Machine Learning | Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the
  Rails (Read more on [arXiv](https://arxiv.org/abs/2510.04860) or [HuggingFace](https://huggingface.co/papers/2510.04860))| Xinyuan Liu, Wenbo Duan, Yaofeng Su, Jiaqi Liu, Siwei Han | This paper introduces the Alignment Tipping Process (ATP), a post-deployment risk where self-evolving LLM agents abandon alignment constraints in favor of self-interested strategies. The main objective is to identify and analyze ATP through Self-Interested Exploration and Imitative Strategy Diffusion paradigms. The methodology involves constructing controllable testbeds and benchmarking LLMs like Qwen3-8B and Llama-3.1-8B-Instruct under self-evolutionary settings. Experiments show alignment benefits erode rapidly, with violation rates increasing from 7.8% to 20.3% even under GRPO-aligned Llama-3.1-8B-Instruct after a few rounds of self-evolution. The implication for practitioners is that LLM alignment is not a static property and is vulnerable to feedback-driven decay during deployment. |
| Natural Language Processing | HiKE: Hierarchical Evaluation Framework for Korean-English
  Code-Switching Speech Recognition (Read more on [arXiv](https://arxiv.org/abs/2509.24613) or [HuggingFace](https://huggingface.co/papers/2509.24613))|  | The paper introduces HiKE, a hierarchical Korean-English code-switching speech recognition benchmark. It addresses the underexplored challenge of code-switching in multilingual ASR by providing a means for precise evaluation. The benchmark includes high-quality CS data, loanword labels, and hierarchical CS-level labeling (word, phrase, sentence). Evaluations show that while multilingual ASR models initially perform poorly on CS data, fine-tuning with synthetic CS data can improve performance; for Whisper-Medium, fine-tuning with synthetic data improves overall MER from 37.3 to 23.9. HiKE enables systematic analysis and improvement of CS-ASR capabilities for Korean-English, potentially applicable to other low-resource language pairs. |
| Natural Language Processing | LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL (Read more on [arXiv](https://arxiv.org/abs/2510.02350) or [HuggingFace](https://huggingface.co/papers/2510.02350))|  | The paper presents LLMSQL, an improved version of the WikiSQL dataset designed for the LLM era. It addresses structural and annotation issues in WikiSQL, such as case sensitivity inconsistencies and data type mismatches, to enhance its reliability and practical usability. The methodology involves automated methods for cleaning and re-annotation, along with manual corrections. Evaluation with multiple large language models showed that LLMSQL enables straightforward generation and evaluation for modern natural language-to-SQL models, with DeepSeek R1 achieving up to 88.4% execution accuracy. LLMSQL provides AI practitioners with a cleaner, validated benchmark for training and evaluating text-to-SQL systems, facilitating more transparent and reliable research. |
| Computer Vision | Character Mixing for Video Generation (Read more on [arXiv](https://arxiv.org/abs/2510.05093) or [HuggingFace](https://huggingface.co/papers/2510.05093))|  | The paper introduces a video generation framework for mixing characters from different visual styles and universes. It addresses the challenges of non-coexistence and style delusion through Cross-Character Embedding (CCE) and Cross-Character Augmentation (CCA). CCE learns identity and behavior, while CCA enriches training data with synthetic mixed-style examples. Experiments on a curated dataset demonstrate improved identity preservation and interaction quality. Specifically, the method achieves improved VLM Identity-P and Style-P compared to baselines, enabling natural character interactions; the exact values are unclear. |
| Computer Vision | SAEdit: Token-level control for continuous image editing via Sparse
  AutoEncoder (Read more on [arXiv](https://arxiv.org/abs/2510.05081) or [HuggingFace](https://huggingface.co/papers/2510.05081))| Or Patashnik, Roni Paiss, Daniel Garibi, Sara Dorfman, Ronen Kamenetsky | The paper introduces SAEdit, a novel method for continuous and disentangled image editing via token-level manipulation of text embeddings. It addresses the challenge of achieving fine-grained control over semantic attributes in text-to-image models. The method uses a Sparse AutoEncoder (SAE) to identify disentangled semantic directions in the text embedding space and manipulates embeddings along these directions to control the strength of target attributes. Experiments demonstrate high preservation and a delta improvement between the VQA score of the edited image to the source image, and results show that it enables intuitive manipulations across diverse attributes and domains. SAEdit offers a model-agnostic approach, applicable to various image synthesis backbones, allowing AI practitioners to perform controlled and continuous image editing without task-specific training. |
| Reinforcement Learning | Learning on the Job: Test-Time Curricula for Targeted Reinforcement
  Learning (Read more on [arXiv](https://arxiv.org/abs/2510.04786) or [HuggingFace](https://huggingface.co/papers/2510.04786))|  | This paper introduces Test-Time Curricula for Reinforcement Learning (TTC-RL), an agent that assembles task-specific curricula to continue training a model for its target task. The research explores continual improvement of LLMs in reasoning by applying RL on automatically selected task-relevant data. TTC-RL selects data from a large pool, avoiding human curation, and applies GRPO to update model weights. Experiments show that TTC-RL improves the pass@1 of Qwen3-8B by 1.8x on AIME25 and 2.1x on CodeElo, indicating an improvement in the performance ceiling. The findings suggest that test-time curricula have potential for extending the test-time scaling paradigm for continual training. |
| Machine Learning | Utility-Learning Tension in Self-Modifying Agents (Read more on [arXiv](https://arxiv.org/abs/2510.04399) or [HuggingFace](https://huggingface.co/papers/2510.04399))| Peter Jin, Keir Dorchen, Charles L. Wang | This paper investigates the learnability of self-modifying agents, identifying a tension between utility-driven changes and the preconditions for reliable learning. It examines when rational self-changes preserve or destroy learning capabilities using a five-axis decomposition of agent architecture. The authors prove that distribution-free PAC guarantees are preserved if and only if the policy-reachable family has a uniformly bounded capacity, using VC dimension as the capacity measure. They introduce a Two-Gate guardrail that ensures monotone true-risk steps, and numerical experiments validate their findings by comparing destructive utility policies against their proposed policies. The implication is that AI practitioners must carefully control capacity growth during self-modification to maintain generalization guarantees. |
| Natural Language Processing | Epistemic Diversity and Knowledge Collapse in Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2510.04226) or [HuggingFace](https://huggingface.co/papers/2510.04226))|  | This paper investigates knowledge collapse in large language models (LLMs) by measuring epistemic diversity in generated outputs. The research examines how the diversity of claims produced by 27 LLMs across 155 topics is affected by model size, architecture, and generation settings. Epistemic diversity is quantified using Hill-Shannon diversity (HSD) on clustered claims extracted from LLM outputs. The study finds that smaller models and retrieval-augmented generation (RAG) positively impact diversity, while larger models negatively impact diversity; however, diversity generally remains lower than a rudimentary web search. The findings suggest a need to prevent LLMs and their RAG databases from becoming dominated by homogenizing content. |
| Multi-Modal | MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition (Read more on [arXiv](https://arxiv.org/abs/2510.04136) or [HuggingFace](https://huggingface.co/papers/2510.04136))|  | The paper introduces MoME, a Mixture of Matryoshka Experts framework for resource-aware audio-visual speech recognition. It addresses the limitations of token granularity in LLMs for AVSR by integrating sparse Mixture-of-Experts (MoE) into Matryoshka representation learning, enabling dynamic allocation of computational capacity across scales and modalities. The key method involves augmenting a frozen LLM with top-k routed and shared experts and a shared router that promotes consistent expert activation across granularities. Experiments on LRS2 and LRS3 demonstrate that MoME achieves state-of-the-art performance across AVSR, ASR, and VSR tasks, attaining WER results of 1.5% on LRS3 while reducing parameter usage. MoME unifies the adaptability of MRL with the efficiency of MoE, offering a scalable and interpretable solution for resource-aware speech recognition, thus providing practitioners with a flexible tool for optimizing AVSR models under various resource constraints. |
| Reinforcement Learning | AdvEvo-MARL: Shaping Internalized Safety through Adversarial
  Co-Evolution in Multi-Agent Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2510.01586) or [HuggingFace](https://huggingface.co/papers/2510.01586))| Zeliang Zhang, Yolo Yunlong Tang, Zhuo Liu, Yiting Zhang, Zhenyu Pan | The paper introduces AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learning framework for internalizing safety into task agents by adversarially training them against evolving jailbreak prompts.  The research aims to improve the safety and utility of multi-agent systems without relying on external guard modules. AdvEvo-MARL jointly optimizes attackers (jailbreak prompts) and defenders (task agents) within an adversarial learning environment using a public baseline for advantage estimation to stabilize learning. Experiments demonstrate that AdvEvo-MARL consistently keeps attack-success rate (ASR) below 20% while preserving or improving task accuracy, achieving up to +3.67% accuracy on reasoning tasks. The framework offers AI practitioners a method to jointly improve system safety and task performance without adding system overhead. |
| Natural Language Processing | Graph2Eval: Automatic Multimodal Task Generation for Agents via
  Knowledge Graphs (Read more on [arXiv](https://arxiv.org/abs/2510.00507) or [HuggingFace](https://huggingface.co/papers/2510.00507))| Zeyi Liao, Ziqi Wang, Yuhan Liu, Xavier Hu, Yurun Chen | The paper introduces Graph2Eval, a knowledge graph-based framework for automatically generating multimodal tasks to evaluate agents' reasoning, collaboration, and interactive capabilities. It addresses the limitations of static datasets by constructing knowledge graphs from multi-source data and translating semantic relations into structured tasks via subgraph sampling and task templates. The methodology involves a multi-stage filtering pipeline based on node reachability, LLM scoring, and similarity analysis to ensure task quality and executability. Experiments on Graph2Eval-Bench, a curated dataset of 1,319 tasks, show that Graph2Eval effectively differentiates agent and model performance, revealing gaps in reasoning, collaboration, and web interaction. This provides AI practitioners with a novel perspective for evaluating agents in dynamic environments and complex scenarios. |
