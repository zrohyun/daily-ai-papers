

## Papers for 2025-10-01

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Multi-Modal | Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified
  Self-Play (Read more on [arXiv](https://arxiv.org/abs/2509.25541) or [HuggingFace](https://huggingface.co/papers/2509.25541))| Jing Shi, Qinsi Wang, timecuriosity, zhoutianyi, Benjamin-eecs | The paper presents Vision-Zero, a domain-agnostic framework for vision-language model (VLM) self-improvement via competitive visual games generated from arbitrary image pairs. It addresses the high training costs and dependency on labor-intensive datasets by enabling VLMs to autonomously generate training data through strategic self-play in "Who Is the Spy?"-style games. The key methodology involves Iterative Self-Play Policy Optimization (Iterative-SPO), alternating between self-play and reinforcement learning with verifiable rewards (RLVR). Vision-Zero achieves state-of-the-art performance on reasoning, chart question answering, and vision-centric understanding tasks, surpassing annotation-based methods and achieving a 3% performance increase on the MathVision validation set compared to a baseline model. The main implication is a scalable and cost-effective approach to VLM self-improvement without reliance on human-annotated data, facilitating broader adoption and exploration of VLM capabilities. |
| Natural Language Processing | MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP
  Use (Read more on [arXiv](https://arxiv.org/abs/2509.24002) or [HuggingFace](https://huggingface.co/papers/2509.24002))|  | MCPMark is a new benchmark designed to stress-test the use of Model Context Protocol (MCP) in realistic and comprehensive workflows. The benchmark aims to address the limitations of existing MCP benchmarks by incorporating tasks with richer interactions and a broader range of CRUD operations. The authors create 127 high-quality tasks across five MCP environments (Notion, GitHub, Filesystem, PostgreSQL, and Playwright) with programmatic verification. Evaluation of cutting-edge LLMs reveals that the best-performing model, gpt-5-medium, achieves only 52.56% pass@1, highlighting the challenging nature of the benchmark. The results imply that current LLMs struggle with the complexity and realism required for effective MCP use in real-world applications. |
| Machine Learning | The Dragon Hatchling: The Missing Link between the Transformer and
  Models of the Brain (Read more on [arXiv](https://arxiv.org/abs/2509.26507) or [HuggingFace](https://huggingface.co/papers/2509.26507))|  | The paper introduces 'Dragon Hatchling' (BDH), a new Large Language Model architecture inspired by biological neural networks. The research aims to bridge the gap between Transformer architectures and brain models by creating a biologically plausible and interpretable architecture without sacrificing performance. BDH uses a scale-free network of locally-interacting neuron particles and admits a GPU-friendly formulation. Empirically, BDH rivals GPT2-architecture Transformer performance on language and translation tasks for parameter counts from 10M to 1B. BDH offers interpretability and potential for better generalization and reasoning over time, while being biologically plausible. |
| Natural Language Processing | TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2509.25760) or [HuggingFace](https://huggingface.co/papers/2509.25760))|  | The paper introduces TruthRL, a reinforcement learning framework for improving the truthfulness of large language models (LLMs). The research aims to directly optimize truthfulness by incentivizing correct answers, abstentions when uncertain, and penalizing hallucinations. TruthRL utilizes GRPO with a ternary reward system, achieving a 28.9% reduction in hallucinations and a 21.1% improvement in truthfulness on knowledge-intensive benchmarks. The framework enhances LLMs' ability to recognize knowledge boundaries, promoting more reliable and trustworthy responses for various AI applications. |
| Reinforcement Learning | OceanGym: A Benchmark Environment for Underwater Embodied Agents (Read more on [arXiv](https://arxiv.org/abs/2509.26536) or [HuggingFace](https://huggingface.co/papers/2509.26536))|  | The paper introduces OceanGym, a benchmark environment for underwater embodied agents to advance AI in challenging real-world settings. It aims to address the limitations of current AI agents in underwater environments characterized by perceptual and decision-making difficulties. The methodology involves creating eight realistic task domains and a unified agent framework driven by Multi-modal Large Language Models (MLLMs), integrating perception, memory, and decision-making. Experiments show substantial gaps between state-of-the-art MLLM-driven agents and human experts, with decision-making success rates dropping to 14.8% under low-visibility conditions. OceanGym provides a high-fidelity platform for developing robust embodied AI and transferring capabilities to autonomous underwater vehicles, facilitating research in perception, planning, and adaptability in complex marine environments. |
| Computer Vision | DC-VideoGen: Efficient Video Generation with Deep Compression Video
  Autoencoder (Read more on [arXiv](https://arxiv.org/abs/2509.25182) or [HuggingFace](https://huggingface.co/papers/2509.25182))|  | DC-VideoGen is a post-training acceleration framework for efficient video generation. The paper aims to improve the efficiency of video diffusion models by adapting them to a deep compression latent space. It introduces a Deep Compression Video Autoencoder (DC-AE-V) with chunk-causal temporal design and an adaptation strategy (AE-Adapt-V) for pre-trained models. The accelerated models achieve up to 14.8x lower inference latency than base models without compromising quality. The framework enables higher resolution video generation on resource-constrained devices, expanding accessibility for AI practitioners. |
| Natural Language Processing | Who's Your Judge? On the Detectability of LLM-Generated Judgments (Read more on [arXiv](https://arxiv.org/abs/2509.25154) or [HuggingFace](https://huggingface.co/papers/2509.25154))|  | This paper introduces the task of detecting LLM-generated judgments and proposes J-Detector, a lightweight neural detector augmented with linguistic and LLM-enhanced features. The research investigates the detectability of LLM-generated judgments based on judgment scores and candidate content, unlike LLM-generated text detection. J-Detector outperforms existing methods across diverse datasets, achieving a F1 score of 99.8% on XGB for Helpsteer2 compared to baselines. The study highlights the importance of considering judgment-candidate interactions for effective detection, with bias quantification for understanding biases of LLM judges. The research implies that LLM-generated judgment detection provides a safeguard for ensuring fairness and accountability in LLM-as-a-judge systems. |
| Multi-Modal | Learning to See Before Seeing: Demystifying LLM Visual Priors from
  Language Pre-training (Read more on [arXiv](https://arxiv.org/abs/2509.26625) or [HuggingFace](https://huggingface.co/papers/2509.26625))| Koustuv Sinha, Yufan Ren, David Fan, Shengbang Tong, Junlin Han | This paper demystifies the origin and structure of visual priors in large language models (LLMs) acquired during pre-training. It investigates whether these priors are composed of separable perception and reasoning abilities with distinct scaling trends and origins. The methodology involves controlled experiments across five model scales, various data categories, and adaptation setups, consuming 500,000 GPU-hours. The study reveals that LLM's visual reasoning ability is predominantly developed by pre-training on reasoning-centric data, while perception prior emerges more diffusely from broad corpora; additionally, an MLE-Bench is introduced for analyzing multi-level existence. The work provides a data-centric recipe for pre-training vision-aware LLMs, paving the way for improved multimodal LLMs by deliberately cultivating visual priors from language pre-training. |
| Natural Language Processing | Thinking Sparks!: Emergent Attention Heads in Reasoning Models During
  Post Training (Read more on [arXiv](https://arxiv.org/abs/2509.25758) or [HuggingFace](https://huggingface.co/papers/2509.25758))|  | This paper investigates the emergence of specialized attention heads in large reasoning models (LRMs) after post-training, using circuit analysis. The study examines Qwen families and DeepSeek-distilled models, revealing that SFT and distillation foster cumulative addition of stable reasoning heads, while GRPO operates through dynamic head pruning guided by reward signals. Ablation studies connect circuit-level dynamics to performance tradeoffs, showing strengthened heads improve performance on complex problems but introduce "over-thinking" on simpler tasks. The findings highlight a tension between complex reasoning and elementary computation, suggesting a need for balanced training strategies. This work provides insights for training policy design, emphasizing the need for effective reasoning with reliable execution. |
| Natural Language Processing | Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token
  Pruning for Efficient Supervised Fine-Tuning (Read more on [arXiv](https://arxiv.org/abs/2509.23873) or [HuggingFace](https://huggingface.co/papers/2509.23873))| Yue Min, Cong Wang, JiajunZhang, Jessamine, Steven-Shaobo | The paper presents a unified approach to joint sample and token pruning for efficient supervised fine-tuning (SFT) of large language models. It aims to maximize data utility under budget constraints by addressing the fragmented design of existing pruning strategies. The proposed method, Quadrant-based Tuning (Q-Tuning), utilizes an Error-Uncertainty (EU) Plane to strategically coordinate sample and token pruning. Q-Tuning achieves a +38% average improvement over full-data SFT baselines using only 12.5% of the original training data on SmolLM2-1.7B. This approach offers a practical blueprint for maximizing data utilization in budget-constrained LLM SFT. |
| Natural Language Processing | VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in
  Real-world Applications (Read more on [arXiv](https://arxiv.org/abs/2509.26490) or [HuggingFace](https://huggingface.co/papers/2509.26490))|  | The paper introduces VitaBench, a challenging benchmark for evaluating LLM agents on versatile interactive tasks in real-world applications. It addresses the gap between existing benchmarks and the complexity of real-life scenarios by focusing on reasoning, tool use, and interaction complexities. The methodology involves a life-serving simulation environment with 66 tools across delivery, in-store, and travel domains, enabling flexible task composition. Evaluation reveals that even advanced models achieve only 30% success on cross-scenario tasks and less than 50% on others.  VitaBench offers a resource for advancing AI agents' development by providing a more realistic and comprehensive assessment of their capabilities. |
| Natural Language Processing | dParallel: Learnable Parallel Decoding for dLLMs (Read more on [arXiv](https://arxiv.org/abs/2509.26488) or [HuggingFace](https://huggingface.co/papers/2509.26488))|  | The paper introduces dParallel, a method to accelerate parallel decoding in diffusion large language models (dLLMs). It aims to address the sequential certainty convergence bottleneck hindering parallel token prediction. The method employs certainty-forcing distillation to enforce rapid certainty on masked tokens while maintaining trajectory consistency. Experiments on GSM8K show dParallel reduces decoding steps from 256 to 30, achieving an 8.5x speedup with preserved accuracy. This enables AI practitioners to significantly reduce the inference latency of dLLMs without compromising performance. |
| Computer Vision | IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance (Read more on [arXiv](https://arxiv.org/abs/2509.26231) or [HuggingFace](https://huggingface.co/papers/2509.26231))|  | The paper introduces Implicit Multimodal Guidance (IMG), a novel re-generation-based framework for calibrating diffusion models to improve multimodal alignment. The research aims to address misalignment issues between prompts and generated images in diffusion models without requiring extra data or editing operations. IMG employs a multimodal large language model to identify misalignments and introduces an Implicit Aligner to refine diffusion conditioning features through an Iteratively Updated Preference Objective. Evaluations on SDXL show that IMG outperforms existing methods, achieving an 84.6% win rate over the base model. This framework offers AI practitioners an effective plug-and-play adapter to enhance the alignment of diffusion models. |
| Computer Vision | MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation (Read more on [arXiv](https://arxiv.org/abs/2509.26391) or [HuggingFace](https://huggingface.co/papers/2509.26391))| Limin Wang, Gangshan Wu, Yilu Wu, wangsssssss, flateon | The paper introduces MotionRAG, a retrieval-augmented framework to enhance motion realism in image-to-video generation. The research aims to improve physically plausible motion by adapting motion priors from relevant reference videos through Context-Aware Motion Adaptation (CAMA). The key methodology involves a retrieval pipeline, in-context learning using a causal transformer, and an attention-based motion injection adapter. Experiments on the OpenVid-1K dataset demonstrate that MotionRAG achieves a substantial improvement in Action Score (65.8) over baselines. MotionRAG offers AI practitioners a plug-and-play module to improve temporal dynamics in generated videos with minimal computational overhead and zero-shot generalization. |
| Multi-Modal | Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and
  Multi-Scale Global-Local Attention (Read more on [arXiv](https://arxiv.org/abs/2509.23610) or [HuggingFace](https://huggingface.co/papers/2509.23610))|  | The paper introduces Dolphin, an efficient audio-visual speech separation (AVSS) method. It aims to reduce the computational cost associated with existing AVSS models while maintaining high separation quality. Dolphin employs a dual-path lightweight video encoder (DP-LipCoder) to transform lip-motion into discrete audio-aligned semantic tokens and a lightweight encoder-decoder separator with global-local attention (GLA). Experiments on three benchmark datasets demonstrate that Dolphin achieves state-of-the-art separation quality with over 50% fewer parameters and more than 2.4x reduction in MACs compared to existing methods. This enables practical deployment of AVSS in resource-constrained environments. |
| Reinforcement Learning | Mem-α: Learning Memory Construction via Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2509.25911) or [HuggingFace](https://huggingface.co/papers/2509.25911))| Yuzhen Mao, Ryuichi Takanobu, Yu Wang, ai-hyz, zkadelzq | The paper introduces Mem-α, a reinforcement learning framework for training agents to manage complex memory systems for LLMs. It addresses the limitation of LLMs' context windows by enabling agents to learn effective memory management strategies through interaction and feedback. Mem-α trains agents to extract, store, and update memory components using a reward signal derived from downstream question-answering accuracy. Experiments show Mem-α achieves significant improvements over baselines, generalizing to sequences exceeding 400k tokens despite training only on 30k token instances, with an increase in performance metrics such as F1/Accuracy of up to 0.642. The research implies that RL can effectively enhance long-context retention in memory-augmented LLMs. |
| Computer Vision | Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal
  LLMs (Read more on [arXiv](https://arxiv.org/abs/2509.22646) or [HuggingFace](https://huggingface.co/papers/2509.22646))|  | This paper introduces DEEPTRACEREWARD, a benchmark for detecting human-perceived fakeness in AI-generated videos using grounded visual artifacts. The research investigates whether humans can detect deepfake traces and provide reasons, addressing the overlooked dimension of human perception in video generation. They annotate 3.3K generated videos with 4.3K detailed annotations providing explanations, bounding boxes, and timestamps.  A 7B reward model trained on this dataset outperforms GPT-5 by 34.7% in fake clue identification, grounding, and explanation. The study highlights a difficulty gradient and underscores the importance of human-perceived traces for socially aware video generation. |
| Reinforcement Learning | Attention as a Compass: Efficient Exploration for Process-Supervised RL
  in Reasoning Models (Read more on [arXiv](https://arxiv.org/abs/2509.26628) or [HuggingFace](https://huggingface.co/papers/2509.26628))|  | The paper introduces AttnRL, a novel Process-Supervised Reinforcement Learning (PSRL) framework for enhancing reasoning models. It addresses the limitations of existing PSRL approaches by improving exploration efficiency through attention-based branching and adaptive sampling strategies. AttnRL branches at steps with high attention scores and uses an adaptive sampling strategy that considers problem difficulty and historical batch size. The approach improves sampling and training efficiency, consistently outperforming prior approaches on multiple mathematical reasoning benchmarks. Experimental results demonstrated a 7.5% average improvement across six benchmarks compared to the base model. |
| Computer Vision | DA^2: Depth Anything in Any Direction (Read more on [arXiv](https://arxiv.org/abs/2509.26618) or [HuggingFace](https://huggingface.co/papers/2509.26618))|  | DA^2: Depth Anything in Any Direction introduces a zero-shot generalizable panoramic depth estimation model. The research aims to address the limitations of existing methods in panoramic depth estimation due to data scarcity and spherical distortions. DA^2 employs a data curation engine to generate a large-scale panoramic dataset from perspective images and introduces SphereViT, a novel architecture leveraging spherical coordinates to mitigate distortions. Evaluation demonstrates state-of-the-art performance, with an average 38% improvement in AbsRel error over previous zero-shot methods. This enables AI practitioners to use a single model for robust 360° depth estimation across diverse scenes without task-specific training. |
| Natural Language Processing | DeepScientist: Advancing Frontier-Pushing Scientific Findings
  Progressively (Read more on [arXiv](https://arxiv.org/abs/2509.26603) or [HuggingFace](https://huggingface.co/papers/2509.26603))|  | The paper introduces DeepScientist, an AI system designed for goal-oriented, fully autonomous scientific discovery in NLP. It aims to overcome the limitations of previous AI scientist systems by focusing on producing scientifically valuable contributions to address pressing human-defined challenges via a Bayesian Optimization approach consisting of hypothesize, verify, and analyze stages. The key methodology involves leveraging a cumulative Findings Memory to intelligently balance exploration and exploitation. The system surpasses human-designed SOTA methods on three frontier AI tasks by 183.7%, 1.9%, and 7.9%. This demonstrates the potential for AI to progressively surpass human SOTA in scientific tasks. |
| Natural Language Processing | OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost
  Always! (Read more on [arXiv](https://arxiv.org/abs/2509.26495) or [HuggingFace](https://huggingface.co/papers/2509.26495))|  | The paper introduces "operational safety" for LLMs, defined as the ability to appropriately accept or refuse user queries based on a specific task. The research question is whether LLM-based agents are safe for their intended use case, considering operational safety. The methodology involves creating a benchmark, OFFTOPICEVAL, to evaluate LLMs on their ability to refuse out-of-domain queries while accepting in-domain queries. Results show that even the strongest models achieve only 77.77% (Qwen-3 235B) and 79.96% (Mistral 24B) operational safety, indicating significant risks. This implies AI practitioners must urgently address operational safety interventions in LLM-based agents to ensure reliable performance. |
| Natural Language Processing | A Cartography of Open Collaboration in Open Source AI: Mapping
  Practices, Motivations, and Governance in 14 Open Large Language Model
  Projects (Read more on [arXiv](https://arxiv.org/abs/2509.25397) or [HuggingFace](https://huggingface.co/papers/2509.25397))| Jennifer Ding, Cailean Osborne, Johan Linåker, burtenshaw | This paper maps open collaboration practices in open source AI, focusing on 14 large language model (LLM) projects. It explores collaboration methods, motivations, and governance structures throughout the LLM lifecycle via semi-structured interviews with 17 developers. The study finds that open collaboration extends beyond LLMs to datasets and frameworks, driven by diverse social, economic, and technological motivations; the projects exhibit five distinct organizational models. The research identifies collaboration on-ramps and challenges at each stage, providing practical recommendations for fostering a global open AI community. It shows 1% of models account for 99% of downloads, the reuse is highly concentrated, and the need for guidelines that improve community engagement strategies throughout the open LLM lifecycle. |
| Machine Learning | Regression Language Models for Code (Read more on [arXiv](https://arxiv.org/abs/2509.26476) or [HuggingFace](https://huggingface.co/papers/2509.26476))|  | This paper presents a Regression Language Model (RLM) for predicting numeric outcomes of code executions across various programming languages and tasks. The research explores whether a unified RLM can replace domain-specific feature engineering for code-to-metric regression. The methodology involves training a T5Gemma-initialized RLM on a diverse dataset of code snippets, GPU kernels, and ONNX neural network representations. The RLM achieves >0.9 Spearman-rank on APPS and >0.5 average Spearman-rank across 17 languages from CodeNet, demonstrating its general applicability and competitive performance compared to specialized methods. The success of RLMs implies that complex computational graph regression can be simplified into a next-token prediction problem, potentially streamlining performance prediction and static analysis in AI workflows. |
| Natural Language Processing | InfoAgent: Advancing Autonomous Information-Seeking Agents (Read more on [arXiv](https://arxiv.org/abs/2509.25189) or [HuggingFace](https://huggingface.co/papers/2509.25189))|  | The paper introduces InfoAgent, a novel deep research agent for autonomous information seeking, enhancing LLMs' capabilities using external tools. The research aims to improve data synthesis and establish an efficient interactive environment for training such agents. InfoAgent employs an innovative data synthesis pipeline with entity trees and subtree sampling, coupled with a self-hosted search infrastructure and a two-stage post-training recipe involving supervised finetuning and reinforcement learning. InfoAgent achieves 15.3% accuracy on BrowseComp, outperforming existing open-source DRAs. This work demonstrates the feasibility of building high-performance information-seeking agents with open-source resources, reducing reliance on commercial APIs and offering avenues for further agent advancement. |
| Machine Learning | Humanline: Online Alignment as Perceptual Loss (Read more on [arXiv](https://arxiv.org/abs/2509.24207) or [HuggingFace](https://huggingface.co/papers/2509.24207))|  | This paper introduces Humanline, a method to align generative models by incorporating human perceptual biases. The research aims to explain the superior performance of online alignment (e.g., GRPO) over offline alignment (e.g., DPO) by leveraging prospect theory. The proposed technique modifies alignment objectives like DPO/KTO/GRPO by syncing reference models and asymmetrically clipping log-probability ratios. Experiments show that Humanline variants, even when trained with offline data, can match the performance of online counterparts, achieving up to 1.6x better win rates on instruction-following tasks.  Humanline offers practitioners a flexible approach for sourcing training data, potentially accelerating and reducing the cost of aligning LLMs with human preferences. |
| Multi-Modal | Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents (Read more on [arXiv](https://arxiv.org/abs/2509.26539) or [HuggingFace](https://huggingface.co/papers/2509.26539))|  | This paper presents Ferret-UI Lite, a compact 3B parameter end-to-end GUI agent for on-device deployment across mobile, web, and desktop platforms. The research focuses on developing strategies for building strong small GUI agents, specifically GUI grounding and navigation, targeting on-device deployment. The methodology involves curating diverse GUI data, implementing visual tool-use with image cropping, and applying a two-stage SFT and RL training strategy. Ferret-UI Lite achieves a 53.3% accuracy on the ScreenSpot-Pro GUI grounding benchmark, outperforming larger models of the same size, though navigation performance remains limited. The work provides guidance for developing effective on-device GUI agents by carefully balancing real and synthetic data, optimizing inference techniques, and using verifiable rewards in reinforcement learning. |
| Multi-Modal | More Thought, Less Accuracy? On the Dual Nature of Reasoning in
  Vision-Language Models (Read more on [arXiv](https://arxiv.org/abs/2509.25848) or [HuggingFace](https://huggingface.co/papers/2509.25848))| Fabian Waschkowski, Mengqi He, Zhaoyuan Yang, Shu Zou, Xinyu Tian | This paper investigates the dual nature of reasoning in Vision-Language Models (VLMs), uncovering a trade-off between logical inference and perceptual accuracy. The research question addresses how reasoning affects accuracy in VLMs, revealing that extended reasoning can impair visual grounding, leading to visual forgetting. To mitigate this, the paper introduces VISION-ANCHORED POLICY OPTIMIZATION (VAPO), which steers reasoning toward visually grounded trajectories.  Experiments demonstrate that VAPO-Thinker-7B achieves new state-of-the-art results, improving average gains of 2-4% over strong baselines. The findings imply that AI practitioners need to address visual forgetting when incorporating reasoning into VLMs to enhance performance across a wide range of benchmarks. |
| Natural Language Processing | Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with
  LLMs (Read more on [arXiv](https://arxiv.org/abs/2509.23166) or [HuggingFace](https://huggingface.co/papers/2509.23166))| Yao Shu, Fei Yu, Ying He, Hong Wang, Chenxing Wei | The paper introduces Test-Time Policy Adaptation for Multi-Turn Interactions (T²PAM), a new paradigm to improve LLMs in extended conversations. It addresses the limitation of LLMs trained on static, single-turn data, which degrades performance in multi-turn interactions by enabling real-time adaptation to user feedback. The proposed method, Optimum-Referenced One-Step Adaptation (ROSA), estimates a latent optimal policy aligned with user preferences using feedback as a reward signal and efficiently updates a small subset of parameters. Experiments on challenging benchmarks demonstrated that ROSA achieves significant improvements in both task effectiveness and efficiency; for instance, ROSA improved accuracy by up to 25.8% on the MATH dataset compared to the baseline. T²PAM and ROSA offer a practical approach for practitioners to enhance LLMs' conversational capabilities by dynamically adjusting model behavior during interactions. |
| Reinforcement Learning | Benefits and Pitfalls of Reinforcement Learning for Language Model
  Planning: A Theoretical Perspective (Read more on [arXiv](https://arxiv.org/abs/2509.22613) or [HuggingFace](https://huggingface.co/papers/2509.22613))|  | This paper theoretically analyzes the benefits and pitfalls of using reinforcement learning (RL) for language model planning compared to supervised fine-tuning (SFT). It examines policy gradient (PG) and Q-learning methods using a graph-based abstraction to model planning. The research investigates the trade-offs between exploration, diversity, and reward hacking in RL-based language model planning. Results show PG suffers from diversity collapse, while Q-learning better preserves diversity and enables off-policy learning, provided careful reward design prevents hacking; experiments on Blocksworld validate these behaviors. The analysis provides insights into designing more robust and scalable RL methods for language model planning. |
| Multi-Modal | TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics (Read more on [arXiv](https://arxiv.org/abs/2509.26329) or [HuggingFace](https://huggingface.co/papers/2509.26329))| Szu-Chi Chen, Yueh-Hsuan Huang, Jia-Kai Dong, Yu-Hua Chen, Yi-Cheng Lin | The paper introduces TAU, a benchmark for evaluating cultural sound understanding beyond semantics in LALMs. It investigates whether current LALMs generalize to localized, non-semantic audio cues instantly recognizable by locals but not outsiders. The methodology involves creating a dataset of Taiwanese soundmarks and evaluating LALMs using multiple-choice questions that cannot be answered by transcripts alone. Experiments show that state-of-the-art LALMs, including Gemini 2.5, perform far below human levels, achieving only around 72% accuracy compared to human performance exceeding 80%. The findings suggest the need for localized benchmarks to reveal cultural blind spots and guide more equitable multimodal evaluation. |
| Machine Learning | EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series
  Forecasting (Read more on [arXiv](https://arxiv.org/abs/2509.26157) or [HuggingFace](https://huggingface.co/papers/2509.26157))|  | The paper introduces EntroPE, an entropy-guided dynamic patch encoder for time series forecasting, addressing limitations in temporally-agnostic patch construction. EntroPE dynamically detects temporal transition points via conditional entropy to create more coherent patches, aiming to improve long-horizon forecasting accuracy and efficiency. The methodology involves an entropy-based dynamic patcher (EDP) and an adaptive patch encoder (APE) which leverages pooling and cross-attention to produce fixed-size latent representations. Experiments on long-term forecasting benchmarks demonstrate that EntroPE improves accuracy and efficiency, achieving approximately 20% accuracy gains on ETTh1 compared to PatchTST. EntroPE establishes a new paradigm for time series modeling, suggesting that entropy-guided dynamic patching offers a practical and generalizable approach for enhancing transformer-based architectures. |
| Computer Vision | VisualOverload: Probing Visual Understanding of VLMs in Really Dense
  Scenes (Read more on [arXiv](https://arxiv.org/abs/2509.25339) or [HuggingFace](https://huggingface.co/papers/2509.25339))| Muhammad Huzaifa, Soumya Jahagirdar, M. Jehanzeb Mirza, Wei Lin, Paul Gavrikov | The paper introduces VisualOverload, a new VQA benchmark to evaluate VLMs' visual understanding in densely populated scenes. The research investigates whether state-of-the-art VLMs can perform simple vision tasks in visually complex scenarios. They manually curated a dataset of high-resolution scans of public-domain paintings with corresponding questions spanning six task categories. Evaluation of 37 VLMs revealed that the best model achieved only 19.6% accuracy on the hardest test split, exposing limitations in fine-grained recognition and logical consistency. The benchmark and error analysis provide insights for developing more robust vision models capable of handling complex, detail-rich visual environments. |
| Computer Vision | TTT3R: 3D Reconstruction as Test-Time Training (Read more on [arXiv](https://arxiv.org/abs/2509.26645) or [HuggingFace](https://huggingface.co/papers/2509.26645))| Anpei Chen, Andreas Geiger, Yuliang Xiu, Yue Chen, rover-xingyu | The paper introduces TTT3R, a novel test-time training approach for 3D reconstruction to enhance length generalization in recurrent neural networks. It addresses the issue of performance degradation with increasing input views by framing 3D reconstruction as an online learning problem. TTT3R leverages alignment confidence between memory states and new observations to derive a closed-form learning rate for memory updates. The method achieves a 2x improvement in global pose estimation over baselines while maintaining 20 FPS using 6GB of GPU memory. TTT3R offers practitioners a training-free intervention to substantially improve the scalability and memory retention of 3D reconstruction models. |
| Machine Learning | Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics
  Research Benchmark (Read more on [arXiv](https://arxiv.org/abs/2509.26574) or [HuggingFace](https://huggingface.co/papers/2509.26574))| Penghao Zhu, Tianci Zhou, Xiaocheng Yang, Minyang Tian, Minhui Zhu | This paper introduces CritPt, a new benchmark for evaluating AI reasoning capabilities in frontier physics research. The primary objective is to assess whether LLMs can effectively solve complex, open-ended physics problems at the research level. CritPt comprises 71 research challenges and 190 checkpoints, evaluated using a physics-informed auto-grading pipeline. Results show that current LLMs achieve only 4.0% average accuracy on full challenges, rising to 11.7% with coding tools, indicating a significant gap between AI capabilities and realistic physics research needs. The implication is that current LLMs are not yet reliable for complex physics research, highlighting the need for scientifically grounded AI tools. |
| Natural Language Processing | Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced
  Performance Gap (Read more on [arXiv](https://arxiv.org/abs/2509.26542) or [HuggingFace](https://huggingface.co/papers/2509.26542))| Hengfan Zhang, Yudong Liu, Qinsi Wang, Zhengmian Hu, linyueqian | The paper introduces Voice Evaluation of Reasoning Ability (VERA), a benchmark for evaluating reasoning in voice-interactive systems under real-time conversational constraints. It addresses the modality-induced performance gap, termed the Voice Reasoning Gap (VRG), by comparing voice and text-based model performance on reasoning tasks. VERA comprises 2,931 voice-native episodes derived from established text benchmarks, and evaluates 12 contemporary voice systems. The best text models achieve 54.0% accuracy versus 11.3% for voice, indicating a significant performance degradation in voice systems; diagnostic experiments reveal a latency-accuracy trade-off and distinct error signatures across different voice architectures. VERA provides a testbed for architectures that decouple thinking from speaking, facilitating progress toward real-time voice assistants capable of reliable reasoning. |
| Computer Vision | LayerD: Decomposing Raster Graphic Designs into Layers (Read more on [arXiv](https://arxiv.org/abs/2509.25134) or [HuggingFace](https://huggingface.co/papers/2509.25134))| Kota Yamaguchi, Naoto Inoue, Kang-Jun Liu, Tomoyuki Suzuki | The paper introduces LayerD, a method for decomposing raster graphic designs into editable layers. The research aims to address the inverse problem of image composition by automatically disassembling raster images into composable layer sequences. LayerD iteratively extracts unoccluded foreground layers using a top-layer matting model trained on graphic design data and refines the results with domain-specific priors. Experiments demonstrate that LayerD achieves high-quality decomposition, outperforming baselines, with a majority of users (71.4%) rating LayerD as superior in a user study. The method enables downstream graphic design editing tasks by providing access to individual image elements. |
| Machine Learning | Who invented deep residual learning? (Read more on [arXiv](https://arxiv.org/abs/2509.24732) or [HuggingFace](https://huggingface.co/papers/2509.24732))| Juergen Schmidhuber | This paper investigates the history and attribution of deep residual learning in neural networks. It aims to clarify who initially introduced the concept of residual connections and their impact on solving the vanishing gradient problem. The methodology involves a chronological analysis of relevant publications, starting with recurrent neural networks (RNNs) in 1991 and tracking their evolution to feedforward networks. The author identifies recurrent residual connections with a weight of 1.0 from 1991 as the origin and argues that LSTM, highway networks and ResNet are all derivatives. The paper implies that current deep learning practitioners should appropriately credit the original inventors of residual connections, dating back to 1991. |
| Natural Language Processing | Knowledge Homophily in Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2509.23773) or [HuggingFace](https://huggingface.co/papers/2509.23773))| Nedim Lipka, Mahantesh Halappanavar, Zhisheng Qi, Utkarsh Sahu, Franck-Dernoncourt | This paper investigates knowledge homophily in LLMs, revealing that topologically close entities exhibit similar knowledgeability. The study explores whether LLMs exhibit structural knowledge organization analogous to semantic clustering in human brains. A GNN-based regression model is proposed to estimate entity-level knowledgeability scores, leveraging neighborhood scores. Experiments show improved performance with knowledgeability prioritization, achieving up to 87.6% selection quality and significant generalization gain in knowledge injection tasks. The discovery allows for more efficient LLM fine-tuning and multi-hop path retrieval in question answering. |
| Natural Language Processing | d^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching (Read more on [arXiv](https://arxiv.org/abs/2509.23094) or [HuggingFace](https://huggingface.co/papers/2509.23094))| Jiarui Wang, Jiale Fu, Xiangzhong Luo, Yue Cai, Yuchu Jiang | The paper introduces d²Cache, a training-free approximate KV cache framework for accelerating diffusion-based large language models (dLLMs). It addresses the inefficiency of dLLMs caused by bidirectional attention, which hinders the direct application of standard KV caching. d²Cache employs a two-stage fine-grained selection strategy to adaptively update KV states and cache the remaining ones, along with quasi left-to-right generation. Experiments on LLaDA and Dream demonstrate an average 3.2x-4.0x speedup over Vanilla while improving generation quality. The results suggest that selective KV state updates reduce redundant computations and improves efficiency in dLLMs. |
| Machine Learning | BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source
  Software (Read more on [arXiv](https://arxiv.org/abs/2509.25248) or [HuggingFace](https://huggingface.co/papers/2509.25248))|  | The paper introduces BUILD-BENCH, a new benchmark for evaluating LLM agents on the task of compiling real-world open-source software. The research aims to address the limitations of existing methods that rely on curated rules or selective evaluation of highly-rated OSS. They propose BUILD-BENCH and OSS-BUILD-AGENT, an LLM-based agent with an enhanced build instruction retrieval module. Results show that their OSS-BUILD-AGENT achieves a 66.4% success rate on BUILD-BENCH. This benchmark and agent can serve as a strong baseline for future research in automating complex software engineering tasks. |
| Computer Vision | Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional
  Video Generation (Read more on [arXiv](https://arxiv.org/abs/2509.26555) or [HuggingFace](https://huggingface.co/papers/2509.26555))|  | This paper introduces Stable Cinemetrics (SCINE), a structured framework for evaluating video generation models based on professional filmmaking controls. SCINE aims to address the gap between casual video synthesis and controllable cinematic outputs by formalizing filmmaking controls into four taxonomies: Setup, Event, Lighting, and Camera. The methodology involves constructing a benchmark of prompts aligned with professional use cases and developing an automated pipeline for prompt categorization and question generation.  Human evaluation by film professionals reveals that even top models exhibit significant gaps in Events and Camera controls, and the authors develop an automatic evaluator achieving 72.36% accuracy with human annotations. SCINE provides a standardized evaluation suite and detailed analyses, enabling AI practitioners to improve cinematic control in video generation models. |
| Multi-Modal | ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency
  Estimation (Read more on [arXiv](https://arxiv.org/abs/2509.26278) or [HuggingFace](https://huggingface.co/papers/2509.26278))| Antonio Liotta, Jacopo Staiano, Edoardo Bianchi | This paper introduces ProfVLM, a lightweight vision-language model for multi-view proficiency estimation. The research aims to develop a unified framework for skill assessment and expert feedback generation using video and language modalities. The method employs a frozen TimeSformer for video encoding, an AttentiveGatedProjector for multi-view fusion, and a LoRA-tuned SmolLM2 for text generation. ProfVLM achieves 48.2% accuracy on the EgoExo4D dataset, surpassing state-of-the-art while using fewer parameters and frames. The work implies that generative vision-language modeling is a promising direction for skill assessment by providing interpretable feedback alongside proficiency labels. |
| Natural Language Processing | jina-reranker-v3: Last but Not Late Interaction for Document Reranking (Read more on [arXiv](https://arxiv.org/abs/2509.25085) or [HuggingFace](https://huggingface.co/papers/2509.25085))|  | The paper introduces jina-reranker-v3, a 0.6B parameter multilingual document reranker utilizing a novel last but not late interaction mechanism. It aims to improve reranking performance by enabling cross-document interactions within a shared transformer context window before extracting contextual embeddings. The methodology involves causal self-attention between query and documents, allowing rich inter-document relationships to be captured. Experimental results show jina-reranker-v3 achieves state-of-the-art BEIR performance with 61.94 nDCG@10. This compact architecture offers AI practitioners a computationally efficient alternative to larger generative listwise rerankers. |
| Computer Vision | MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial
  Purification (Read more on [arXiv](https://arxiv.org/abs/2509.25082) or [HuggingFace](https://huggingface.co/papers/2509.25082))| Zhiming Luo, Carl Yang, Kejia Zhang, Junwei Wu, Xiaoyi Huang | The paper introduces MANI-Pure, an adversarial purification framework that uses magnitude-adaptive noise injection to enhance robustness against adversarial attacks. It addresses the limitation of uniform noise injection by targeting high-frequency, low-magnitude perturbation regions while preserving semantically critical low-frequency content. The methodology involves adaptively adjusting noise injection based on the magnitude spectrum and employing magnitude-phase decomposition for frequency-domain purification. Evaluated on CIFAR-10 and ImageNet-1K, MANI-Pure achieves a top-1 robust accuracy that surpasses the previous state-of-the-art method and narrows the clean accuracy gap. The framework is plug-and-play, suggesting that AI practitioners can easily integrate it into existing diffusion-based purification pipelines to improve adversarial robustness. |
| Machine Learning | Specialization after Generalization: Towards Understanding Test-Time
  Training in Foundation Models (Read more on [arXiv](https://arxiv.org/abs/2509.24510) or [HuggingFace](https://huggingface.co/papers/2509.24510))|  | This paper explores test-time training (TTT) in foundation models, aiming to understand its effectiveness beyond out-of-distribution adaptation. It posits that TTT facilitates specialization after generalization by focusing model capacity on task-relevant concepts. The methodology involves a theoretical model based on the linear representation hypothesis and empirical validation using sparse autoencoders on ImageNet. Results show TTT improves in-distribution test error, particularly in underparameterized regimes, achieving 72.64% accuracy with TTT compared to 71.45% with global training. The work suggests TTT is a mechanism to efficiently allocate model capacity for specific tasks, especially relevant for practitioners working with underparameterized models. |
| Machine Learning | Estimating Time Series Foundation Model Transferability via In-Context
  Learning (Read more on [arXiv](https://arxiv.org/abs/2509.23695) or [HuggingFace](https://huggingface.co/papers/2509.23695))| Jun Qi, Chao-Han Huck Yang, Chengqi Zhang, Ming Jin, Qingren | The paper introduces TIMETIC, a framework for estimating time series foundation model (TSFM) transferability using in-context learning. The research addresses the challenge of efficiently selecting the best TSFM for fine-tuning on downstream datasets with limited data. TIMETIC organizes observed model-data relationships as contextual information and uses tabular foundation models as in-context learners, leveraging entropy evolution for model characterization. Experiments demonstrate TIMETIC achieves a mean rank correlation of approximately 0.6 with actual fine-tuned performance, a 30% improvement over zero-shot performance. This provides AI practitioners with an efficient method for TSFM selection, reducing computational costs and improving downstream fine-tuning effectiveness. |
