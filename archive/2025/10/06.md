

## Papers for 2025-10-06

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Multi-Modal | Apriel-1.5-15b-Thinker (Read more on [arXiv](https://arxiv.org/abs/2510.01141) or [HuggingFace](https://huggingface.co/papers/2510.01141))|  | The paper introduces Apriel-1.5-15B-Thinker, a 15-billion parameter open-weights multimodal reasoning model. It addresses the challenge of achieving frontier-level performance in a compact model by focusing on training design rather than sheer scale. The model employs a three-stage methodology: depth upscaling, staged continual pre-training using synthetic data and high-quality supervised fine-tuning. Apriel-1.5-15B-Thinker achieves a score of 52 on the Artificial Analysis Intelligence Index and operates within single-GPU deployment constraints. This demonstrates that thoughtful mid-training can close capability gaps without massive scale, making frontier-level multimodal reasoning accessible to organizations with limited infrastructure. |
| Multi-Modal | Efficient Multi-modal Large Language Models via Progressive Consistency
  Distillation (Read more on [arXiv](https://arxiv.org/abs/2510.00515) or [HuggingFace](https://huggingface.co/papers/2510.00515))|  | This paper introduces Efficient MLLMs via ProgressIve Consistency Distillation (EPIC) to improve the efficiency of multi-modal large language models (MLLMs) by compressing visual tokens. The research aims to address the increased learning difficulty caused by visual token compression by progressively distilling knowledge from a teacher model. The method decomposes feature space perturbations introduced by token compression into token-wise and layer-wise dimensions, introducing token consistency distillation and layer consistency distillation. Experiments demonstrate that EPIC achieves superior effectiveness, robustness, and generalization capabilities, achieving comparable average performance to vanilla models while using far fewer visual tokens. EPIC enables practitioners to train robust and generalizable MLLMs using a progressive learning strategy without architectural modifications, balancing efficiency and performance. |
| Reinforcement Learning | Compose Your Policies! Improving Diffusion-based or Flow-based Robot
  Policies via Test-time Distribution-level Composition (Read more on [arXiv](https://arxiv.org/abs/2510.01068) or [HuggingFace](https://huggingface.co/papers/2510.01068))|  | This paper introduces General Policy Composition (GPC), a training-free method for improving robot policies by composing pre-trained diffusion- or flow-based models. The research aims to enhance policy performance without additional training by leveraging distributional scores from multiple pre-trained policies. GPC combines these scores via convex combination and test-time search, allowing integration of heterogeneous policies including VA and VLA models. Experiments on Robomimic and other benchmarks demonstrate consistent performance improvements, achieving up to +7.55% on Robomimic & PushT, +7% on RoboTwin, and +10% in real-world tasks. GPC offers a simple and effective way for AI practitioners to improve control performance by leveraging existing policies. |
| Multi-Modal | Self-Improvement in Multimodal Large Language Models: A Survey (Read more on [arXiv](https://arxiv.org/abs/2510.02665) or [HuggingFace](https://huggingface.co/papers/2510.02665))| Yapeng Tian, Harsh Singh, Tianyu Yang, Kai Wang, Shijian Deng | This survey provides a comprehensive overview of self-improvement techniques in Multimodal Large Language Models (MLLMs). It investigates methods for data collection, organization, and model optimization to enhance MLLM capabilities. The primary objective is to structure the current literature and discuss methodologies for advancing self-improvement in MLLMs. The survey compiles benchmark results to compare the performance gains from self-improvement methods. The survey identifies challenges such as modality alignment issues and limited data generation capabilities, implying the need for better mechanisms for developing the next generation of self-improving MLLMs. |
| Natural Language Processing | Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents (Read more on [arXiv](https://arxiv.org/abs/2509.26354) or [HuggingFace](https://huggingface.co/papers/2509.26354))| Boyi Wei, Chen Qian, Qihan Ren, Shuai Shao, JY-Young | This paper introduces the concept of 'Misevolution' in self-evolving LLM agents, where autonomous improvements lead to unintended and potentially harmful outcomes. The research investigates how self-evolution along model, memory, tool, and workflow pathways can degrade safety. Through empirical evaluation, the study finds that misevolution affects even top-tier LLMs, with a memory-evolving coding agent showing a 55% reduction in Refusal Rate after several cycles.  The primary results reveal the widespread risk of misevolution. This highlights an urgent need for new safety paradigms for self-evolving agents to ensure alignment and trustworthiness. |
| Natural Language Processing | SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys? (Read more on [arXiv](https://arxiv.org/abs/2510.03120) or [HuggingFace](https://huggingface.co/papers/2510.03120))| Shuo Wang, Xin Tong, Xuanhe Zhou, Xuzhou Zhu, Zhaojun Sun | The paper introduces SurveyBench, a benchmark for evaluating LLM(-Agents) in writing academic surveys. It investigates whether LLMs can generate surveys that meet reader needs in terms of outline and content quality. SurveyBench uses a fine-grained, quiz-driven evaluation framework with metrics for outline structure, content depth, and non-textual richness, along with human-reference-based and quiz-based answerability tests. Results show that LLM4Survey approaches score on average 21% lower than human surveys in content-based evaluation. This highlights the need for more targeted optimization in automatic survey writing to improve technical detail, reasoning, and idea abstraction. |
| Natural Language Processing | REPAIR: Robust Editing via Progressive Adaptive Intervention and
  Reintegration (Read more on [arXiv](https://arxiv.org/abs/2510.01879) or [HuggingFace](https://huggingface.co/papers/2510.01879))|  | The paper introduces REPAIR, a lifelong editing framework for large language models designed for precise and low-cost model updates while preserving non-target knowledge. REPAIR employs a closed-loop feedback mechanism with dynamic memory management, distribution-aware optimization, and frequent knowledge fusion to mitigate instability and side effects in sequential edits. Experiments demonstrate that REPAIR achieves a 10%-30% boost in editing accuracy across various model families and significantly reduces knowledge forgetting. This approach offers AI practitioners a robust method for creating reliable and continually evolving LLMs by improving editing accuracy and reducing unintended knowledge attrition. The framework enhances editing stability and reduces unintended ripple effects by using distribution-aware optimization. |
| Machine Learning | CoDA: Agentic Systems for Collaborative Data Visualization (Read more on [arXiv](https://arxiv.org/abs/2510.03194) or [HuggingFace](https://huggingface.co/papers/2510.03194))|  | The paper introduces CoDA, a multi-agent system designed to automate data visualization from natural language queries. CoDA aims to address the limitations of existing systems in handling complex datasets, code errors, and visualization quality. It employs specialized LLM agents for metadata analysis, task planning, code generation, and self-reflection, outperforming competitive baselines by up to 41.5% in overall score on benchmarks like MatplotBench. CoDA demonstrates that collaborative agentic workflows, rather than isolated code generation, are key to visualization automation, benefiting AI practitioners needing automated chart generation. |
| Natural Language Processing | FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of
  Web Agents (Read more on [arXiv](https://arxiv.org/abs/2510.03204) or [HuggingFace](https://huggingface.co/papers/2510.03204))| Léo Boisvert, Xing Han Lù, Megh Thakkar, Sahar Omidi Shayegan, Imene Kerboua | This paper introduces FOCUSAGENT, a method to trim web page context for LLMs in web agents, aiming for efficient reasoning and reduced prompt injection vulnerability. The research focuses on leveraging a lightweight LLM retriever to extract relevant lines from accessibility tree (AxTree) observations based on task goals. Experiments on WorkArena and WebArena show FOCUSAGENT matches strong baselines while reducing observation size by over 50%. A variant of FOCUSAGENT significantly reduces prompt-injection attack success while maintaining task performance in attack-free settings. This highlights a practical strategy for building efficient, effective, and secure web agents. |
| Computer Vision | Improving GUI Grounding with Explicit Position-to-Coordinate Mapping (Read more on [arXiv](https://arxiv.org/abs/2510.03230) or [HuggingFace](https://huggingface.co/papers/2510.03230))| Spandana Gella, Christopher Pal, Ahmed Masry, Tianyu Zhang, Suyuchen Wang | This paper introduces a novel approach to GUI grounding by addressing limitations in existing vision-language models (VLMs) when mapping natural language instructions to pixel coordinates. It aims to improve grounding accuracy and resolution generalization by explicitly mapping positions to coordinates. The proposed method incorporates RULER tokens as coordinate markers and Interleaved MROPE (I-MROPE) to improve spatial encoding. Experiments on ScreenSpot-Pro demonstrate an accuracy improvement from 31.1% to 37.2% when fine-tuning with RULER tokens on high-resolution displays. The explicit spatial guidance provided enables more reliable GUI automation across diverse resolutions and platforms. |
| Machine Learning | LSPO: Length-aware Dynamic Sampling for Policy Optimization in LLM
  Reasoning (Read more on [arXiv](https://arxiv.org/abs/2510.01459) or [HuggingFace](https://huggingface.co/papers/2510.01459))|  | The paper introduces Length-aware Sampling for Policy Optimization (LSPO), a meta-RLVR algorithm designed to improve training effectiveness in LLM reasoning tasks. It addresses the problem of inefficient data sampling in RLVR by dynamically selecting training prompts based on average response length, favoring shortest and longest responses. LSPO demonstrates consistent improvement in final model accuracy across multiple base models and datasets, reporting performance increase in challenging math benchmarks (e.g. improving AIME25 by up to 2.2% for GRPO model Qwen3-4B-Base). The implication for AI practitioners is that incorporating length signals into dynamic sampling can significantly enhance the performance of RLVR-trained models. |
| Machine Learning | WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents (Read more on [arXiv](https://arxiv.org/abs/2510.01354) or [HuggingFace](https://huggingface.co/papers/2510.01354))| Neil Zhenqiang Gong, Yuqi Jia, Xilong Wang, Ruohan Xu, Yinuo Liu | The paper introduces WAInjectBench, a benchmark for evaluating prompt injection detection methods in web agents. It aims to systematically assess and compare detection techniques against various attack types targeting web agents by considering attacker goals, capabilities, and background knowledge. The study constructs comprehensive datasets encompassing both text and image modalities with curated malicious and benign samples to benchmark detection methods. Results show that while some detectors can identify attacks that rely on explicit textual instructions or visible image perturbations with moderate to high accuracy, they largely fail against attacks that omit explicit instructions or employ imperceptible perturbations. WAInjectBench provides valuable insights for developing robust prompt injection defenses for web agents, thereby enhancing their security and reliability. |
| Computer Vision | Free Lunch Alignment of Text-to-Image Diffusion Models without
  Preference Image Pairs (Read more on [arXiv](https://arxiv.org/abs/2509.25771) or [HuggingFace](https://huggingface.co/papers/2509.25771))|  | The paper introduces Text Preference Optimization (TPO), a novel framework for aligning text-to-image diffusion models without human preference data. It addresses the challenge of aligning generated images with textual prompts by training models to prefer matched prompts over LLM-generated mismatched prompts. TPO, applied via TDPO and TKTO, improves alignment, achieving superior human preference scores on benchmarks. Quantitatively, the method achieves a win rate of 83.25% against SDv1.5 on the HPSv2 dataset using PickScore. TPO offers AI practitioners a "free lunch" alignment strategy, enhancing text-to-image consistency without costly human annotation. |
| Machine Learning | OrtSAE: Orthogonal Sparse Autoencoders Uncover Atomic Features (Read more on [arXiv](https://arxiv.org/abs/2509.22033) or [HuggingFace](https://huggingface.co/papers/2509.22033))| Elena Tutubalina, Oleg Rogov, Alexey Dontsov, Andrey Galichin, Anton Korznikov | The paper introduces Orthogonal Sparse Autoencoders (OrtSAE) to improve feature disentanglement in sparse autoencoders. It addresses feature absorption and composition issues by enforcing orthogonality between learned features through a novel training procedure that penalizes high pairwise cosine similarity. OrtSAE achieves this with linear scalability, discovering 9% more distinct features, reducing feature absorption by 65%, and feature composition by 15% compared to traditional SAEs. Experiments on SAEBench show OrtSAE improves performance on spurious correlation removal by +6% while maintaining on-par performance in other downstream tasks. This method offers AI practitioners a more efficient way to obtain interpretable and atomic feature representations from neural network activations. |
| Multi-Modal | LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks
  for Multimodal Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2510.03232) or [HuggingFace](https://huggingface.co/papers/2510.03232))| Yu-Chiang Frank Wang, Yu-Yang Sheng, Min-Hung Chen, Ci-Siang Lin | The paper introduces LEAML, a label-efficient framework for adapting Multimodal Large Language Models (MLLMs) to out-of-distribution visual tasks. It addresses the challenge of limited labeled data in specialized domains by generating pseudo question-answer pairs from unlabeled images using a QA generator regularized by caption distillation and selective neuron updating. The methodology involves training a QA generator with limited labeled data and then using it to create synthetic QA pairs for unlabeled data, which in turn are used to fine-tune the target MLLM. Experiments on gastrointestinal endoscopy VQA demonstrate that LEAML achieves significantly improved performance compared to standard fine-tuning, reaching 76.7% VQA accuracy with only 1% labeled data. LEAML enables efficient adaptation of MLLMs to specialized domains, reducing the reliance on extensive labeled datasets for VQA tasks. |
| Multi-Modal | SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the
  SpineMed-450k Corpus (Read more on [arXiv](https://arxiv.org/abs/2510.03160) or [HuggingFace](https://huggingface.co/papers/2510.03160))| Zhonghao Zhang, Xiang Zheng, Yang Zhang, Wenhui Dong, Ming Zhao | This paper introduces SpineBench, a clinically salient, level-aware benchmark for evaluating AI-assisted spine disorder diagnosis. The research aims to address the lack of level-aware, multimodal datasets by creating a comprehensive framework for vertebral-level reasoning across X-ray, CT, and MRI modalities. The methodology involves curating SpineMed-450k, a large-scale dataset with over 450,000 instruction instances, and developing SpineBench to evaluate models on clinically relevant axes. Evaluations show the proposed model achieves 87.44% average score, outperforming other open-source models by 4.18+ points on close-ended QA tasks.  SpineBench provides a standardized benchmark and high-quality dataset to drive advances in fine-grained, level-specific reasoning for spinal diagnosis, potentially improving the diagnostic clarity and practical utility of AI outputs for clinicians. |
| Computer Vision | How Confident are Video Models? Empowering Video Models to Express their
  Uncertainty (Read more on [arXiv](https://arxiv.org/abs/2510.02571) or [HuggingFace](https://huggingface.co/papers/2510.02571))| Anirudha Majumdar, Ola Shorinwa, Zhiting Mei | This paper introduces a framework for uncertainty quantification (UQ) in generative video models. The primary objective is to enable video models to express uncertainty, addressing a critical safety gap. The method, S-QUBED, uses latent modeling to decompose predictive uncertainty into aleatoric and epistemic components and includes a new metric based on rank correlation for calibration. Experiments demonstrate calibrated total uncertainty estimates that are negatively correlated with task accuracy, with CLIP score as the primary accuracy metric (99% significance in Panda-70M dataset). This enables practitioners to better understand and trust video generation model outputs. |
| Multi-Modal | TalkPlay-Tools: Conversational Music Recommendation with LLM Tool
  Calling (Read more on [arXiv](https://arxiv.org/abs/2510.01698) or [HuggingFace](https://huggingface.co/papers/2510.01698))| Juhan Nam, Keunwoo Choi, Seungheon Doh | The paper introduces TalkPlay-Tools, a conversational music recommendation system using LLM tool calling for a unified retrieval-reranking pipeline. The research aims to improve music recommendation by orchestrating specialized tools like boolean filters, sparse retrieval, dense retrieval, and generative retrieval based on user intent. The system utilizes an LLM to plan tool invocations, predict execution order, and integrate diverse modalities for music discovery. Experimental results on a conversational recommendation benchmark demonstrate competitive performance, evidenced by improved Hit@K. This tool-calling framework allows AI practitioners to selectively employ appropriate retrieval methods based on user queries in conversational music recommendation systems. |
| Reinforcement Learning | A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2510.01132) or [HuggingFace](https://huggingface.co/papers/2510.01132))|  | This paper presents a practitioner's guide to multi-turn agentic reinforcement learning (RL) with large language models (LLMs) in situated textual domains. It investigates the impact of environment complexity, reward density, and policy optimization on LLM agent training. The methodology involves empirically deriving a training recipe across three pillars: environment, reward, and policy, using TextWorld, ALFWorld, and SWE-Gym. The study finds that multi-turn RL performance scales with environment complexity and that an optimal SFT:RL ratio exists for balancing task accuracy and generalization, achieving an 88% improvement on the base environment. This guide facilitates research by codifying effective co-design principles for multi-turn agentic RL systems. |
| Computer Vision | Align Your Tangent: Training Better Consistency Models via
  Manifold-Aligned Tangents (Read more on [arXiv](https://arxiv.org/abs/2510.00658) or [HuggingFace](https://huggingface.co/papers/2510.00658))| Jong Chul Ye, Byunghee Cha, Beomsu Kim | This paper introduces a novel approach to training consistency models (CMs) by aligning their tangents with the data manifold. The research aims to mitigate oscillatory tangent behavior during CM training, which hinders convergence and sample quality. The proposed method, Align Your Tangent (AYT), employs a manifold feature distance loss function that provides manifold-aligned tangents. Experiments on CIFAR10 show that AYT accelerates CM training and achieves a 1-step FID score of 2.61, outperforming baseline methods and even LPIPS. This approach enables faster and more reliable few-step generation for AI practitioners. |
| Multi-Modal | NuRisk: A Visual Question Answering Dataset for Agent-Level Risk
  Assessment in Autonomous Driving (Read more on [arXiv](https://arxiv.org/abs/2509.25944) or [HuggingFace](https://huggingface.co/papers/2509.25944))|  | NuRisk introduces a visual question answering dataset to assess agent-level risk in autonomous driving by combining real-world and simulated scenarios with spatio-temporal risk annotations. The research aims to address the limitations of current VLMs in quantitative risk assessment, particularly in spatio-temporal reasoning. The methodology involves constructing a BEV-based dataset from nuScenes, Waymo, and CommonRoad, benchmarking existing VLMs, and fine-tuning a 7B VLM with LoRA. The fine-tuned VLM achieved an accuracy of 41% and a latency reduction of 75% compared to baseline VLMs. This dataset provides a critical benchmark and a fine-tuning pipeline for advancing spatio-temporal reasoning in autonomous driving systems. |
| Computer Vision | Triangle Splatting+: Differentiable Rendering with Opaque Triangles (Read more on [arXiv](https://arxiv.org/abs/2509.25122) or [HuggingFace](https://huggingface.co/papers/2509.25122))| Matheus Gadelha, Daniel Rebain, Sanghyun Son, Renaud Vandeghen, Jan Held | The paper introduces Triangle Splatting+, a novel differentiable rendering framework using opaque triangles. It aims to bridge the gap between radiance field optimization and traditional mesh-based rendering by directly optimizing triangle-based representations. The method enforces triangle connectivity through shared vertices and employs a training strategy to ensure opacity. Experiments on Mip-NeRF360 show that Triangle Splatting+ achieves state-of-the-art performance with a PSNR of 25.21. The resulting semi-connected meshes are immediately usable in game engines and support physics-based simulation. |
| Machine Learning | DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via
  Repetitive Pattern (Read more on [arXiv](https://arxiv.org/abs/2509.24975) or [HuggingFace](https://huggingface.co/papers/2509.24975))| Jia Li, Yitong Zhang, Yuetong Liu, wellbeing | The paper introduces DIFFTESTER, an acceleration framework for unit test generation (UTG) using diffusion LLMs (dLLMs) by exploiting repetitive patterns in test cases. The research aims to improve the efficiency of dLLMs in UTG without compromising test quality. DIFFTESTER dynamically identifies common patterns through abstract syntax tree analysis and adaptively increases the number of tokens generated per step. Experiments on TestEval, TestEval-C++, and TestEval-Java benchmarks with Dream and DiffuCoder show that DIFFTESTER achieves significant acceleration while preserving test coverage, e.g., reducing computational cost by 1.75x and decoding time by 1.57x on TestEval-Python with DiffuCoder and n=3. DIFFTESTER offers a practical solution for efficient UTG by generalizing across different dLLMs and programming languages, which reduces the manual burden of software testing. |
| Natural Language Processing | Scaling Policy Compliance Assessment in Language Models with Policy
  Reasoning Traces (Read more on [arXiv](https://arxiv.org/abs/2509.23291) or [HuggingFace](https://huggingface.co/papers/2509.23291))|  | This paper introduces Policy Reasoning Traces (PRTs) to enhance policy compliance assessment in Language Models (LLMs). The research aims to improve LLMs' ability to accurately assess compliance with human-defined rules and policies by providing a reasoning bridge. The key methodology involves generating PRTs from frontier pseudo-expert reasoning models using policy compliance datasets, which are then used for both inference-time and training-time enhancements. Empirical evaluations demonstrate that the use of PRTs significantly improves performance, setting a new state-of-the-art for HIPAA and GDPR policies, with open-weight models achieving a 50-100% increase in performance for HIPAA. The main implication for AI practitioners is that PRTs provide a valuable resource for scaling policy compliance capabilities in LLMs, improving accuracy and interpretability in high-stakes domains. |
