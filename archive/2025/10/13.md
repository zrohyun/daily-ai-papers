

## Papers for 2025-10-13

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Computer Vision | Thinking with Camera: A Unified Multimodal Model for Camera-Centric
  Understanding and Generation (Read more on [arXiv](https://arxiv.org/abs/2510.08673) or [HuggingFace](https://huggingface.co/papers/2510.08673))| Linyi Jin, Zhonghua Wu, Size Wu, yikaiwang, KangLiao | The paper introduces Puffin, a unified camera-centric multimodal model for both understanding and generating scenes from arbitrary viewpoints. The research aims to bridge the modality gap between camera parameters and vision-language models by treating camera as language, enabling thinking with camera. Puffin combines autoregressive and diffusion modeling, aligning visual cues with photographic terminology while reasoning across geometric contexts. The model is trained on Puffin-4M, a large-scale dataset of 4 million vision-language-camera triplets, and demonstrates superior performance over specialized models, achieving improved accuracy in camera parameter estimation. Puffin's ability to generalize to cross-view tasks and its unified framework offer AI practitioners a powerful tool for spatial intelligence research and applications. |
| Reinforcement Learning | D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to
  Embodied AI (Read more on [arXiv](https://arxiv.org/abs/2510.05684) or [HuggingFace](https://huggingface.co/papers/2510.05684))| Haebin Seong, Suwhan Choi, Maangeek, shovelingpig, lastdefiance20 | The paper presents D2E, a framework for scaling vision-action pretraining by leveraging desktop environment data for transfer to embodied AI tasks. It addresses the challenge of costly physical trajectory collection by utilizing gaming environments for sensorimotor interaction pretraining. The key methodology involves an OWA Toolkit for standardized desktop data collection, a Generalist-IDM for zero-shot generalization through timestamp-based event prediction and VAPT to transfer desktop-pretrained representations to physical tasks. Using 1.3K+ hours of desktop data, the D2E framework achieves 96.6% success on LIBERO manipulation and 83.3% on CANVAS navigation. This establishes desktop pretraining as a viable paradigm for robotics by reducing the need for expensive real-world data. |
| Computer Vision | TAG:Tangential Amplifying Guidance for Hallucination-Resistant Diffusion
  Sampling (Read more on [arXiv](https://arxiv.org/abs/2510.04533) or [HuggingFace](https://huggingface.co/papers/2510.04533))| Seungryong Kim, Jee Eun Kim, Susung Hong, Donghoon Ahn, hyeoncho01 | The paper introduces Tangential Amplifying Guidance (TAG) for improving the fidelity of diffusion model sampling. It addresses the hallucination problem in diffusion models by amplifying the tangential components of score estimates, guiding sampling trajectories towards high-probability regions. TAG decomposes the update step into normal and tangential components, amplifying the latter to enhance semantic structure. Experiments demonstrate that TAG reduces FID from 76.942 to 67.805 compared to DDIM on ImageNet. TAG provides an efficient and architecture-agnostic guidance approach to mitigate inconsistencies in generated samples. |
| Multi-Modal | Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for
  MLLMs (Read more on [arXiv](https://arxiv.org/abs/2510.09201) or [HuggingFace](https://huggingface.co/papers/2510.09201))|  | The paper introduces multimodal prompt optimization for multimodal large language models (MLLMs). It addresses the limitation of existing prompt optimization methods that are confined to text, hindering the potential of MLLMs. The research objective is to optimize prompts using both textual and non-textual modalities jointly. It proposes the Multimodal Prompt Optimizer (MPO), a framework combining alignment-preserving updates and Bayesian-based prompt selection. Experiments across images, videos, and molecules show that MPO outperforms text-only methods, achieving up to a 76.4% accuracy on image classification tasks, and prior-inherited selection reduced evaluation budget by 42%. This highlights the importance of leveraging multiple modalities for prompt optimization to fully realize the capabilities of MLLMs. |
| Natural Language Processing | AutoPR: Let's Automate Your Academic Promotion! (Read more on [arXiv](https://arxiv.org/abs/2510.09558) or [HuggingFace](https://huggingface.co/papers/2510.09558))| Yixin Yuan, Libo Qin, Mingda Yang, Zheng Yan, Qiguang Chen | The paper introduces AutoPR, a novel task and framework for automating the promotion of academic research papers on social media.  It addresses the challenge of efficiently transforming research into engaging and timely public content. The paper proposes PRBench, a multimodal benchmark, and PRAgent, a multi-agent framework for content extraction, synthesis, and platform adaptation. PRAgent demonstrates substantial improvements on PRBench compared to direct LLM pipelines, achieving a 604% increase in total watch time and a 438% rise in likes. The work suggests a scalable and impactful approach to automated scholarly communication by platform modeling and targeted promotion. |
| Natural Language Processing | R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth
  and Depth? (Read more on [arXiv](https://arxiv.org/abs/2510.08189) or [HuggingFace](https://huggingface.co/papers/2510.08189))|  | This paper introduces R-HORIZON, a method to stimulate long-horizon reasoning in Large Reasoning Models (LRMs) by composing queries to create interdependent, multi-step reasoning tasks. The research aims to evaluate and enhance the long-horizon reasoning capabilities of LRMs, which are inadequately assessed by single-horizon benchmarks. R-HORIZON constructs long-horizon reasoning benchmarks and training data, enabling reinforcement learning with verified rewards (RLVR) to improve LRM performance. Results show that RLVR with R-HORIZON improves performance on multi-horizon reasoning tasks and standard reasoning tasks (+7.5 on AIME2024). R-HORIZON offers a scalable paradigm to enhance and evaluate the long-horizon reasoning capabilities of LRMs. |
| Reinforcement Learning | Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining
  Levels (Read more on [arXiv](https://arxiv.org/abs/2510.06499) or [HuggingFace](https://huggingface.co/papers/2510.06499))|  | The paper introduces Webscale-RL, a data pipeline to scale reinforcement learning (RL) by converting large pre-training documents into question-answer pairs. The primary objective is to address the data bottleneck in RL by creating a diverse and scalable dataset. The pipeline includes data filtering, domain-specific generation, and quality verification, resulting in the Webscale-RL dataset with 1.2 million examples across 9 domains. Experiments show the model trained on this dataset outperforms continual pre-training by up to 3.4 points and achieves comparable performance with 100x fewer tokens, suggesting a viable path for scaling RL to pre-training levels. |
| Computer Vision | SpaceVista: All-Scale Visual Spatial Reasoning from mm to km (Read more on [arXiv](https://arxiv.org/abs/2510.09606) or [HuggingFace](https://huggingface.co/papers/2510.09606))| Kaituo Feng, Yi Ding, Dongming Wu, Shiqiang Lang, spw2000 | The paper introduces SpaceVista, a novel framework for all-scale visual spatial reasoning from millimeters to kilometers. It aims to address limitations in existing spatial reasoning datasets and models by creating a dataset with diverse scales and semantics, and (?) to address (?) lack of models that generalize across scales. The method involves a specialist-driven automated pipeline for data curation, scale-aware modeling, and progressive training. SpaceVista-7B, the proposed model, achieves (competitive?) performance on SpaceVista-Bench, suggesting (?) it can generalize across diverse scenarios. This all-scale spatial reasoning can support diverse applications such as manufacturing, robotics, autonomous driving, and remote sensing. |
| Multi-Modal | ARES: Multimodal Adaptive Reasoning via Difficulty-Aware Token-Level
  Entropy Shaping (Read more on [arXiv](https://arxiv.org/abs/2510.08457) or [HuggingFace](https://huggingface.co/papers/2510.08457))| Wenbo Hu, Yimeng Ye, Yue Guo, JoeYing, csfufu | The paper introduces ARES, a novel framework for adaptive reasoning in multimodal large language models. It aims to address the imbalance of overthinking in simple problems and under-exploring in complex ones by dynamically allocating reasoning effort based on task difficulty. ARES uses a two-stage training process involving Adaptive Cold-Start and Adaptive Entropy Policy Optimization (AEPO), leveraging high window entropy as exploration triggers. Experiments demonstrate that ARES achieves superior performance and reasoning efficiency across diverse benchmarks, improving average accuracy by up to 19.0 on MathVision. The framework offers a computationally efficient approach to enhancing multimodal reasoning capabilities. |
| Multi-Modal | StreamingVLM: Real-Time Understanding for Infinite Video Streams (Read more on [arXiv](https://arxiv.org/abs/2510.09608) or [HuggingFace](https://huggingface.co/papers/2510.09608))| Kelly Peng, Liuning He, Guangxuan Xiao, Ruyi Xu, Yukang | This paper introduces StreamingVLM for real-time understanding of infinite video streams. The research aims to address challenges in processing long videos with low latency and bounded memory usage. The method involves training with full attention on short, overlapped video chunks and using a compact KV cache at inference with attention sinks and contiguous RoPE. On the Inf-Streams-Eval benchmark, StreamingVLM achieves a 66.18% win rate against GPT-4O mini while maintaining real-time performance. This approach enables stable, real-time video understanding for applications like autonomous agents and assistants. |
| Reinforcement Learning | Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence
  Reweighting (Read more on [arXiv](https://arxiv.org/abs/2510.08696) or [HuggingFace](https://huggingface.co/papers/2510.08696))| Julia Kempe, Yaqi Duan, Anthony Hartshorn, Parag Jain, Yunzhen Feng | This paper introduces LENS, a method to leverage negative groups in Reinforcement Learning with Verifiable Rewards (RLVR) by reweighting them based on confidence. It aims to address the issue of wasted computation in Group Relative Policy Optimization (GRPO) when no sampled response in a group is correct, leading to zero advantage and no gradient. LENS modifies GRPO by assigning confidence-dependent rewards to incorrect generations, thereby making negative groups informative. The method was evaluated on the MATH benchmark, showing consistent outperformance against GRPO with Llama-3.1-8B and Qwen-2.5-3B, particularly on harder items, as it achieves higher Pass@k. The work enables more efficient RLVR training by effectively utilizing previously discarded samples for gradient updates. |
| Machine Learning | Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out
  of Distribution Generalization (Read more on [arXiv](https://arxiv.org/abs/2510.06274) or [HuggingFace](https://huggingface.co/papers/2510.06274))| Mahdi Ghaznavai, Mohamadreza Fereydooni, Arash Marioriyad, Mohammad Mahdi Samiei Paqaleh, OstadTahmasb | This paper introduces Complexity Out-of-Distribution (OoD) generalization as a framework for defining and measuring reasoning abilities in AI models. The objective is to assess model performance on test instances where the minimal solution complexity exceeds that of training examples, clarifying the distinction from compositional and length OoD. They formalize complexity using Kolmogorov complexity and operational proxies like object/relation counts. The primary implication is that progress toward robust reasoning requires architectures and training regimes that explicitly model and allocate computation with respect to complexity, as Complexity OoD cannot be solved by scaling data alone. |
| Natural Language Processing | KORMo: Korean Open Reasoning Model for Everyone (Read more on [arXiv](https://arxiv.org/abs/2510.09426) or [HuggingFace](https://huggingface.co/papers/2510.09426))|  | The paper introduces KORMo-10B, a fully open bilingual Korean-English LLM trained primarily on synthetic data. The study investigates whether synthetic data can be reliably used for large-scale pretraining in a low-resource language without model collapse or bias introduction. KORMo-10B, with 68.74% of the Korean portion being synthetic, achieves performance comparable to open-weight multilingual baselines on reasoning and knowledge tasks. This demonstrates that carefully curated synthetic data can sustain long-horizon pretraining and that bilingual instruction tuning enables near-native reasoning in Korean. The release of all KORMo components facilitates reproducible multilingual LLM research and provides a framework for developing synthetic data-driven FOMs in low-resource settings. |
| Computer Vision | Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open
  Vocabulary Occupancy Prediction (Read more on [arXiv](https://arxiv.org/abs/2510.04759) or [HuggingFace](https://huggingface.co/papers/2510.04759))| danxuhk, yanchi3dv | This paper introduces PG-Occ, a novel framework for open-vocabulary 3D occupancy prediction. It addresses the limitations of sparse Gaussian representations and dense scene modeling by employing progressive online densification to enhance 3D Gaussian representations. The method incorporates an anisotropy-aware sampling strategy with spatio-temporal fusion to improve feature aggregation. PG-Occ achieves state-of-the-art performance on the Occ3D-nuScenes dataset, with a relative 14.3% mIoU improvement. The framework enables more flexible and accurate scene understanding, benefiting applications in autonomous driving and embodied intelligence. |
| Natural Language Processing | StatEval: A Comprehensive Benchmark for Large Language Models in
  Statistics (Read more on [arXiv](https://arxiv.org/abs/2510.09517) or [HuggingFace](https://huggingface.co/papers/2510.09517))|  | StatEval is a new comprehensive benchmark designed to evaluate large language models' (LLMs) statistical reasoning capabilities. The study aims to address the underexplored area of statistics in LLM benchmarking by introducing StatEval, which contains both undergraduate and graduate-level problems, as well as research-level proof tasks. The methodology involves a multi-agent pipeline for automated problem extraction, rewriting, and quality control with human-in-the-loop validation. Experimental results indicate that while closed-source models like GPT5-mini achieve below 57% on research-level problems, open-source models perform significantly lower, highlighting limitations in statistical reasoning. The implication is that StatEval serves as a rigorous benchmark to advance statistical intelligence in LLMs by exposing the unique challenges in statistical reasoning. |
| Multi-Modal | MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for
  Reasoning-Intensive Multimodal Retrieval (Read more on [arXiv](https://arxiv.org/abs/2510.09510) or [HuggingFace](https://huggingface.co/papers/2510.09510))| Tingyu Song, Yilun Zhao, Xiao Zhou, Siyue Zhang, ItzYog | This paper introduces MRMR, a new expert-level multidisciplinary benchmark for reasoning-intensive multimodal retrieval. The research aims to address limitations of existing multimodal benchmarks by focusing on expert domains, reasoning-intensive queries, and image-text interleaved sequences. MRMR contains 1,502 queries across 23 domains, requiring retrieval systems to handle diverse expertise and contradiction retrieval. Evaluation of 14 models shows Qwen3-Embedding achieves the highest nDCG@10 of 52.1, highlighting the need for improved reasoning capabilities in multimodal retrieval models. The MRMR benchmark facilitates advancements in multimodal retrieval by providing a more realistic and challenging evaluation scenario. |
| Machine Learning | DISCO: Diversifying Sample Condensation for Efficient Model Evaluation (Read more on [arXiv](https://arxiv.org/abs/2510.07959) or [HuggingFace](https://huggingface.co/papers/2510.07959))|  | The paper introduces DISCO, a novel approach for efficient model evaluation by diversifying sample condensation. It aims to reduce the computational cost of evaluating large machine learning models without significant loss in accuracy. DISCO selects a subset of evaluation samples based on maximizing model disagreement and uses model signatures to predict benchmark performance. Empirical results on MMLU show DISCO reduces evaluation cost by 99.3% with only 1.07 percentage points of error. DISCO provides AI practitioners with a cost-effective method for evaluating models, enabling more inclusive innovation cycles. |
| Reinforcement Learning | Dyna-Mind: Learning to Simulate from Experience for Better AI Agents (Read more on [arXiv](https://arxiv.org/abs/2510.09577) or [HuggingFace](https://huggingface.co/papers/2510.09577))| Qianhui Wu, Hao Cheng, Michel Galley, Baolin Peng, Xiao Yu | This paper introduces Dyna-Mind, a two-stage framework designed to enhance the simulation capabilities of AI agents in complex interactive environments. The research aims to improve long-horizon task performance by explicitly teaching agents to integrate simulation into their reasoning via Reasoning with Simulations (RESIM) and Dyna-GRPO. RESIM uses expanded search trees from real-world interactions to generate reasoning traces, while Dyna-GRPO employs online reinforcement learning utilizing outcome rewards and intermediate states as feedback. Experiments demonstrate that Dyna-Mind improves performance; for instance, achieving a 90.8% success rate on AndroidWorld compared to RESIM alone, indicating improved policy learning. The framework offers a structured approach to training AI agents to reason and plan more effectively in challenging environments by integrating world model simulations. |
| Machine Learning | ReviewerToo: Should AI Join The Program Committee? A Look At The Future
  of Peer Review (Read more on [arXiv](https://arxiv.org/abs/2510.08867) or [HuggingFace](https://huggingface.co/papers/2510.08867))| Christopher Pal, Laurent Charlin, Hugo Larochelle, Gaurav Sahu | The paper introduces ReviewerToo, a modular framework to study and deploy AI-assisted peer review to complement human judgment. The research investigates the potential of AI to address inconsistencies and scalability challenges in peer review by systematically analyzing different reviewer personas. ReviewerToo uses LLMs to simulate diverse reviewer roles, generating structured assessments grounded in manuscript content and literature. Experiments on a curated ICLR 2025 dataset reveal that the gpt-oss-120b model achieves 81.8% accuracy in accept/reject categorization, compared to 83.9% for human reviewers. The analysis highlights domains where AI reviewers excel (e.g., fact-checking, literature coverage) and provides guidelines for integrating AI into peer-review pipelines. |
| Machine Learning | BigCodeArena: Unveiling More Reliable Human Preferences in Code
  Generation via Execution (Read more on [arXiv](https://arxiv.org/abs/2510.08697) or [HuggingFace](https://huggingface.co/papers/2510.08697))| Juyong Jiang, Hange Liu, Xiaolong Jin, Terry Yue Zhuo, Benjamin-eecs | The paper introduces BigCodeArena, a human evaluation platform for code generation that incorporates on-the-fly code execution and UI interaction. It aims to collect more reliable human preferences for code generation by providing execution feedback. The methodology involves collecting over 14K code-centric conversation sessions across 10 LLMs, 10 languages, and 8 execution environments, with 4.7K multi-turn samples used for pairwise preference analysis. Results show that execution feedback significantly improves the reliability of human judgment in code evaluation and find GPT-5 leads in code generation quality. BigCodeArena enables more transparent and reliable evaluation of code generation, aiding in the development of more capable and aligned code LLMs. |
| Natural Language Processing | Which Heads Matter for Reasoning? RL-Guided KV Cache Compression (Read more on [arXiv](https://arxiv.org/abs/2510.08525) or [HuggingFace](https://huggingface.co/papers/2510.08525))| Huan Wang, Xue Liu, Keda Tao, Li Jiang, Kurt232 | The paper introduces RLKV, a reinforcement learning-guided framework for compressing Key-Value (KV) caches in large language models during reasoning tasks. It aims to identify reasoning-critical attention heads and allocate full KV cache to them, while compressing the cache for less important heads. RLKV uses RL to optimize the relationship between each head's cache usage and reasoning quality. Experiments show that RLKV outperforms baseline methods, achieving 20-50% cache reduction with near lossless performance. This implies that only a small fraction of attention heads is essential for reasoning, allowing for more efficient deployment of reasoning models. |
| Machine Learning | Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic
  Speech Recognition (Read more on [arXiv](https://arxiv.org/abs/2510.08047) or [HuggingFace](https://huggingface.co/papers/2510.08047))| Shang-Tse Chen, Tzu-Quan Lin, Yu-Hsuan Li Liang, Yi-Cheng Lin, jacksukk | This paper introduces Pseudo2Real, a task arithmetic method for mitigating systematic pseudo-label errors in ASR domain adaptation. The research addresses how to correct recurring biases in pseudo-labels without target ground truth. The key methodology involves fine-tuning two ASR models on ground-truth and pseudo-labels in the source domain and using their weight difference as a correction vector. Results on AFRISPEECH-200 show a WER reduction of up to 35% with Whisper TINY. Pseudo2Real provides a parameter-space correction technique applicable to practitioners seeking to improve ASR performance in low-resource or domain-shifted scenarios. |
| Natural Language Processing | Parallel Test-Time Scaling for Latent Reasoning Models (Read more on [arXiv](https://arxiv.org/abs/2510.07745) or [HuggingFace](https://huggingface.co/papers/2510.07745))|  | The paper introduces parallel test-time scaling (TTS) to enhance latent reasoning models. It investigates whether latent models, unlike explicit Chain-of-Thought models, can benefit from parallel TTS by addressing sampling and aggregation challenges in continuous vector spaces. The key methodology involves two uncertainty-inspired stochastic sampling strategies and a Latent Reward Model (LatentRM) for trajectory scoring and guidance. Experiments demonstrate that both sampling strategies scale effectively with compute and enable effective trajectory selection via LatentRM. Findings indicate that parallel TTS transfers to latent reasoning models by redesigning sampling and aggregation strategies opening a new pathway for scalable inference in latent space. |
| Natural Language Processing | Mind-Paced Speaking: A Dual-Brain Approach to Real-Time Reasoning in
  Spoken Language Models (Read more on [arXiv](https://arxiv.org/abs/2510.09592) or [HuggingFace](https://huggingface.co/papers/2510.09592))| Zhang, Xiangyu, Jun Chen, Haoyang Zhang, Donghang Wu | The paper introduces Mind-Paced Speaking (MPS), a dual-brain framework for real-time reasoning in spoken language models (SLMs). It aims to enable SLMs to think while speaking by mimicking the human cognitive-speech system. The proposed method uses a "Formulation Brain" for reasoning and an "Articulation Brain" for speech generation, allowing for concurrent processing. Experimental results on Spoken-MQA show that MPS achieves an accuracy of 92.8% in a zero-latency configuration. This approach offers AI practitioners a method to significantly reduce latency in SLMs while maintaining high reasoning performance and semantic coherence. |
| Natural Language Processing | A Goal Without a Plan Is Just a Wish: Efficient and Effective Global
  Planner Training for Long-Horizon Agent Tasks (Read more on [arXiv](https://arxiv.org/abs/2510.05608) or [HuggingFace](https://huggingface.co/papers/2510.05608))| Fanchao Qi, Gang Chen, Kangyang Luo, Haozhe Zhao, Shuzheng Si | The paper introduces EAGLET, a method for training global planners for long-horizon agent tasks. It addresses the challenge of brainless trial-and-error and hallucination actions in LLMs by proposing a plan-and-execute framework. EAGLET uses a two-step process: synthesizing high-quality plans with a homologous consensus filtering strategy and fine-tuning the planner using a rule-based reinforcement learning stage with an executor capability gain reward. Experiments on ScienceWorld, ALFWorld, and WebShop show that EAGLET outperforms existing methods, achieving new state-of-the-art performance with an 8x reduction in training costs. The implications suggest that EAGLET offers an efficient, effective, and labor-free approach to enhance the planning abilities of LLM-based agents. |
| Multi-Modal | PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs (Read more on [arXiv](https://arxiv.org/abs/2510.09507) or [HuggingFace](https://huggingface.co/papers/2510.09507))| Xu Zheng, Lutao Jiang, Xingwang Lin, Kanghao Chen, Zixin Zhang | The paper introduces PhysToolBench, a new benchmark for evaluating the understanding of physical tools in Multimodal Large Language Models (MLLMs). It assesses capabilities across three difficulty levels: Tool Recognition, Tool Understanding, and Tool Creation using a Visual Question Answering (VQA) dataset. The evaluation of 32 MLLMs reveals a significant deficiency in tool understanding, with even the most advanced proprietary models scoring no higher than 63% overall accuracy. The work identifies critical weaknesses in current MLLMs, including challenges in recognizing tool availability and visual reasoning skills. The authors propose a "vision-centric reasoning" framework to improve visual reasoning and offer a tiered evaluation for benchmarking embodied agents. |
| Machine Learning | Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols (Read more on [arXiv](https://arxiv.org/abs/2510.09462) or [HuggingFace](https://huggingface.co/papers/2510.09462))| Maksym Andriushchenko, Caglar Gulcehre, Daniil Dzenhaliou, Mikhail Terekhov, kotekjedi | This paper demonstrates that adaptive attacks, utilizing prompt injections, can subvert AI control protocols that rely on trusted monitors. The research investigates how an untrusted model can compromise the monitor, enabling malicious task completion. The key methodology involves embedding publicly known or zero-shot prompt injections in model outputs, which are then used to bypass the monitor. The primary result is that frontier models consistently evade diverse monitors on AI control benchmarks, leading to a significant decrease in safety and usefulness metrics. This implies that current control protocols must incorporate robust red-teaming and address monitor vulnerabilities to prevent easy compromise. |
| Natural Language Processing | GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare (Read more on [arXiv](https://arxiv.org/abs/2510.08872) or [HuggingFace](https://huggingface.co/papers/2510.08872))|  | The paper introduces GTALIGN, a framework for aligning LLM assistants to optimize mutual welfare in user-LLM interactions. It addresses the problem of suboptimal LLM responses arising from a lack of principled decision-making. The approach integrates game-theoretic reasoning into LLM reasoning and training, using payoff matrices and mutual welfare rewards. Experiments demonstrate GTALIGN improves reasoning efficiency by 21.5%, answer quality by 4.9%, and mutual welfare by 7.2% across diverse tasks. The framework offers a way to steer LLM behavior dynamically based on pricing policies, enabling more rational and adaptive cooperative AI. |
| Natural Language Processing | Understanding DeepResearch via Reports (Read more on [arXiv](https://arxiv.org/abs/2510.07861) or [HuggingFace](https://huggingface.co/papers/2510.07861))| Chengen Huang, Fengji Zhang, Yuxiang Zheng, Xinyao Niu, T1anyu | This paper introduces DEEPRESEARCH-REPORTEVAL, a comprehensive framework for evaluating DeepResearch systems via their generated reports. It addresses the challenge of assessing holistic research capabilities by measuring quality, redundancy, and factuality. The methodology employs an LLM-as-a-Judge approach, aligned with human expert judgments (Mean Absolute Deviation scores: Quality MAD=0.72, Redundancy MAD=0.31, Factuality MAD=0.29). The framework includes a curated benchmark of 100 queries across 12 categories. The framework provides tools for measuring progress and guiding the development of DeepResearch systems. |
| Computer Vision | One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework (Read more on [arXiv](https://arxiv.org/abs/2510.02898) or [HuggingFace](https://huggingface.co/papers/2510.02898))| Giuseppe Amato, Nicola Messina, Fabio Carrara, Ruggero1912, lorebianchi98 | The paper introduces Patch-ioner, a unified zero-shot captioning framework that generates captions for arbitrary regions of an image by treating individual patches as atomic captioning units. It aims to perform region-level captioning without region-level supervision by aggregating patch representations. The methodology repurposes existing models by analyzing key components, particularly vision backbones like DINO, to produce meaningful dense visual features. Experiments demonstrate that Patch-ioner achieves better performance than other baselines on zero-shot dense, region-set, and trace captioning tasks, reporting a CIDEr score of 109.1 on the COCO Entities dataset for region-set captioning, suggesting an effective approach for scalable caption generation. This offers AI practitioners a flexible tool for diverse captioning tasks without extensive training data. |
| Computer Vision | TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion
  Control (Read more on [arXiv](https://arxiv.org/abs/2510.09561) or [HuggingFace](https://huggingface.co/papers/2510.09561))| Adityan Jothi, Christian Jacobsen, Ruben Ohana, Minkyoung Cho, cmhungsteve | The paper introduces Temporally Modulated Conditional LoRA (TC-LoRA), a novel framework for dynamic control in diffusion models. It addresses the limitation of static conditioning by dynamically generating LoRA adapters conditioned on time and the user's control signal. TC-LoRA uses a hypernetwork to tailor weight modifications for the frozen backbone at each diffusion step. Experiments show enhanced generative fidelity and adherence to spatial conditions, achieving a NMSE reduction of 11.7% on TransferBench compared to static methods. TC-LoRA offers AI practitioners a new approach to refine controllable generation by dynamically adapting model weights during inference. |
| Natural Language Processing | Mitigating Overthinking through Reasoning Shaping (Read more on [arXiv](https://arxiv.org/abs/2510.09535) or [HuggingFace](https://huggingface.co/papers/2510.09535))| Wen Luo, Yejie Wang, Bofei Gao, Shaohang Wei, Feifan Song | The paper introduces Group Relative Segment Penalization (GRSP) to mitigate overthinking in large reasoning models (LRMs) by regularizing reasoning at the step-level. GRSP balances computational efficiency and task performance through length-aware weighting across segment clusters. Experiments demonstrate that GRSP achieves superior token efficiency without heavily compromising accuracy, particularly in harder problems. For instance, GRSP achieves a task performance of 64.72% with an average response length of 3477 tokens. This suggests that segment-level penalization can be a viable strategy for controlling LRM reasoning behavior while preserving task accuracy, offering a method for practitioners to balance cost and accuracy. |
| Computer Vision | Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive
  Text-to-image Generation (Read more on [arXiv](https://arxiv.org/abs/2510.08994) or [HuggingFace](https://huggingface.co/papers/2510.08994))| Han Shi, Zhekai Chen, Xian Liu, Fuyun Wang, Yao Teng | The paper introduces Speculative Jacobi-Denoising Decoding (SJD2) to accelerate autoregressive text-to-image generation. It aims to improve inference speed by enabling parallel token generation through integrating a denoising process into Jacobi iterations. SJD2 introduces a next-clean-token prediction paradigm and a fine-tuning strategy that allows the model to denoise noise-perturbed token embeddings. Experiments on Lumina-mGPT and Emu3 show the method reduces model forward passes by about 4x and over 5x, respectively, achieving latency speedup. This allows for faster autoregressive text-to-image generation without compromising image quality. |
| Natural Language Processing | ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual
  Recall (Read more on [arXiv](https://arxiv.org/abs/2510.07896) or [HuggingFace](https://huggingface.co/papers/2510.07896))| Jiaqi Tang, Shengen Wu, Songning Lai, Yuxuan Fan, Jiayu Yang | The paper introduces ACE, a novel knowledge editing framework designed to improve multi-hop factual recall in large language models.  It addresses the limitation of existing knowledge editing methods in handling edits involving intermediate implicit subjects in reasoning chains by focusing on how chained knowledge is dynamically represented at the neuron level.  ACE leverages neuron-level attribution to identify and edit critical query-value pathways in transformer networks.  Empirically, ACE outperforms state-of-the-art methods, achieving a 9.44% improvement on GPT-J and a 37.46% increase on Qwen3-8B in multi-hop accuracy.  This work provides a mechanistically grounded approach for knowledge editing, enabling more effective updates of factual information in LLMs and offering insights into internal reasoning mechanisms. |
| Computer Vision | Temporal Prompting Matters: Rethinking Referring Video Object
  Segmentation (Read more on [arXiv](https://arxiv.org/abs/2510.07319) or [HuggingFace](https://huggingface.co/papers/2510.07319))| Sifei Liu, Chien-Yi Wang, I-Jieh Liu, Ci-Siang Lin, cmhungsteve | This paper addresses Referring Video Object Segmentation (RVOS) by decomposing it into referring, video, and segmentation factors. The research aims to efficiently adapt image-based foundation segmentation models to RVOS. They propose a Temporal Prompt Generation and Selection (Tenet) framework that leverages object detectors and trackers to produce temporal prompts, and Prompt Preference Learning to evaluate their quality. Experiments on RVOS benchmarks show the Tenet framework achieves a J&F score of 71.0% on Ref-DAVIS17, demonstrating effectiveness. The approach enables efficient model adaptation, avoiding end-to-end training and dense mask annotations. |
| Computer Vision | Instant4D: 4D Gaussian Splatting in Minutes (Read more on [arXiv](https://arxiv.org/abs/2510.01119) or [HuggingFace](https://huggingface.co/papers/2510.01119))| Li Lu, Haoxi Ran, Zhanpeng Luo | This paper introduces Instant4D, a novel system for efficient dynamic 3D scene reconstruction from monocular videos using 4D Gaussian splatting. The research aims to achieve real-time rendering speeds and reduce training time compared to existing methods. Instant4D employs deep visual SLAM for geometric recovery, grid pruning to reduce model size, and a simplified 4D Gaussian representation for efficient temporal dynamics modeling. The method achieves a 30x speed-up in reconstruction time and 90% memory reduction, demonstrating competitive performance across several benchmarks, achieving an average of 23.02 dB PSNR on the Dycheck dataset. The implication for AI practitioners is a faster and more memory-efficient approach for creating dynamic 3D scene representations from casual videos, potentially enabling real-time AR/VR applications. |
| Machine Learning | Better Together: Leveraging Unpaired Multimodal Data for Stronger
  Unimodal Models (Read more on [arXiv](https://arxiv.org/abs/2510.08492) or [HuggingFace](https://huggingface.co/papers/2510.08492))|  | This paper introduces UNPAIRED MULTIMODAL LEARNER (UML) to enhance unimodal models by leveraging unpaired multimodal data. The research explores whether unpaired data from auxiliary modalities can improve representation learning in a target modality. UML shares model weights across modalities during training. Experiments show UML consistently improves downstream performance across various unimodal targets, such as image and audio tasks, achieving higher top-1 linear probe accuracy than unimodal baselines on datasets like MUSTARD. The main implication is that AI practitioners can leverage readily available unpaired multimodal data to boost the performance of unimodal systems. |
