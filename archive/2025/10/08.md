

## Papers for 2025-10-08

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Machine Learning | TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular
  Reasoning (Read more on [arXiv](https://arxiv.org/abs/2510.06217) or [HuggingFace](https://huggingface.co/papers/2510.06217))|  | The paper introduces TATTOO, a table-grounded Process Reward Model (PRM) for test-time scaling in tabular reasoning tasks. It aims to address the limitations of existing PRMs in supervising tabular operations like sub-table retrieval and schema interaction. TATTOO employs a data curation pipeline integrating tool-based executions and a dual-stage training paradigm (supervised fine-tuning followed by reinforcement learning with tool-grounded reward shaping). Experiments on five tabular reasoning benchmarks show TATTOO improves downstream policy LRMs by 30.9% and outperforms Qwen-2.5-Math-PRM-72B using only 8B parameters. This enables practitioners to enhance LRM performance in tabular reasoning tasks with more reliable step-level supervision and efficient tool utilization. |
| Natural Language Processing | Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and
  Synthesis for SLMs (Read more on [arXiv](https://arxiv.org/abs/2509.24107) or [HuggingFace](https://huggingface.co/papers/2509.24107))|  | The paper introduces Fathom-DeepResearch, a tool-integrated agentic system for long-horizon information retrieval and synthesis in SLMs. It aims to improve DeepResearch agents' performance on complex, open-ended information-seeking tasks. The system comprises Fathom-Search-4B, a DeepSearch model trained with DUETQA, RAPO, and steerable step-level rewards, and Fathom-Synthesizer-4B, for converting DeepSearch traces into structured reports. Fathom-DeepResearch achieves state-of-the-art performance on DeepSearch benchmarks and strong generalization to diverse reasoning tasks, with accuracy reaching 90.0% on SimpleQA. This framework provides AI practitioners with an effective open-weights solution for building robust and scalable DeepResearch agents. |
| Natural Language Processing | Fast-dLLM v2: Efficient Block-Diffusion LLM (Read more on [arXiv](https://arxiv.org/abs/2509.26328) or [HuggingFace](https://huggingface.co/papers/2509.26328))|  | Fast-dLLM v2 introduces an efficient block diffusion language model (dLLM) that adapts pretrained autoregressive (AR) models for parallel text generation. The paper addresses the limitation of sequential decoding in AR models by proposing a block diffusion mechanism combined with a complementary attention mask. This approach achieves up to 2.5x speedup over standard AR decoding while maintaining or surpassing AR baseline accuracy on diverse benchmarks. Fast-dLLM v2 requires only ~1B tokens for fine-tuning, a significant reduction compared to other diffusion LLMs, such as Dream. The main implication is that this marks a step toward practical deployment of fast and accurate LLMs. |
| Natural Language Processing | CoDA: Coding LM via Diffusion Adaptation (Read more on [arXiv](https://arxiv.org/abs/2510.03270) or [HuggingFace](https://huggingface.co/papers/2510.03270))|  | The paper introduces CoDA, a 1.7B-parameter diffusion language model for code generation. It investigates the potential of diffusion models for code generation by addressing the limitations of autoregressive models. The methodology involves pre-training, mid-training with code-centric datasets, and instruction tuning to adapt a Qwen3 backbone to a diffusion objective. On the Humaneval benchmark, CoDA-1.7B-Instruct achieves performance comparable to diffusion models with up to 7B parameters. This suggests that lightweight diffusion models can provide competitive coding assistance with bidirectional context and infilling capabilities while maintaining interactive latency. |
| Natural Language Processing | Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model
  Reasoning (Read more on [arXiv](https://arxiv.org/abs/2510.04081) or [HuggingFace](https://huggingface.co/papers/2510.04081))| Zhuoshi Pan, Xin Gao, Qizhi Pei, Honglin Lin, apeters | The paper introduces Caco, a framework for automating the synthesis of high-quality, verifiable, and diverse instruction-CoT reasoning data using code-driven augmentation. Caco aims to address the limitations of existing CoT prompting methods, such as uncontrolled generation and insufficient quality, by grounding reasoning in executable code. It fine-tunes a code-based CoT generator, scales data generation with automated validation and rule-based filtering, and reverse-engineers filtered outputs into natural language instructions. Experiments show that Caco-trained models achieve a strong competitive performance on mathematical reasoning benchmarks, for example, attaining 92.6% accuracy on GSM8K. The results suggest that Caco provides a paradigm for building self-sustaining, trustworthy reasoning systems without human intervention, leading to improved generalization in reasoning tasks. |
| Reinforcement Learning | ASPO: Asymmetric Importance Sampling Policy Optimization (Read more on [arXiv](https://arxiv.org/abs/2510.06062) or [HuggingFace](https://huggingface.co/papers/2510.06062))| Xiu Li, Wenping Hu, Lei Lin, Jiakang Wang, RyanLiu112 | The paper introduces Asymmetric Importance Sampling Policy Optimization (ASPO) to address mismatched importance sampling ratios in Outcome-Supervised Reinforcement Learning (OSRL) for Large Language Models (LLMs). It aims to rectify unbalanced token weighting by flipping the IS ratios of positive-advantage tokens and incorporating a soft dual-clipping mechanism. ASPO was evaluated on coding and mathematical reasoning benchmarks, showing improved training stability and mitigated premature convergence. The results demonstrated that ASPO achieves a 12.5% improvement in math tasks and 17.0% on coding tasks over the base model. This suggests that correcting IS ratios in LLM RL can significantly enhance performance and training dynamics. |
| Natural Language Processing | Mixing Mechanisms: How Language Models Retrieve Bound Entities
  In-Context (Read more on [arXiv](https://arxiv.org/abs/2510.06182) or [HuggingFace](https://huggingface.co/papers/2510.06182))|  | This paper investigates how language models retrieve bound entities in-context, challenging the prevailing view of a purely positional mechanism. The study examines the interplay of positional, lexical, and reflexive mechanisms in entity retrieval, particularly as the context grows more complex. The methodology involves extensive experiments across nine models and ten binding tasks, using interchange interventions to isolate each mechanism's contribution. Results indicate that LMs supplement the positional mechanism with lexical and reflexive retrieval, achieving up to 95% agreement between a causal model combining these mechanisms and the next token distribution. The findings imply that practitioners should consider the multifaceted approach to entity retrieval in LMs, moving beyond a reliance on purely positional understanding for in-context learning. |
| Machine Learning | AInstein: Assessing the Feasibility of AI-Generated Approaches to
  Research Problems (Read more on [arXiv](https://arxiv.org/abs/2510.05432) or [HuggingFace](https://huggingface.co/papers/2510.05432))| Jose Dolz, Laurent Charlin, Marco Pedersoli, Gaurav Sahu, Shambhavi Mishra | This paper introduces AInstein, a framework to assess if LLMs can solve AI research problems using only pre-trained knowledge. The research questions ask if LLMs can generate valid solutions to AI problems without external aids or fine-tuning. AInstein distills problems from ICLR papers and uses LLMs to propose and refine solutions via iterative critique loops, mimicking the scientific process. Evaluation on 1,214 ICLR papers using an LLM-as-a-judge reveals that LLMs can rediscover feasible solutions with a success rate of up to 74.05% but struggle with perfect rediscovery. These findings highlight both the potential and current limitations of LLMs as autonomous scientific problem-solvers. |
| Natural Language Processing | Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning? (Read more on [arXiv](https://arxiv.org/abs/2510.06036) or [HuggingFace](https://huggingface.co/papers/2510.06036))|  | The paper investigates the vulnerability of safety alignment in large reasoning models (LRMs), finding that refusal intentions often diminish sharply before output generation, termed as the "refusal cliff." It seeks to determine the mechanism causing safety alignment vulnerability. A linear probing approach reveals refusal suppression heads contributing to this cliff, evidenced by ablating just 3% of these heads reducing attack success rates below 10%. Based on this, a novel data selection method, Cliff-as-a-Judge, uses these insights to select training data for efficient safety repair, achieving comparable safety improvements using only 1.7% of vanilla safety training data. This implies a less-is-more strategy for safety alignment in LRMs, requiring targeted interventions to address specific vulnerabilities, offering a new alignment strategy. |
| Computer Vision | HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video (Read more on [arXiv](https://arxiv.org/abs/2510.05560) or [HuggingFace](https://huggingface.co/papers/2510.05560))| Katelyn Gao, Quentin Leboutet, Hao-Yu Hsu, Chih-Hao Lin, Hongchi Xia | The paper presents HoloScene, a novel framework for reconstructing simulation-ready, interactive 3D worlds from a single video input. It addresses the challenge of achieving complete geometry, physical plausibility, and realistic rendering simultaneously in 3D reconstruction. HoloScene employs a comprehensive scene-graph representation and formulates reconstruction as an energy-based optimization problem combining observational data, physical constraints, and generative priors. Evaluations on benchmark datasets demonstrate superior performance; for example, achieving a stable reconstruction rate of 95.7% on the Replica dataset. The framework enables applications in interactive gaming and real-time digital-twin manipulation, providing AI practitioners with a robust tool for digitizing and interacting with real-world environments. |
| Natural Language Processing | TensorBLEU: Vectorized GPU-based BLEU Score Implementation for
  Per-Sentence In-Training Evaluation (Read more on [arXiv](https://arxiv.org/abs/2510.05485) or [HuggingFace](https://huggingface.co/papers/2510.05485))|  | The paper introduces TensorBLEU, a GPU-accelerated implementation of the BLEU metric for per-sentence, in-training evaluation. It addresses the computational bottleneck of evaluating text generation quality within training loops, particularly in reinforcement learning scenarios. TensorBLEU employs a vectorized approach with a memory-efficient n-gram counting mechanism using `torch.unique` to avoid memory explosion. Benchmarking shows TensorBLEU achieves speedups of over 13x on consumer-grade GPUs and over 40x on data-center GPUs compared to a CPU-based NLTK implementation. This significantly reduces evaluation time, transforming it from a potential bottleneck into a negligible overhead, thus accelerating research in areas like RL-based model fine-tuning. |
| Machine Learning | Margin Adaptive DPO: Leveraging Reward Model for Granular Control in
  Preference Optimization (Read more on [arXiv](https://arxiv.org/abs/2510.05342) or [HuggingFace](https://huggingface.co/papers/2510.05342))| sirano1004 | This paper introduces Margin-Adaptive Direct Preference Optimization (MADPO), a novel method for preference optimization in large language models. It addresses the limitation of fixed temperature parameters in DPO by adaptively re-weighting the DPO loss based on the preference margin, aiming to improve training on diverse data by amplifying hard examples and dampening easy ones. The approach involves training a reward model to estimate preference margins, which are then used to weight the DPO loss for each sample. Experiments on sentiment generation tasks demonstrate that MADPO outperforms strong baselines, achieving performance gains of up to +33.3% on high-quality data and +10.5% on low-quality data compared to the next-best method. MADPO offers AI practitioners a more robust and data-efficient approach to preference alignment by providing granular, instance-level control over the learning signal. |
| Multi-Modal | Discrete Diffusion Models with MLLMs for Unified Medical Multimodal
  Generation (Read more on [arXiv](https://arxiv.org/abs/2510.06131) or [HuggingFace](https://huggingface.co/papers/2510.06131))|  | The paper introduces MeDiM, a discrete diffusion model for unified medical multimodal generation. It addresses the challenge of integrating diverse medical data by learning shared distributions across modalities without modality-specific components. MeDiM employs a multimodal large language model (MLLM) as its diffusion backbone, removing the causal attention mask for bidirectional information flow. The model achieves a Fréchet Inception Distance (FID) of 16.60 on MIMIC-CXR and a METEOR score of 0.2650 for report generation. This offers AI practitioners a versatile framework for generating and aligning diverse medical data types, such as images and reports. |
| Machine Learning | MixReasoning: Switching Modes to Think (Read more on [arXiv](https://arxiv.org/abs/2510.06052) or [HuggingFace](https://huggingface.co/papers/2510.06052))|  | The paper introduces MixReasoning, a novel framework for dynamically adjusting the reasoning depth in large language models. It addresses the redundancy inherent in uniform chain-of-thought reasoning by allocating detailed computation to pivotal steps and concise inference to simpler ones. MixReasoning employs a LoRA adapter and token-level uncertainty to switch between reasoning modes. Experiments on GSM8K show MixReasoning reduces tokens by 47% while improving accuracy by 1.01% using QwQ-32B-Preview, suggesting it achieves a better accuracy-efficiency trade-off. The framework enables more efficient and human-readable reasoning in AI systems without compromising performance. |
| Computer Vision | LightCache: Memory-Efficient, Training-Free Acceleration for Video
  Generation (Read more on [arXiv](https://arxiv.org/abs/2510.05367) or [HuggingFace](https://huggingface.co/papers/2510.05367))| Zheng Zhan, Yushu Wu, Kaiyuan Deng, Gen Li, Yang Xiao | The paper introduces LightCache, a memory-efficient and training-free method for accelerating video generation based on diffusion models. The research addresses the substantial memory surges in the denoising and decoding stages of diffusion model inference. LightCache employs asynchronous cache swapping, feature chunking, and latent slicing to reduce memory consumption while maintaining inference speed. Experiments show LightCache achieves up to 2.86x acceleration with 8.0 GB memory reduction on AnimateDiff-Lightning. LightCache provides AI practitioners with a practical approach to reduce the memory footprint of video generation tasks without requiring additional training. |
| Natural Language Processing | Demystifying deep search: a holistic evaluation with hint-free multi-hop
  questions and factorised metrics (Read more on [arXiv](https://arxiv.org/abs/2510.05137) or [HuggingFace](https://huggingface.co/papers/2510.05137))|  | This paper presents WebDetective, a novel benchmark for evaluating deep search capabilities in web agents, focusing on hint-free multi-hop question answering. The research addresses limitations in existing benchmarks by removing reasoning path hints and introducing factorized metrics to assess search sufficiency, knowledge utilization, and refusal behavior. Experiments on 25 state-of-the-art models reveal systematic weaknesses, including knowledge utilization despite sufficient evidence and lack of appropriate refusal; the strongest models reach only ~50% Pass@1. To address these challenges, the authors propose EvidenceLoop, an agentic workflow incorporating verification loops and evidence tracking, which improves both search and synthesis capabilities, increasing the Pass@1 metric to 25% from a baseline, though this increase is minimal. The work implies that future research should focus on improving autonomous reasoning systems' ability to discover reasoning paths rather than pattern-following agents. |
| Natural Language Processing | BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language
  Models via Lens of Dynamic Interactions (Read more on [arXiv](https://arxiv.org/abs/2510.05318) or [HuggingFace](https://huggingface.co/papers/2510.05318))| Shipei Lin, Per Jacobsson, Jinyang Li, Xiaohan Xu, Nan Huo | This paper introduces BIRD-INTERACT, a new benchmark for evaluating text-to-SQL capabilities of LLMs in dynamic, multi-turn interaction scenarios. The research addresses the gap in existing benchmarks by creating a realistic interactive environment that combines ambiguous queries, hierarchical knowledge bases, and user simulators. Their methodology includes a novel two-stage function-driven user simulator and two evaluation settings: protocol-guided (c-Interact) and agentic (a-Interact). Results show that the flagship model, GPT-5, achieves only 8.67% success in c-Interact and 17.00% in a-Interact on the full task suite. These findings highlight the importance of effective interaction strategies for achieving success in complex, dynamic text-to-SQL tasks. |
| Natural Language Processing | VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation (Read more on [arXiv](https://arxiv.org/abs/2510.05156) or [HuggingFace](https://huggingface.co/papers/2510.05156))|  | The paper introduces VeriGuard, a framework for enhancing the safety of LLM agents through verified code generation. It addresses the challenge of guaranteeing agent adherence to safety constraints via a dual-stage architecture involving offline validation and online action monitoring. The methodology includes synthesizing behavioral policies, subjecting them to testing and formal verification using the Nagini verifier, and implementing runtime monitoring. Experiments on the Agent Security Bench (ASB) show VeriGuard achieves near-zero attack success rate while improving task success rate compared to baselines. This allows for more trustworthy deployment of LLM agents in sensitive environments. |
| Natural Language Processing | CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support
  Conversation (Read more on [arXiv](https://arxiv.org/abs/2510.05122) or [HuggingFace](https://huggingface.co/papers/2510.05122))|  | The paper introduces CARE, a novel framework that enhances cognitive reasoning in emotional support conversations (ESC). It addresses the lack of deep cognitive reasoning in existing ESC models by leveraging the original ESC training set to guide models in generating logically coherent and supportive responses. The methodology involves supervised fine-tuning and reinforcement learning to refine the reasoning process. Experimental results demonstrate that CARE significantly improves the logical soundness and supportive quality of responses, achieving a strategy accuracy of 30.29% on the ESConv dataset. CARE offers AI practitioners a method to improve empathy and coherence in conversational agents without relying on large-scale synthetic data. |
| Multi-Modal | CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical
  Contrastive Decoding (Read more on [arXiv](https://arxiv.org/abs/2509.23379) or [HuggingFace](https://huggingface.co/papers/2509.23379))|  | This paper presents Clinical Contrastive Decoding (CCD), a novel inference framework to mitigate medical hallucinations in radiology Multimodal Large Language Models (MLLMs). The research aims to improve the clinical fidelity of radiology reports generated by MLLMs by integrating structured clinical signals from task-specific expert models. CCD introduces a dual-stage contrastive mechanism to refine token-level logits during generation. Experiments on the MIMIC-CXR dataset show a 17% improvement in RadGraph-F1 using state-of-the-art models. The findings suggest that lightweight and generalisable solutions, like CCD, can effectively bridge expert models and MLLMs in radiology, improving the reliability of AI systems. |
| Computer Vision | EgoNight: Towards Egocentric Vision Understanding at Night with a
  Challenging Benchmark (Read more on [arXiv](https://arxiv.org/abs/2510.06218) or [HuggingFace](https://huggingface.co/papers/2510.06218))| Tianwen Qian, Yang Miao, Runyi Yang, Yuqian Fu, dehezhang2 | The paper introduces EgoNight, a new benchmark for egocentric vision understanding in nighttime conditions. It aims to address the lack of datasets focusing on low-light egocentric vision by providing aligned day-night video pairs from synthetic and real-world sources. The key methodology involves constructing EgoNight-VQA, a visual question answering dataset with 3658 QA pairs, and evaluating state-of-the-art MLLMs.  Experiments revealed a significant performance drop in MLLMs from day to night, underscoring the challenges of low-light reasoning, with a best accuracy of 30.93% achieved by GPT-4.1. EgoNight provides a valuable resource for developing robust egocentric vision models that generalize across diverse illumination conditions. |
| Multi-Modal | No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language
  Models (Read more on [arXiv](https://arxiv.org/abs/2510.03978) or [HuggingFace](https://huggingface.co/papers/2510.03978))| Xiao Xiao Sun, Vishwesh Nath, Javier Gamazo Tejero, Alejandro Lozano, Min Woo Sun | The paper introduces a method to improve biomedical vision-language models by leveraging longer context windows during pretraining. The research aims to address the limitation of short text windows in existing VLMs, which leads to truncation of long-format biomedical captions. The key methodology involves pretraining CLIP on BIOMEDICA and BIOMEDICA-LongCAP datasets, varying context lengths from 77 to 512 tokens and introducing BMC-LongCLIP. The model achieves up to +30% absolute gains in Recall@1 on long-caption retrieval benchmarks and +2% average improvements in classification accuracy. The study suggests that long-context modeling is a promising direction for enhancing biomedical VLMs, improving both retrieval and classification performance. |
| Machine Learning | Equilibrium Matching: Generative Modeling with Implicit Energy-Based
  Models (Read more on [arXiv](https://arxiv.org/abs/2510.02300) or [HuggingFace](https://huggingface.co/papers/2510.02300))|  | The paper introduces Equilibrium Matching (EqM), a generative modeling framework leveraging implicit energy-based models and equilibrium dynamics. It aims to improve generative performance by learning the equilibrium gradient of an implicit energy landscape, discarding time-conditional dynamics of traditional diffusion models. EqM achieves a state-of-the-art FID of 1.90 on ImageNet 256x256 generation. The framework enables optimization-based sampling with adjustable compute and naturally supports partially noised input denoising, OOD detection, and image composition. This approach provides a tighter bridge between flow and energy-based models, simplifying optimization-driven inference. |
| Computer Vision | Human3R: Everyone Everywhere All at Once (Read more on [arXiv](https://arxiv.org/abs/2510.06219) or [HuggingFace](https://huggingface.co/papers/2510.06219))| Yuliang Xiu, Anpei Chen, Yuxuan Xue, Xingyu Chen, Yue Chen | Human3R is a unified, feed-forward framework for online 4D human-scene reconstruction from monocular videos. The paper addresses the challenge of jointly recovering global multi-person SMPL-X bodies, dense 3D scene geometry, and camera trajectories in real-time. It achieves this through parameter-efficient visual prompt tuning of a 4D online reconstruction model, CUT3R. Trained on the relatively small BEDLAM dataset for one day on one GPU, Human3R reconstructs multiple humans and 3D scenes in real-time (15 FPS) with low memory footprint (8 GB). Human3R achieves state-of-the-art or competitive performance across tasks like global human motion estimation, demonstrating a unified and efficient approach suitable for various downstream applications. |
| Computer Vision | Deforming Videos to Masks: Flow Matching for Referring Video
  Segmentation (Read more on [arXiv](https://arxiv.org/abs/2510.06139) or [HuggingFace](https://huggingface.co/papers/2510.06139))| Chengzu Li, Sizhe Dang, Liuzhuozheng Li, Dengyang Jiang, Zanyi Wang | The paper introduces FlowRVS, a novel framework for Referring Video Object Segmentation (RVOS) that reformulates the task as a conditional continuous flow problem. It addresses the limitations of existing 'locate-then-segment' pipelines by learning a language-guided deformation from video representations to target masks using flow matching. The key methodology involves a boundary-biased sampling strategy, direct video injection, and task-specific VAE adaptation to leverage pre-trained text-to-video (T2V) models. FlowRVS achieves state-of-the-art results, including a J&F score of 51.1 on MeViS, a +1.6 improvement over prior SOTA. The framework demonstrates the potential of modeling video understanding tasks as continuous deformation processes, offering a more effective approach to RVOS. |
| Natural Language Processing | Distributional Semantics Tracing: A Framework for Explaining
  Hallucinations in Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2510.06107) or [HuggingFace](https://huggingface.co/papers/2510.06107))| Jacobo Azcona, Kevin Allan, Somayajulu G Sripada, gagan3012 | The paper introduces Distributional Semantics Tracing (DST), a framework to explain and trace hallucinations in Large Language Models (LLMs).  It aims to pinpoint the architectural origins of hallucinations by identifying the layer where a model's internal representations irreversibly diverge from factuality. DST integrates interpretability techniques to create a causal map of the model's reasoning process, treating meaning as a function of context. Using DST, the authors observe a conflict between associative and contextual pathways, negatively correlated with hallucination rates (p = -0.863). The study provides a mechanistic understanding of how, when, and why hallucinations occur, offering a foundation for developing more reliable LLMs. |
| Machine Learning | Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI
  Models for Scatterplot-Related Tasks (Read more on [arXiv](https://arxiv.org/abs/2510.06071) or [HuggingFace](https://huggingface.co/papers/2510.06071))| Pedro Bizarro, Rita Costa, Diogo Duarte, joaompalmeiro | The paper introduces a new synthetic, annotated dataset and benchmark (BIY) for evaluating AI models on scatterplot-related tasks. It aims to address the gap in existing benchmarks for scatterplot-specific analyses such as clustering and outlier detection. The study evaluates several models, including OpenAI and Google proprietary models, using N-shot prompting on tasks derived from cluster and outlier annotations. Results show that models like Gemini 2.5 Flash achieve over 90% accuracy in outlier counting, though localization tasks perform poorly with precision and recall near or below 50%. The BIY dataset provides AI practitioners with a tool for assessing the robustness of models on a common visualization type. |
| Natural Language Processing | A Contextual Quality Reward Model for Reliable and Efficient Best-of-N
  Sampling (Read more on [arXiv](https://arxiv.org/abs/2510.04087) or [HuggingFace](https://huggingface.co/papers/2510.04087))| sirano1004 | The paper introduces a contextual quality reward model for improving the reliability and efficiency of Best-of-N (BoN) sampling in language models. It addresses the issue of false acceptances in standard BoN by incorporating an outside option in preference data, training reward models to distinguish between merely better and genuinely acceptable responses. The proposed method, best of mini-N in-loop, uses adaptive thresholds to partition the generation budget into sequential loops, showing a 70% reduction in reliability failures when tuned as an alignment guardrail. Alternatively, it improves inference speed by over 22% in IMDB-sentiment setting when tuned as an inference accelerator. This offers a tunable framework for managing the trade-off between reliability and computational efficiency in language model inference. |
| Natural Language Processing | DRIFT: Learning from Abundant User Dissatisfaction in Real-World
  Preference Learning (Read more on [arXiv](https://arxiv.org/abs/2510.02341) or [HuggingFace](https://huggingface.co/papers/2510.02341))| Zheli Liu, Zhaoxuan Tan, Junlin Wu, Bolian Li, AmberYifan | This paper introduces DRIFT, a novel approach to preference learning for LLMs leveraging abundant user dissatisfaction (DSAT) signals. The research aims to effectively train LLMs using readily available DSAT feedback from real-world interactions, overcoming the scarcity of explicit satisfaction signals. DRIFT anchors training on real-world DSAT signals and dynamically samples positives from the evolving policy using direct preference optimization. Experiments on WildFeedback datasets show DRIFT achieves up to +6.23% improvement on the WildBench Task Score and +8.95% on AlpacaEval2 win rate. DRIFT provides an effective and scalable method for aligning LLMs using easily accessible, real-world feedback. |
| Machine Learning | Training Dynamics Impact Post-Training Quantization Robustness (Read more on [arXiv](https://arxiv.org/abs/2510.06213) or [HuggingFace](https://huggingface.co/papers/2510.06213))| Jonas Geiping, Niccolò Ajroldi, Albert Catalan-Tatjer | This paper analyzes the relationship between training dynamics and post-training quantization (PTQ) robustness in large language models (LLMs). It investigates how training hyperparameters affect quantization error across various open-source LLM training trajectories. The key methodology involves analyzing quantization error trajectories in relation to learning rate schedules, finding that quantization error diverges with learning rate decay, independent of training data scale. Controlled experiments reveal that strategic training hyperparameter interventions, such as optimized learning rate schedules and weight averaging, can improve quantization quality, and experiments show models can be quantized to 3 bits or 4 bits with minimal degradation. The findings suggest that PTQ robustness can be improved through careful hyperparameter tuning during pretraining. |
| Machine Learning | Revisiting Modeling and Evaluation Approaches in Speech Emotion
  Recognition: Considering Subjectivity of Annotators and Ambiguity of Emotions (Read more on [arXiv](https://arxiv.org/abs/2510.05934) or [HuggingFace](https://huggingface.co/papers/2510.05934))|  | This dissertation explores novel modeling and evaluation approaches for speech emotion recognition (SER) by incorporating annotator subjectivity and emotion ambiguity. The research addresses whether to remove minority emotion ratings, limit learning to a few annotators, or predict single emotions. It introduces a label aggregation method, an all-inclusive rule, which achieved improved performance in multiple public English emotion databases. Furthermore, a penalty matrix was developed to improve SER by penalizing rare co-occurring emotions. The framework improves performance in assessing SER systems. |
| Multi-Modal | OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit
  Flows (Read more on [arXiv](https://arxiv.org/abs/2510.03506) or [HuggingFace](https://huggingface.co/papers/2510.03506))|  | The paper introduces OneFlow, a novel non-autoregressive multimodal model for concurrent and interleaved text-image generation. It aims to overcome limitations of autoregressive and diffusion models by combining an insertion-based Edit Flow for text with Flow Matching for image latents. OneFlow enables simultaneous text-image synthesis and surpasses autoregressive baselines in generation and understanding tasks, using up to 50% fewer training FLOPs. Experiments show OneFlow achieves a 4% relative improvement on VQA and 1.5% on image generation through concurrent mixed-modal pretraining. The model unlocks new capabilities for iterative refinement and reasoning-like generation, offering AI practitioners a more efficient and flexible multimodal generation approach. |
| Natural Language Processing | HalluGuard: Evidence-Grounded Small Reasoning Models to Mitigate
  Hallucinations in Retrieval-Augmented Generation (Read more on [arXiv](https://arxiv.org/abs/2510.00880) or [HuggingFace](https://huggingface.co/papers/2510.00880))| Radu State, Jérôme François, Ioana Buhnila, lrsbrgrn | The paper introduces HalluGuard, a 4B-parameter Small Reasoning Model (SRM) designed to mitigate hallucinations in Retrieval-Augmented Generation (RAG). The research aims to classify document-claim pairs as grounded or hallucinated and provide evidence-grounded justifications for transparency. HalluGuard combines a domain-agnostic synthetic dataset, synthetic grounded and hallucinated claims, and preference-based fine-tuning with Odds Ratio Preference Optimization. On the RAGTruth subset of LLM-AggreFact, HalluGuard achieves 84.0% balanced accuracy, rivaling specialized models. This allows for more trustworthy and explainable outputs in real-world RAG applications, especially in resource-constrained settings. |
