

## Papers for 2025-09-05

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Computer Vision | From Editor to Dense Geometry Estimator (Read more on [arXiv](https://arxiv.org/abs/2509.04338) or [HuggingFace](https://huggingface.co/papers/2509.04338))| Lang Nie, Rongying Liu, Lei Sun, Chunyu Lin, exander | This paper introduces FE2E, a DiT-based foundation model that leverages pre-trained image editing models for monocular dense geometry prediction. The research aims to improve zero-shot depth and normal estimation by adapting editing models, which possess inherent structural priors. The key methodology involves reformulating the editor's flow matching loss into a consistent velocity objective and using logarithmic quantization to resolve precision conflicts. FE2E achieves over 35% performance gains on the ETH3D dataset compared to other methods. The implication for AI practitioners is a data-efficient approach to dense prediction, leveraging the inherent capabilities of editing models. |
| Natural Language Processing | Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth (Read more on [arXiv](https://arxiv.org/abs/2509.03867) or [HuggingFace](https://huggingface.co/papers/2509.03867))| Chi-Li Chen, Zi Yan Chang, Chia-Yi Hsiao, Chenghao Xiao, Yang Wang | This paper introduces Drivelology, a phenomenon of nonsense with depth, and challenges LLMs' ability to understand it. The study constructs a new DRIVELHUB dataset of over 1,200 examples in multiple languages to evaluate LLMs on classification, generation, and reasoning tasks related to Drivelology. Experiments with various LLMs reveal limitations in pragmatic understanding, evidenced by performance on tasks like Drivelology Detection (81.67% accuracy) and Tagging (55.32% F1 score). The research suggests a representational gap in LLMs' ability to model linguistic depth, indicating statistical fluency does not guarantee cognitive comprehension. |
| Natural Language Processing | Towards a Unified View of Large Language Model Post-Training (Read more on [arXiv](https://arxiv.org/abs/2509.04419) or [HuggingFace](https://huggingface.co/papers/2509.04419))| Hongyi Liu, Youbang Sun, Yuxin Zuo, Xingtai Lv, iseesaw | This paper proposes a unified view of large language model post-training, integrating supervised fine-tuning (SFT) and reinforcement learning (RL) approaches. The objective is to show these methods are instances of a single optimization process. The authors derive a Unified Policy Gradient Estimator (UPGE) framework, demonstrating how SFT and RL losses can be viewed as complementary learning signals. They introduce Hybrid Post-Training (HPT), an algorithm that dynamically selects training signals, achieving a 7-point gain over a strong baseline on the AIME 2024 benchmark with Qwen2.5-Math-7B. This work offers a more principled approach to post-training, enabling practitioners to effectively combine demonstration data and exploration for enhanced model capabilities. |
| Natural Language Processing | Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow
  Real Instructions? (Read more on [arXiv](https://arxiv.org/abs/2509.04292) or [HuggingFace](https://huggingface.co/papers/2509.04292))| Yu Fu, Ruijie Miao, Xinping Lei, Qinyan Zhang, zhangysk | The paper introduces Inverse IFEval, a benchmark designed to evaluate LLMs' ability to follow counter-intuitive instructions. It investigates whether LLMs can override training-induced biases and comply with adversarial instructions across eight challenging categories. The methodology involves constructing a dataset of 1012 high-quality Chinese and English questions across 23 domains and evaluating them under an optimized LLM-as-a-Judge framework. Results show that existing LLMs exhibit cognitive inertia and struggle with counter-intuitive instructions, highlighting the need for alignment efforts that account for adaptability under unconventional contexts. The benchmark provides a diagnostic tool and foundation for developing methods to mitigate cognitive inertia and enhance the reliability of LLMs in diverse scenarios. |
| Natural Language Processing | DeepResearch Arena: The First Exam of LLMs' Research Abilities via
  Seminar-Grounded Tasks (Read more on [arXiv](https://arxiv.org/abs/2509.01396) or [HuggingFace](https://huggingface.co/papers/2509.01396))| Jiaxuan Lu, Meiqi Tu, Junchi Yu, Chen Yang, haiyuanwan | This paper introduces DeepResearch Arena, a benchmark designed to evaluate deep research agents using seminar-grounded tasks to mitigate data leakage and reflect real-world research environments. The main research question focuses on formulating high-quality research tasks to faithfully assess the ability of deep research agents. The key methodology involves a Multi-Agent Hierarchical Task Generation (MAHTG) system that extracts research-worthy inspirations from seminar transcripts and translates them into structured research tasks. Evaluation shows that current state-of-the-art agents face substantial challenges, with a KSR of 83.3% for Grok-4 on English tasks. The results imply that new benchmarks are needed which address the situated, evolving nature of real-world research. |
| Computer Vision | Transition Models: Rethinking the Generative Learning Objective (Read more on [arXiv](https://arxiv.org/abs/2509.04394) or [HuggingFace](https://huggingface.co/papers/2509.04394))| Yangguang Li, Xiangyu Yue, Xiaoyu Yue, Yiyuan Zhang, GoodEnough | The paper introduces Transition Models (TiM), a novel generative paradigm for image synthesis. It addresses the trade-off between fidelity and efficiency in generative models by learning state transitions over arbitrary time intervals. TiM analytically defines state transitions across any finite time interval âˆ†t, adapting to arbitrary-step transitions. The 865M parameter TiM model achieves state-of-the-art performance on GenEval, outperforming larger models and reaching a score of 0.67 with 1-NFE. This allows for generating high-quality images with fewer steps or refining results with more steps. |
| Natural Language Processing | NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware
  Embeddings (Read more on [arXiv](https://arxiv.org/abs/2509.04011) or [HuggingFace](https://huggingface.co/papers/2509.04011))| Oren Glickman, Yoav Goldberg, Uri Katz, Or Shachar | The paper introduces NER Retriever, a zero-shot framework for ad-hoc named entity retrieval. It aims to retrieve documents mentioning entities of user-defined types without relying on fixed schemas or fine-tuned models. The method utilizes internal representations from a mid-layer transformer block of a large language model and contrastive learning to embed both entity mentions and type descriptions into a shared semantic space. Results on three benchmarks demonstrate significant outperformance compared to lexical and dense sentence-level retrieval baselines, achieving up to four times better performance with an R-Precision of 0.34 on Few-NERD. The framework provides a practical solution for scalable, schema-free entity retrieval by leveraging type-aware embeddings. |
| Computer Vision | Few-step Flow for 3D Generation via Marginal-Data Transport Distillation (Read more on [arXiv](https://arxiv.org/abs/2509.04406) or [HuggingFace](https://huggingface.co/papers/2509.04406))| Lingxi Xie, Chen Yang, Jiemin Fang, Zanwei Zhou, thewhole | The paper introduces MDT-dist, a novel framework for accelerating 3D flow-based generative models. It addresses the challenge of slow inference in 3D generation by distilling a pre-trained model into a few-step generator via marginal-data transport learning. The method employs Velocity Matching (VM) and Velocity Distillation (VD) to optimize the transport objective by matching velocity fields and probability densities between the student and teacher models, respectively. Evaluated on TRELLIS, MDT-dist reduces sampling steps from 25 to 1-2, achieving 0.68s inference time with a 9.0x speedup on A800 while preserving visual fidelity. This approach enables faster 3D content generation, benefiting applications requiring low latency. |
| Computer Vision | Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding (Read more on [arXiv](https://arxiv.org/abs/2508.20478) or [HuggingFace](https://huggingface.co/papers/2508.20478))| Lionel Ni, Zheng Ge, Tianshui Chen, Yuan Xie | The paper introduces Video-MTR, a reinforced multi-turn reasoning framework for long-form video understanding. It addresses the challenge of long-range temporal dependencies and multiple events in videos through iterative video segment selection and question comprehension. Video-MTR employs a novel gated bi-level reward system to optimize both video segment selection and question answering, enabling end-to-end training without external VLMs. Experiments on VideoMME, MLVU, and EgoSchema show that Video-MTR outperforms existing methods, achieving 48.4% accuracy on MLVU using 32 frames. The method advances the state-of-the-art in long video understanding by facilitating more refined and contextually aware analysis. |
| Computer Vision | Durian: Dual Reference-guided Portrait Animation with Attribute Transfer (Read more on [arXiv](https://arxiv.org/abs/2509.04434) or [HuggingFace](https://huggingface.co/papers/2509.04434))| Hanbyul Joo, Byungjun Kim, Hyunsoo Cha | The paper introduces Durian, a zero-shot framework for portrait animation with attribute transfer. It addresses the challenge of high-fidelity attribute transfer in portrait animation by using dual reference networks to inject spatial features from both portrait and attribute images into a diffusion model. The model is trained with a self-reconstruction formulation, mask expansion, and augmentation strategies. Durian achieves state-of-the-art performance, reaching an L1 distance of 0.0744, and facilitates multi-attribute composition without additional training. This provides AI practitioners a new approach for generating realistic and customizable portrait animations. |
| Computer Vision | Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from
  Vector Drawings (Read more on [arXiv](https://arxiv.org/abs/2508.18733) or [HuggingFace](https://huggingface.co/papers/2508.18733))| Meie Fang, Changmiao Wang, Shichao Lu, Feiwei Qin, 1nnoh | The paper introduces Drawing2CAD, a sequence-to-sequence learning framework for generating parametric CAD models from 2D vector drawings. It addresses the challenge of automatically generating CAD models from 2D drawings by reframing it as a translation problem. The method uses a network-friendly vector representation, a dual-decoder Transformer architecture, and a soft target distribution loss. Experiments on the CAD-VGDrawing dataset show that Drawing2CAD achieves state-of-the-art performance with an Invalidity Ratio (IR) of 20.31% using four views, demonstrating its effectiveness in generating high-quality CAD models from vector drawings, enabling efficient design workflows for AI practitioners. |
| Natural Language Processing | Delta Activations: A Representation for Finetuned Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2509.04442) or [HuggingFace](https://huggingface.co/papers/2509.04442))| Ser-Nam Lim, Mayur Naik, Amish Sethi, OscarXZQ | The paper introduces Delta Activations, a method to represent finetuned large language models as vector embeddings based on shifts in internal activations. The primary research objective is to create a standalone representation that allows for effective clustering, comparison, and discovery of specialized LLMs without reliance on training data or metadata. They compute activation differences using a fixed set of generic prompts and show through experiments a silhouette score of 0.614. Delta Activations demonstrate robustness across finetuning settings and exhibit additive properties when finetuning datasets are mixed. This representation facilitates model selection and merging, enabling AI practitioners to reuse publicly available models more effectively. |
| Natural Language Processing | False Sense of Security: Why Probing-based Malicious Input Detection
  Fails to Generalize (Read more on [arXiv](https://arxiv.org/abs/2509.03888) or [HuggingFace](https://huggingface.co/papers/2509.03888))| Muhao Chen, Qin Liu, Zeming Wei, Cheng Wang | This paper investigates the generalization capabilities of probing-based malicious input detection in Large Language Models (LLMs), finding they often fail to generalize. The research question centers around why these probes show poor out-of-distribution performance, hypothesizing that they learn superficial patterns rather than semantic harmfulness. The methodology includes contrasting probe classifiers against n-gram models and using semantically cleaned datasets to remove harmful content while preserving structure. Results show that probe accuracy drops significantly (by 15-99 percentage points) on out-of-distribution data, and simple n-gram models perform comparably. This suggests that current probing-based methods provide a false sense of security and that AI practitioners should rethink safety representations for LLMs. |
