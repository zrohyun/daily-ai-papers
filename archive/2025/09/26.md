

## Papers for 2025-09-26

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines (Read more on [arXiv](https://arxiv.org/abs/2509.21320) or [HuggingFace](https://huggingface.co/papers/2509.21320))| Jiaqi Liu, Jiabei Xiao, Han Deng, Chen Tang, Yizhou Wang | The paper introduces SciReasoner, a scientific reasoning foundation model that aligns natural language with heterogeneous scientific representations. It aims to bridge the gap between natural language and scientific disciplines by supporting faithful translation, text/knowledge extraction, property prediction/classification, and sequence generation/design. The model is pre-trained on 206B tokens and fine-tuned with SFT and task-specific reward shaping. SciReasoner achieves state-of-the-art performance on 54 tasks and ranks among the top 2 on 101 tasks, demonstrating improved cross-domain generalization and fidelity. This allows AI practitioners to develop more generalizable and reliable models for scientific reasoning and discovery. |
| Multi-Modal | MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and
  Open Resources (Read more on [arXiv](https://arxiv.org/abs/2509.21268) or [HuggingFace](https://huggingface.co/papers/2509.21268))| Zhiqiang Hu, Hao Zhang, Jiaxi Li, Jing Wang, Sicong Leng | The paper introduces MMR1, a framework enhancing multimodal reasoning by addressing limitations in data and reinforcement learning stability. It aims to stabilize RL fine-tuning by proposing Variance-Aware Sampling (VAS), guided by a Variance Promotion Score (VPS) to promote reward variance and stabilize policy optimization. The methodology involves curating a large-scale dataset and employing VAS to mitigate gradient vanishing. Experiments on mathematical reasoning benchmarks demonstrate the effectiveness of the curated data and VAS, achieving a state-of-the-art performance of 58.4% average accuracy, suggesting improved convergence and stability for multimodal reasoning models. The implication is that VAS and curated datasets can enhance the training and performance of multimodal reasoning models for complex tasks, providing a solid foundation for future research. |
| Reinforcement Learning | VCRL: Variance-based Curriculum Reinforcement Learning for Large
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2509.19803) or [HuggingFace](https://huggingface.co/papers/2509.19803))| Yuewei Zhang, Chuzhan Hao, Guofeng Quan, Wenfeng Feng, Guochao Jiang | The paper introduces Variance-based Curriculum Reinforcement Learning (VCRL) to improve LLMs' mathematical reasoning by dynamically controlling training sample difficulty. VCRL addresses the limitations of existing rollout-based RL methods by focusing on samples with high reward variance, which indicates the LLM is learning effectively. The method incorporates a memory bank and replay learning to improve training stability and efficiency. Experiments on five mathematical benchmarks demonstrate that VCRL outperforms existing LLM RL baselines, achieving an average score of 57.76 on Qwen3-8B-Base, a 4.67 point increase over the strongest baseline GSPO. This approach offers AI practitioners a more effective strategy for enhancing LLMs' reasoning capabilities. |
| Reinforcement Learning | Tree Search for LLM Agent Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2509.21240) or [HuggingFace](https://huggingface.co/papers/2509.21240))| Xiangxiang Chu, Guanhua Chen, Yong Wang, Ziyu Ma, Yuxiang Ji | The paper introduces Tree-GRPO, a tree-search-based reinforcement learning method for LLM agents to address sparse supervision in long-term tasks. It aims to improve learning efficiency by constructing stepwise process-supervised signals derived from outcome rewards and sharing trajectory prefixes via tree search. The methodology involves estimating group relative advantages on intra-tree and inter-tree levels, implicitly performing step-level preference learning. Experiments across 11 datasets demonstrate Tree-GRPO's superiority, achieving up to 69% relative improvement over chain-based methods in multi-hop question answering tasks. The results suggest that tree-based exploration can enhance LLM agent training under limited rollout budgets by more effectively utilizing process supervision signals. |
| Computer Vision | Seedream 4.0: Toward Next-generation Multimodal Image Generation (Read more on [arXiv](https://arxiv.org/abs/2509.20427) or [HuggingFace](https://huggingface.co/papers/2509.20427))| Meng Guo, Lixue Gong, Yu Gao, Yunpeng Chen, Team Seedream | Seedream 4.0 is a multimodal image generation system unifying text-to-image synthesis, image editing, and multi-image composition. The research focuses on developing an efficient diffusion transformer and VAE to reduce image tokens and accelerate high-resolution image generation. They employ multimodal post-training with a VLM and inference acceleration techniques like adversarial distillation and quantization. The system achieves inference times of up to 1.4 seconds for generating a 2K image without an LLM/VLM as PE model. Seedream 4.0 demonstrates state-of-the-art results in T2I and multimodal image editing, allowing for more interactive and multidimensional creative tools for practitioners. |
| Computer Vision | Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D
  Assets (Read more on [arXiv](https://arxiv.org/abs/2509.21245) or [HuggingFace](https://huggingface.co/papers/2509.21245))| Hongyu Yan, Haolin Liu, Chunchao Guo, Bowen Zhang, Team Hunyuan3D | Hunyuan3D-Omni is a unified framework for fine-grained, controllable 3D asset generation. It addresses the limitations of existing 3D generation methods by integrating point clouds, voxels, bounding boxes, and skeleton priors as conditioning signals. The model uses a single cross-modal architecture with a progressive, difficulty-aware sampling strategy to handle various input modalities. Experiments demonstrate improved generation accuracy and geometry-aware transformations. The enhanced controllability and robustness facilitates more effective and geometry-aware 3D asset creation workflows. |
| Natural Language Processing | AutoIntent: AutoML for Text Classification (Read more on [arXiv](https://arxiv.org/abs/2509.21138) or [HuggingFace](https://huggingface.co/papers/2509.21138))| Denis Kuznetsov, Darina Rustamova, Roman Solomatin, Ilya Alekseev | AutoIntent is an AutoML framework for text classification tasks, offering end-to-end automation. The paper addresses the need for comprehensive hyperparameter optimization in AutoML for NLP, specifically for multi-label classification and out-of-scope detection. AutoIntent sequentially optimizes embedding model selection, classifier settings, and decision thresholds using a modular, sklearn-like interface. Evaluation on standard intent classification datasets demonstrates superior performance compared to existing AutoML tools, achieving an average accuracy of 93.45% on several datasets with "classic-medium" AutoIntent settings. This framework enables practitioners to balance effectiveness and resource consumption more effectively in intent classification tasks. |
| Natural Language Processing | TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them (Read more on [arXiv](https://arxiv.org/abs/2509.21117) or [HuggingFace](https://huggingface.co/papers/2509.21117))| Zhuohao Yu, Xuanwang Zhang, Tingyuan Zhu, Yunze Song, Yidong Wang | The paper addresses inconsistencies in LLM-as-a-judge frameworks. It investigates score-comparison and pairwise transitivity inconsistencies arising from information loss and ambiguous tie judgments. TrustJudge, a probabilistic framework, is proposed, using distribution-sensitive scoring and likelihood-aware aggregation to mitigate these issues. Experiments show that TrustJudge reduces score-comparison inconsistency by 8.43% and pairwise transitivity inconsistency by 10.82% using Llama-3.1-70B-Instruct. The framework enhances the reliability of automated LLM evaluation without additional training or annotations, offering practical solutions for AI practitioners. |
| Reinforcement Learning | CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy
  Optimization in Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2509.20712) or [HuggingFace](https://huggingface.co/papers/2509.20712))| Wenping Hu, Yuntao Li, Minxuan Lv, Leiyu Pan, Zhenpeng Su | The paper introduces CE-GPPO, a novel reinforcement learning algorithm to improve policy entropy management in large language models. The research aims to address the issue of gradient signal loss in low-probability tokens caused by the clipping mechanism in PPO. CE-GPPO reintroduces gradients from clipped tokens in a bounded manner, achieving a balance between exploration and exploitation. Empirical results on mathematical reasoning benchmarks demonstrate that CE-GPPO outperforms strong baselines, achieving an average score of 67.5 on multiple benchmarks with a DeepSeek-R1-Distill-Qwen-7B model. The implication is that CE-GPPO provides AI practitioners with a more robust and controllable method for training RL models, especially for complex reasoning tasks. |
| Computer Vision | Does FLUX Already Know How to Perform Physically Plausible Image
  Composition? (Read more on [arXiv](https://arxiv.org/abs/2509.21278) or [HuggingFace](https://huggingface.co/papers/2509.21278))| Chen Zhao, Shaocong Zhang, Zihan Zhou, Zhuming Lian, Shilin Lu | This paper introduces a training-free framework, SHINE, for physically plausible image composition using diffusion models. It addresses the problem of achieving realistic lighting and handling diverse resolutions in image composition by leveraging existing physical and resolution priors in diffusion models. SHINE employs a manifold-steered anchor loss, degradation-suppression guidance, and adaptive background blending. Experiments on ComplexCompo and DreamEditBench show state-of-the-art performance with human-aligned scores, surpassing baselines and achieving better results on both DINOv2 and DreamSim metrics. SHINE offers AI practitioners a method to seamlessly integrate objects into complex scenes with high fidelity without task-specific training. |
| Computer Vision | CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling (Read more on [arXiv](https://arxiv.org/abs/2509.21114) or [HuggingFace](https://huggingface.co/papers/2509.21114))| Yushi Bai, Jingwen Ye, Wang Zhao, Yanning Zhou, Yuze He | The paper introduces CHARM, a novel framework for 3D anime hairstyle modeling using an autoregressive approach. It addresses the challenge of generating stylized anime hairstyles by proposing a compact, invertible control-point-based parameterization. The methodology involves an autoregressive transformer network trained on a curated dataset (AnimeHair) to generate hair cards sequentially. Experiments demonstrate state-of-the-art performance, achieving a Voxel-IoU of 0.7566 on a test set. This framework provides AI practitioners with an expressive and scalable solution for anime hairstyle modeling, enhancing avatar creation and digital art applications. |
| Multi-Modal | Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web
  Reconnaissance, Tool Generation, and Task Execution (Read more on [arXiv](https://arxiv.org/abs/2509.21072) or [HuggingFace](https://huggingface.co/papers/2509.21072))| Jinjie Gu, Chenyi Zhuang, Zhiwei Wang, Kaiwen He | The paper introduces Recon-Act, a self-evolving multi-agent system for browser-use tasks that leverages web reconnaissance, tool generation, and task execution. The research aims to improve the adaptability and solvability of browser-use agents in long-horizon tasks by incorporating a reconnaissance-action behavioral paradigm. Recon-Act employs a Reconnaissance Team for comparative analysis and tool generation and an Action Team for intent decomposition and execution, establishing a closed-loop training pipeline. The system achieves a 36.48% success rate on the VisualWebArena dataset, outperforming other automated agents, indicating substantial improvement in adaptability to unseen websites and solvability on long-horizon tasks. Recon-Act offers AI practitioners a framework for building more robust and adaptable browser-use agents through self-evolution and targeted tool utilization. |
| Machine Learning | V-GameGym: Visual Game Generation for Code Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2509.20136) or [HuggingFace](https://huggingface.co/papers/2509.20136))| Shawn Guo, Lingzheng Chai, Renshuai Tao, Jack Yang, Wei Zhang | The paper introduces V-GameGym, a comprehensive benchmark for evaluating code large language models (LLMs) in visual game generation. It addresses the gap between algorithmic problem-solving capabilities of LLMs and the comprehensive requirements of practical game development. V-GameGym consists of 2,219 high-quality samples across 100 thematic clusters derived from real-world repositories, adopting a novel clustering-based curation methodology.  Evaluations reveal that V-GameGym effectively captures the complexity spectrum of real-world game development tasks; models show high code generation ability but weaker visual generation capability (the top-performing models only succeed in 45% of the cases).  The benchmark provides quantifiable quality metrics for visual programming and interactive element generation, facilitating targeted improvements in LLMs for practical game development workflows. |
| Machine Learning | Interactive Recommendation Agent with Active User Commands (Read more on [arXiv](https://arxiv.org/abs/2509.21317) or [HuggingFace](https://huggingface.co/papers/2509.21317))| Xueyang Feng, Fei Sun, Xunke Xi, Yujie Luo, Jiakai Tang | This paper introduces the Interactive Recommendation Feed (IRF), a novel paradigm enabling natural language commands within recommendation feeds. The research aims to address the gap between user intentions and system interpretations by allowing users to actively control recommendation policies. The proposed RecBot architecture uses a dual-agent system with a Parser Agent and a Planner Agent to translate linguistic expressions into structured preferences and adjust recommendation policies accordingly. Through online A/B testing, RecBot demonstrates a 0.71% reduction in Negative Feedback Frequency (NFF). This approach enables more user-centric and controllable recommendation systems for AI practitioners. |
| Natural Language Processing | BESPOKE: Benchmark for Search-Augmented Large Language Model
  Personalization via Diagnostic Feedback (Read more on [arXiv](https://arxiv.org/abs/2509.21106) or [HuggingFace](https://huggingface.co/papers/2509.21106))| Dongha Lee, Kwangwook Seo, Sangam Lee, Hyunseo Kim | BESPOKE is introduced as a realistic benchmark for evaluating personalization in search-augmented LLMs. The paper addresses the under-explored systematic evaluation of personalization in LLMs by recognizing diverse user needs and preferred information forms. It constructs a diagnostic benchmark by collecting authentic chat and search histories from human annotators, paired with fine-grained preference scores and feedback. Using BESPOKE, the analysis reveals that personalization effectiveness is influenced by user context construction, and models often fall short in delivering personalized responses. The main implication is that the benchmark aids in future research on developing personalized systems for more effective information seeking. |
| Natural Language Processing | Thinking Augmented Pre-training (Read more on [arXiv](https://arxiv.org/abs/2509.20186) or [HuggingFace](https://huggingface.co/papers/2509.20186))| Furu Wei, Li Dong, Shaohan Huang, Nan Yang, Liang Wang | The paper introduces Thinking Augmented Pre-Training (TPT), a method to improve data efficiency in LLM training by augmenting text data with automatically generated thinking trajectories. It addresses the challenge of learning complex rationales for individual tokens, which are difficult to learn directly with limited model capacity. TPT augments training data with step-by-step reasoning trajectories to increase the learnability of high-quality tokens. Experiments across various model sizes demonstrate that TPT enhances data efficiency by a factor of 3 and improves post-training performance by over 10% on reasoning benchmarks for a 3B parameter model. The implication is that TPT provides a scalable approach for improving LLM performance without requiring extensive data or human annotation. |
| Reinforcement Learning | Residual Off-Policy RL for Finetuning Behavior Cloning Policies (Read more on [arXiv](https://arxiv.org/abs/2509.19301) or [HuggingFace](https://huggingface.co/papers/2509.19301))| Pieter Abbeel, Guanya Shi, Rocky Duan, Zhenyu Jiang, Lars Ankile | The paper introduces ResFiT, a residual reinforcement learning method for fine-tuning behavior cloning (BC) policies. The research focuses on improving BC policies through sample-efficient off-policy RL by learning residual corrections. The method leverages a black-box BC policy and sparse binary rewards to learn per-step residual adjustments. Results demonstrate state-of-the-art performance in simulation and successful real-world RL training on a humanoid robot with dexterous hands, achieving a boost from 14% to 64% in a ball pick-and-place task. ResFiT offers a practical approach for enhancing visuomotor control policies in high-DoF systems, making RL deployment more feasible. |
| Computer Vision | SD3.5-Flash: Distribution-Guided Distillation of Generative Flows (Read more on [arXiv](https://arxiv.org/abs/2509.21318) or [HuggingFace](https://huggingface.co/papers/2509.21318))| Yi-Zhe Song, Reshinth Adithyan, Jim Scott, Rahim Entezari, Hmrishav Bandyopadhyay | The paper introduces SD3.5-Flash, a framework for efficient few-step distillation of generative flows for high-quality image generation on consumer devices. It addresses the challenge of distribution matching in few-step regimes by introducing timestep sharing and split-timestep fine-tuning to improve stability and prompt alignment. The key methodology involves reformulating the distribution matching objective, text encoder restructuring, and specialized quantization to enable rapid generation and memory-efficient deployment. Results demonstrate SD3.5-Flash outperforms existing methods, achieving competitive image quality and faster inference times. This makes advanced generative AI accessible across a wide range of devices, potentially democratizing access to AI-driven image generation. |
| Computer Vision | Quantized Visual Geometry Grounded Transformer (Read more on [arXiv](https://arxiv.org/abs/2509.21302) or [HuggingFace](https://huggingface.co/papers/2509.21302))| Yuqi Li, Chuanguang Yang, Mingqiang Wu, Haotong Qin, Weilun Feng | The paper introduces QuantVGGT, a novel quantization framework for Visual Geometry Grounded Transformers (VGGTs) to address the challenges of high computational costs and memory requirements for 3D reconstruction. It aims to effectively quantize VGGTs to W4A4 precision without significantly compromising visual quality. The methodology incorporates Dual-Smoothed Fine-Grained Quantization and Noise-Filtered Diverse Sampling to mitigate heavy-tailed activation distributions and ensure stable quantization ranges. Experiments show QuantVGGT achieves state-of-the-art results, delivering a 3.7x memory reduction and 2.5x acceleration while maintaining reconstruction accuracy above 98% of the full-precision counterpart. QuantVGGT offers a practical solution for deploying billion-scale 3D reconstruction models in resource-constrained scenarios. |
| Computer Vision | SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and
  Self-Reflective Agent (Read more on [arXiv](https://arxiv.org/abs/2509.20414) or [HuggingFace](https://huggingface.co/papers/2509.20414))| Siyuan Huang, Shujie Zhang, Baoxiong Jia, Yandan Yang | SceneWeaver is an agentic framework for all-in-one 3D scene synthesis, aiming to generate realistic, physically plausible, and functionally diverse scenes. The research addresses the limitations of current scene synthesis methods by unifying diverse generation paradigms via tool-based iterative refinement. SceneWeaver employs a language model-based planner to select from extensible scene generation tools, guided by self-evaluation of physical plausibility, visual realism, and semantic alignment. Experiments demonstrate that SceneWeaver outperforms existing methods on physical, visual, and semantic metrics, achieving an object count of 36.5 in open-vocabulary scene synthesis. The framework offers AI practitioners a general-purpose 3D environment generation tool extensible to diverse instructions and capable of self-reflection. |
| Machine Learning | Understanding the Thinking Process of Reasoning Models: A Perspective
  from Schoenfeld's Episode Theory (Read more on [arXiv](https://arxiv.org/abs/2509.14662) or [HuggingFace](https://huggingface.co/papers/2509.14662))| Yanbin Fu, Hong Jiao, Chenrui Fan, Nan Zhang, Ming Li | This paper introduces a novel framework for understanding the reasoning processes of Large Reasoning Models (LRMs) by applying Schoenfeld's Episode Theory. The research investigates how well LRM reasoning traces align with cognitive episodes observed in human problem-solving. The methodology involves annotating thousands of sentences from model-generated solutions to math problems using seven cognitive labels. Preliminary analysis reveals distinct patterns in LRM reasoning and transition dynamics between cognitive states, however, the exact inter-rater reliability achieved is uncertain. The findings offer a theoretically grounded methodology for interpreting LRM cognition and enabling future work on more controllable and transparent reasoning systems. |
| Machine Learning | ScaleDiff: Scaling Difficult Problems for Advanced Mathematical
  Reasoning (Read more on [arXiv](https://arxiv.org/abs/2509.21070) or [HuggingFace](https://huggingface.co/papers/2509.21070))| Yu Li, Xin Gao, Honglin Lin, Zhuoshi Pan, Qizhi Pei | The paper introduces ScaleDiff, a pipeline for scaling the creation of difficult mathematical problems to improve advanced reasoning in large language models. It addresses the limitations of existing methods by efficiently identifying difficult problems and training a specialized problem generator using adaptive thinking models. The key methodology involves training a DiffGen-8B model on filtered difficult data, then fine-tuning Qwen2.5-Math-7B-Instruct. Results show a 65.9% average accuracy on AIME'24, AIME'25, HMMT-Feb'25, BRUMO'25, and MATH500 after fine-tuning on the generated ScaleDiff-Math dataset. The implication for AI practitioners is a practical and generalizable strategy for strengthening LRMs in domains requiring complex reasoning. |
| Natural Language Processing | Behind RoPE: How Does Causal Mask Encode Positional Information? (Read more on [arXiv](https://arxiv.org/abs/2509.21042) or [HuggingFace](https://huggingface.co/papers/2509.21042))| Yeyun Gong, Lei Ji, Zhenghao Lin, Xiao Liu, Junu Kim | This paper investigates how causal masks in Transformer decoders encode positional information, even without explicit positional encodings like RoPE. Through theoretical analysis and empirical validation, the authors demonstrate that the causal mask induces position-dependent attention patterns favoring nearby query-key pairs. They further show that the interaction between causal masks and RoPE can distort the relative positional encoding of RoPE. Analysis of LLMs such as Llama-3.1-8B revealed that attention patterns are influenced by both ROPE and the causal mask, suggesting the importance of considering both for LLM performance and length generalization. The findings imply that practitioners should account for the causal mask as a source of positional information alongside explicit positional encodings when designing Transformer decoders. |
| Multi-Modal | MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for
  Video Temporal Reasoning (Read more on [arXiv](https://arxiv.org/abs/2509.21113) or [HuggingFace](https://huggingface.co/papers/2509.21113))| Yubo Gao, Junyan Zhang, Yibo Yan, Jungang Li, Sicheng Tao | MOSS-ChatV introduces a reinforcement learning framework for video temporal reasoning, addressing process inconsistency in existing MLLMs. The research aims to align reasoning traces with video dynamics using a Dynamic Time Warping (DTW)-based process reward, eliminating the need for auxiliary reward models. MOSS-ChatV achieves 87.2% accuracy on the MOSS-Video benchmark and improves performance on other video benchmarks like MVBench and MMVU. The framework's enhanced consistency and stability in reasoning traces has implications for improving the robustness of MLLMs. |
| Computer Vision | The Unanticipated Asymmetry Between Perceptual Optimization and
  Assessment (Read more on [arXiv](https://arxiv.org/abs/2509.20878) or [HuggingFace](https://huggingface.co/papers/2509.20878))| Tianhe Wu, Du Chen, Siyu Wu, Qi Wang, Jiabei Zhang | This paper investigates the relationship between perceptual optimization objectives and image quality assessment (IQA) metrics. The central question explores whether fidelity metrics effective for IQA also lead to better perceptual optimization, and if discriminator representations generalize as IQA backbones. Through a systematic analysis using single-image super-resolution (SR) as a testbed, the study reveals an asymmetry: high-performing IQA metrics don't necessarily improve perceptual optimization, especially with adversarial training. Furthermore, patch-level convolutional discriminators demonstrate more faithful detail reconstruction compared to vanilla or Transformer-based architectures, shown via improved detail clarity in SR results. These findings highlight the need for co-designing perceptual metrics and adversarial objectives for robust perceptual modeling, indicating current reliance on unimodal approaches limits potential gains. |
| Natural Language Processing | StyleBench: Evaluating thinking styles in Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2509.20868) or [HuggingFace](https://huggingface.co/papers/2509.20868))| Javad Lavaei, Costas Spanos, Ming Jin, Shangding Gu, Junyu Guo | StyleBench is a benchmark designed to evaluate reasoning styles in large language models (LLMs). The research investigates how different reasoning strategies, model architectures, and task types impact LLM performance. The methodology involves assessing five reasoning styles (CoT, ToT, AoT, SoT, CoD) on five tasks using 15 open-source models. Results show that no single style is universally optimal, with strategy efficacy contingent on model scale and task type; for instance, search-based methods excel on open-ended problems but require larger models. These findings provide a roadmap for selecting optimal reasoning strategies based on specific constraints. |
| Machine Learning | When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks
  Silently Undermine Validity (Read more on [arXiv](https://arxiv.org/abs/2509.20293) or [HuggingFace](https://huggingface.co/papers/2509.20293))| John P Dickerson, Oussama Elachqar, Astitwa Sarthak Lathe, Chiung-Yi Tseng, Benjamin Feuer | This paper investigates design failures in LLM-judged benchmarks that undermine validity, leading to noisy rankings. The study aims to quantify how much a judge's overall verdict aligns with the explicit evaluation schema and to assess the internal consistency and discriminant validity. The methodology includes novel metrics such as schematic adherence and psychometric validity applied to the Arena-Hard Auto benchmark. The results reveal schema incoherence, factor collapse (e.g., >90% unexplained variance for DeepSeek-R1-32B), and the masking of genuine ranking uncertainty due to ELO-style aggregation. The main implication is the need for reliability-aware benchmark design principles to ensure the validity of LLM-judged evaluations. |
| Computer Vision | Discrete Diffusion for Reflective Vision-Language-Action Models in
  Autonomous Driving (Read more on [arXiv](https://arxiv.org/abs/2509.20109) or [HuggingFace](https://huggingface.co/papers/2509.20109))| Hang Zhao, Huimin Wang, Yue Wang, Yinan Zheng, Pengxiang Li | The paper introduces ReflectDrive, a novel learning-based framework for safe autonomous driving trajectory generation using discrete diffusion models. It aims to address the limitations of imitation learning by integrating a reflection mechanism for safety-aware trajectory correction without gradient computation. The method discretizes the driving space and employs a Diffusion Language Model with a safety-aware reflection mechanism for iterative self-correction. Evaluated on the NAVSIM benchmark, ReflectDrive demonstrates significant advantages in safety-critical trajectory generation, achieving near human-level closed-loop performance, although specific quantitative metrics beyond "significant advantages" were not provided. This approach offers a scalable and reliable solution for autonomous driving systems by enabling the integration of safety constraints directly into the trajectory generation process. |
| Machine Learning | Thinking While Listening: Simple Test Time Scaling For Audio
  Classification (Read more on [arXiv](https://arxiv.org/abs/2509.19676) or [HuggingFace](https://huggingface.co/papers/2509.19676))| Mert Pilanci, Prateek Verma | This paper introduces a test-time scaling framework to improve audio classification by enabling models to "think while listening." The research aims to enhance audio classification performance by incorporating reasoning into existing pipelines and exploring new architectures. The proposed method samples patch-level predictions from a frozen audio classifier to build a reasoning trace, which is then refined by a frozen LLM to improve accuracy. Experiments on ESC-50 demonstrate increased top-1 accuracy with trace length, achieving performance comparable to full fine-tuning; FSD-50K experiments show AUC improvements over the baseline. The implication is that performance can be scaled by reasoning over patch-level category traces during inference without retraining, offering a complementary approach to increasing model size or training data. |
| Other | Blueprints of Trust: AI System Cards for End to End Transparency and
  Governance (Read more on [arXiv](https://arxiv.org/abs/2509.20394) or [HuggingFace](https://huggingface.co/papers/2509.20394))| Roman Zhukov, Florencio Cano Gabarda, Garth Mollett, Emily Fox, Huzaifa Sidhpurwala | This paper introduces the Hazard-Aware System Card (HASC), a novel framework designed to improve AI system transparency and accountability. The research focuses on defining a comprehensive and dynamic record of an AI system's safety posture through a standardized system of identifiers including the Al Safety Hazard (ASH) ID. The methodology involves building upon existing model and system card concepts to create a single, accessible source of truth. The paper finds that using HASC will result in developers and stakeholders to make more informed decisions about Al system safety throughout its lifecycle; quantitative metrics are not explicitly discussed in the paper, but this will be measured by the adoption of such HASC. This work has implications for practitioners needing to implement transparency and governance measures for Al systems. |
| Natural Language Processing | MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with
  Closed-Source Large-Audio Language Model (Read more on [arXiv](https://arxiv.org/abs/2509.20706) or [HuggingFace](https://huggingface.co/papers/2509.20706))| Hung-yi Lee, Yi-Cheng Lin, Hsiao-Ying Huang | The paper introduces MI-Fuse, a label fusion framework for unsupervised domain adaptation (SFUDA) in speech emotion recognition (SER) using closed-source large audio-language models (LALMs). It aims to adapt a student model to outperform an API-only LALM using only unlabeled target-domain audio. The approach fuses pseudo-labels from the LALM and a source-domain classifier, weighting them based on mutual information and stabilizing training with an EMA teacher. Experiments demonstrate a 3.9% improvement over the strongest baseline, achieving 58.38% average accuracy across six transfer settings. MI-Fuse enables emotion-aware speech systems without sharing source data, facilitating realistic adaptation scenarios. |
