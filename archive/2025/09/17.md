

## Papers for 2025-09-17

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for
  Open-Ended Deep Research (Read more on [arXiv](https://arxiv.org/abs/2509.13312) or [HuggingFace](https://huggingface.co/papers/2509.13312))| Houquan Zhou, Shen Huang, Bo Zhang, Xin Guan, Zijian Li | The paper introduces WebWeaver, a dual-agent framework for open-ended deep research (OEDR) that synthesizes web-scale information into insightful reports. It addresses limitations in current OEDR approaches by dynamically interleaving evidence acquisition with outline optimization, guided by a planner and a writer. WebWeaver achieves state-of-the-art performance across major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and DeepResearchGym, demonstrating the effectiveness of adaptive planning. Specifically, WebWeaver achieves a citation accuracy of 93.37% on DeepResearch Bench. The human-centric, iterative methodology highlights that adaptive planning and focused synthesis are crucial for producing high-quality and well-structured reports, thus providing AI practitioners with a new paradigm for tackling complex knowledge work. |
| Natural Language Processing | Scaling Agents via Continual Pre-training (Read more on [arXiv](https://arxiv.org/abs/2509.13310) or [HuggingFace](https://huggingface.co/papers/2509.13310))| Chenxi Wang, Zhuo Chen, Guangyu Li, Zhen Zhang, Liangcai Su | The paper introduces Agentic Continual Pre-training (CPT) to improve agentic capabilities in large language models. It addresses the underperformance of post-training methods by pre-aligning models for agentic tasks. AgentFounder, a model trained using Agentic CPT, leverages scalable data synthesis and a two-stage training strategy. The AgentFounder-30B achieves state-of-the-art performance on 10 benchmarks, including a 39.9% score on BrowseComp-en, demonstrating strong tool-use ability. This approach offers a pathway for building more robust agentic foundation models, ultimately streamlining downstream fine-tuning processes for enhanced AI agent development. |
| Reinforcement Learning | WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic
  Data and Scalable Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2509.13305) or [HuggingFace](https://huggingface.co/papers/2509.13305))| Yida Zhao, Rui Ye, Huifeng Yin, Zhongwang Zhang, Kuan Li | WebSailor-V2 is presented as a complete pipeline to improve open-source web agents via synthetic data and reinforcement learning. The research aims to bridge the performance gap between open-source and proprietary web agents. The methodology involves a novel data construction technique (SailorFog-QA-2) and a dual-environment RL framework. WebSailor-V2 achieves state-of-the-art results, including a score of 35.3 on BrowseComp-EN using a Qwen3-30B-A3B model. The paper implies that carefully constructed synthetic data and a scalable RL training environment are crucial for developing high-performing web agents, enabling smaller models to achieve competitive results. |
| Natural Language Processing | Towards General Agentic Intelligence via Environment Scaling (Read more on [arXiv](https://arxiv.org/abs/2509.13311) or [HuggingFace](https://huggingface.co/papers/2509.13311))| Guangyu Li, Jialong Wu, Baixuan Li, Shihao Cai, Runnan Fang | The paper explores scaling environments to improve general agentic intelligence, specifically function-calling capabilities in Large Language Models (LLMs). It addresses environment scaling and effective training by constructing fully simulated, heterogeneous environments. A two-phase fine-tuning strategy is used to endow agents with fundamental capabilities and specialize them for specific contexts. Experiments on agentic benchmarks (t-bench, t2-Bench, ACEBench) demonstrate that AgentScaler significantly enhances function-calling capability, achieving state-of-the-art performance at comparable scales. This scalable environment creation and agent fine-tuning approach offers a pathway towards more generalizable and robust agentic systems. |
| Natural Language Processing | WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon
  Agents (Read more on [arXiv](https://arxiv.org/abs/2509.13309) or [HuggingFace](https://huggingface.co/papers/2509.13309))| Wenbiao Yin, Donglei Yu, Xuanzhong Chen, Guoxin Chen, Zile Qiao | The paper introduces WebResearcher, a novel framework designed to enhance the reasoning capabilities of long-horizon AI agents. It aims to address the limitations of mono-contextual deep research approaches by introducing IterResearch, an iterative deep-research paradigm, and WebFrontier, a scalable data synthesis engine. The methodology involves reformulating deep research as a Markov Decision Process and generating high-quality training data through tool-augmented complexity escalation. Experiments across six benchmarks demonstrate that WebResearcher achieves state-of-the-art performance, surpassing existing systems, with a 36.7% accuracy on Humanity's Last Exam. The main implication is the potential for improved tool-use capabilities and sustained high-quality reasoning in complex research scenarios for AI practitioners. |
| Natural Language Processing | ReSum: Unlocking Long-Horizon Search Intelligence via Context
  Summarization (Read more on [arXiv](https://arxiv.org/abs/2509.13313) or [HuggingFace](https://huggingface.co/papers/2509.13313))| Litu Ou, Liwen Zhang, Yida Zhao, Kuan Li, Xixi Wu | The paper introduces ReSum, a novel paradigm for long-horizon web search intelligence that overcomes context window limitations in LLMs via periodic context summarization. ReSum addresses complex queries by converting interaction histories into compact reasoning states using a specialized summarization tool. ReSum-GRPO, a reinforcement learning algorithm, is proposed for paradigm adaptation, integrating GRPO with segmented trajectory training. Experiments demonstrate that ReSum delivers an average absolute improvement of 4.5% over ReAct, and up to 8.2% with ReSum-GRPO training. The primary implication is that ReSum enables indefinite exploration in web agents, facilitating solutions to knowledge-intensive tasks that were previously hindered by context constraints. |
| Reinforcement Learning | Single-stream Policy Optimization (Read more on [arXiv](https://arxiv.org/abs/2509.13232) or [HuggingFace](https://huggingface.co/papers/2509.13232))| Zihan Ding, Zhongwen Xu | This paper introduces Single-stream Policy Optimization (SPO), a novel approach to policy gradient optimization for Large Language Models. It addresses the limitations of group-based methods, like GRPO, by eliminating degenerate groups and synchronization barriers. SPO employs a persistent KL-adaptive value tracker and global advantage normalization for stable, low-variance learning. Experiments with Qwen3-8B demonstrate that SPO achieves higher accuracy than GRPO, improving the average maj@32 by +3.4 percentage points across five hard math benchmarks. The method offers a more scalable and efficient path for LLM reasoning by focusing on foundational RL principles. |
| Computer Vision | Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset
  Generation (Read more on [arXiv](https://arxiv.org/abs/2509.12815) or [HuggingFace](https://huggingface.co/papers/2509.12815))| Lixin Xu, Shuhui Yang, Xinhai Liu, Yang Li, Biwen Lei | The paper introduces Hunyuan3D Studio, an end-to-end AI pipeline for generating game-ready 3D assets from concept images or text descriptions. It aims to automate and streamline the 3D asset creation process using advanced neural modules like Part-level 3D Generation and Semantic UV. The system integrates various modules orchestrated through a unified asset graph, enabling parametric control and reversibility. Hunyuan3D Studio generates visually compelling assets adhering to game engine technical requirements, reducing iteration time and lowering entry barriers. The approach significantly accelerates content creation and democratizes 3D artistry for game development and interactive media. |
| Computer Vision | 3D Aware Region Prompted Vision Language Model (Read more on [arXiv](https://arxiv.org/abs/2509.13317) or [HuggingFace](https://huggingface.co/papers/2509.13317))| Xiaolong Li, Zhijian Liu, Yukang Chen, Yang Fu, An-Chieh Cheng | The paper introduces Spatial Region 3D (SR-3D), a vision-language model that unifies 2D images and 3D data through a shared visual token space for improved spatial reasoning. The research aims to enhance 3D scene understanding by incorporating 3D positional embeddings into 2D visual features within a foundational vision-language model. SR-3D enriches 2D features with 3D position information and delivers flexible region prompting to support accurate spatial understanding. The model achieves state-of-the-art performance on 3D question answering, demonstrating its effectiveness in unifying 2D and 3D representation spaces. SR-3D enables more accurate spatial reasoning from visual data, which benefits AI practitioners through more reliable scene understanding capabilities. |
| Natural Language Processing | EconProver: Towards More Economical Test-Time Scaling for Automated
  Theorem Proving (Read more on [arXiv](https://arxiv.org/abs/2509.12603) or [HuggingFace](https://huggingface.co/papers/2509.12603))| Shansan Gong, Jiahao Xu, Zhenwen Liang, Linfeng Song, Mukai Li | The paper introduces EconProver, a framework for more economical test-time scaling in automated theorem proving (ATP). It aims to reduce the computational cost of test-time scaling strategies like reflective Chain-of-Thought (CoT) and increased sampling passes. The methodology involves a dynamic CoT switching mechanism and diverse parallel-scaled reinforcement learning with trainable prefixes. Experiments on miniF2F demonstrate that EconProver-GD achieves comparable performance to baseline methods with only 12% of the computational cost. The main implication is providing actionable insights for deploying lightweight ATP models without sacrificing performance by optimizing token usage and sampling passes. |
| Other | Exact Coset Sampling for Quantum Lattice Algorithms (Read more on [arXiv](https://arxiv.org/abs/2509.12341) or [HuggingFace](https://huggingface.co/papers/2509.12341))| Yifan Zhang | The paper presents a simplified and corrected domain-extension method for a windowed-QFT lattice algorithm. The research addresses the periodicity/support mismatch issue in the original Step 9 of Chen (2024). The authors introduce a pair-shift difference construction to coherently cancel unknown offsets and generate an exact uniform CRT-coset state. By employing a QFT, the intended modular linear relation is enforced with poly(log M2) gates. This preserves the algorithm's asymptotics, though specific quantitative metrics are not explicitly provided beyond the gate complexity. |
| Multi-Modal | Multimodal Reasoning for Science: Technical Report and 1st Place
  Solution to the ICML 2025 SeePhys Challenge (Read more on [arXiv](https://arxiv.org/abs/2509.06079) or [HuggingFace](https://huggingface.co/papers/2509.06079))| Wentao Zhang, Junbo Niu, Bohan Zeng, Ruitao Wu, Hao Liang | This paper introduces a caption-assisted reasoning framework to improve multimodal reasoning in science-related tasks. It addresses the challenge of maintaining strong performance in multimodal scenarios, where even state-of-the-art models struggle. The proposed method leverages automatically generated or human-provided captions to bridge the gap between visual and textual modalities. The framework achieved 1st place in the ICML 2025 SeePhys competition. The results demonstrate that high-quality captions can significantly improve multimodal reasoning performance, enabling caption-only reasoning to rival or even outperform direct multimodal pipelines. |
| Computer Vision | Multiple Instance Learning Framework with Masked Hard Instance Mining
  for Gigapixel Histopathology Image Analysis (Read more on [arXiv](https://arxiv.org/abs/2509.11526) or [HuggingFace](https://huggingface.co/papers/2509.11526))| Bo Liu, Fengtao Zhou, Heng Fang, Sheng Huang, Wenhao Tang | This paper introduces a novel multiple instance learning (MIL) framework for gigapixel histopathology image analysis. It aims to address the limitations of existing MIL methods that bias towards easy-to-classify instances by incorporating masked hard instance mining (MHIM). The MHIM-MIL framework utilizes a Siamese structure with a consistency constraint to explore hard instances, employing a momentum teacher model for masking salient instances and a global recycle network to recover key features. Experimental results demonstrate that MHIM-MIL outperforms state-of-the-art methods in cancer diagnosis, subtyping, and survival analysis, improving C-index by 1.8% on TCGA-BLCA using TransMIL. The method provides AI practitioners with an efficient approach for training MIL models that can better model discriminative boundaries. |
| Natural Language Processing | Optimal Brain Restoration for Joint Quantization and Sparsification of
  LLMs (Read more on [arXiv](https://arxiv.org/abs/2509.11177) or [HuggingFace](https://huggingface.co/papers/2509.11177))| Luca Benini, Yawei Li, Hang Guo | The paper introduces Optimal Brain Restoration (OBR), a novel framework for joint quantization and sparsification of Large Language Models (LLMs). It addresses the conflicting weight distribution requirements of quantization and pruning by introducing error compensation between both. OBR leverages a second-order Hessian objective reformulated into a tractable problem via surrogate approximation and group error compensation. Experiments demonstrate W4A4KV4 quantization with 50% sparsity, achieving up to 4.72x speedup and 6.4x memory reduction compared to FP16-dense baselines on Llama2, Llama3, and Qwen2.5 models. OBR provides AI practitioners a training-free method to significantly compress LLMs while maintaining acceptable performance on downstream tasks. |
