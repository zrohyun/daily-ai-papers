

## Papers for 2025-09-02

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Reinforcement Learning | PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic
  Reasoning (Read more on [arXiv](https://arxiv.org/abs/2508.21104) or [HuggingFace](https://huggingface.co/papers/2508.21104))| Yuewei Zhang, Penghong Zhao, Wenfeng Feng, Chuzhan, Nothing2Say | The paper introduces PVPO, a novel reinforcement learning method, to optimize policy learning for complex tasks by enhancing advantage estimation. It addresses the limitations of existing critic-free methods, which rely on extensive sampling and intra-group comparisons, potentially leading to local optima and increased computational cost. PVPO employs a reference model to pre-estimate value functions, acting as a stable advantage baseline, and integrates this with group sampling for efficient data selection. Experiments across nine datasets demonstrate SOTA performance, with PVPO achieving up to 3.6 times the accuracy of baseline models on in-domain datasets. PVPO offers AI practitioners a more efficient and scalable approach to reinforcement learning, especially in scenarios with complex reasoning and tool use. |
| Natural Language Processing | T2R-bench: A Benchmark for Generating Article-Level Reports from Real
  World Industrial Tables (Read more on [arXiv](https://arxiv.org/abs/2508.19813) or [HuggingFace](https://huggingface.co/papers/2508.19813))| Yu Zhao, Sishi Xiong, Kaiwen Wei, Changzai Pan, Jie Zhang | This paper introduces T2R-bench, a new benchmark for evaluating large language models (LLMs) in generating article-level reports from real-world industrial tables. The research aims to address the challenges of complex and diverse industrial tables and the limitations of existing table benchmarks. The methodology involves constructing a bilingual benchmark comprising 457 industrial tables across 19 domains and proposing an evaluation criteria to measure report generation quality. Experiments on 25 widely-used LLMs showed that even Deepseek-R1 only achieves 62.71% overall score, indicating LLMs still have room for improvement on T2R-bench. The benchmark and evaluation framework provides AI practitioners with a resource and standardized method to improve LLM capabilities in table-to-report generation. |
| Computer Vision | No Label Left Behind: A Unified Surface Defect Detection Model for all
  Supervision Regimes (Read more on [arXiv](https://arxiv.org/abs/2508.19060) or [HuggingFace](https://huggingface.co/papers/2508.19060))| Danijel Skočaj, MaticFuc, blaz-r | The paper introduces SuperSimpleNet, a unified discriminative model for surface defect detection across various supervision regimes. It addresses the challenge of adapting to diverse data annotations in manufacturing by proposing a model trainable under unsupervised, weakly supervised, mixed supervision, and fully supervised settings. The core methodology involves a novel synthetic anomaly generation process, an enhanced classification head, and an improved learning procedure. SuperSimpleNet achieves state-of-the-art results, demonstrating an AUROC of 98.0% on SensumSODF and a detection AP of 97.8% on KSDD2 in the fully supervised setting, while maintaining a fast inference time below 10ms. This unified approach enables AI practitioners to leverage all available data annotations for improved defect detection in industrial applications, bridging the gap between academic research and real-world demands. |
| Natural Language Processing | UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via
  HUMAIN Chat (Read more on [arXiv](https://arxiv.org/abs/2508.17378) or [HuggingFace](https://huggingface.co/papers/2508.17378))| Omartificial-Intelligence-Space | This paper presents a UI-level evaluation of ALLaM 34B, an Arabic-centric LLM, using the HUMAIN Chat platform. The study aims to assess ALLaM 34B's performance across various linguistic and functional tasks including dialect handling and safety. The methodology involves a prompt pack with 23 prompts across different categories, response sampling via HUMAIN Chat, and multi-metric scoring by LLM judges. The results show strong performance in generation and code-switching (mean 4.92/5), with solid reasoning ability (4.64/5) and dialect fidelity (4.21/5), suggesting its robustness and cultural grounding. These findings imply that ALLaM 34B is a practically ready LLM for real-world Arabic-centric applications, however, more work needs to be done in the dialectal space. |
| Natural Language Processing | How Can Input Reformulation Improve Tool Usage Accuracy in a Complex
  Dynamic Environment? A Study on τ-bench (Read more on [arXiv](https://arxiv.org/abs/2508.20931) or [HuggingFace](https://huggingface.co/papers/2508.20931))| Jayanth Srinivasa, Mutsumi Nakamura, Satyam Raj, Amir Saeidi, Venkatesh Mishra | This paper introduces a novel framework to improve tool usage accuracy in complex dynamic environments, specifically focusing on the τ-bench benchmark. The research question investigates how input reformulation can enhance the performance of tool-calling agents. The proposed Input-Reformulation Multi-Agent (IRMA) framework reformulates user queries by augmenting them with domain rules and tool suggestions. Experimental results demonstrate that IRMA outperforms ReAct, Function Calling, and Self-Reflection, achieving a 16.1% improvement in overall pass@5 scores. These findings suggest that input reformulation significantly enhances the reliability and consistency of tool-calling agents in dynamic environments. |
| Machine Learning | From reactive to cognitive: brain-inspired spatial intelligence for
  embodied agents (Read more on [arXiv](https://arxiv.org/abs/2508.17198) or [HuggingFace](https://huggingface.co/papers/2508.17198))| Songming Liu, Qihui Zhu, Caixin Kang, Liyuan Wang, Shouwei Ruan | The paper introduces Brain-inspired Spatial Cognition for Navigation (BSC-Nav), a framework for constructing and leveraging structured spatial memory in embodied agents. BSC-Nav aims to overcome limitations of reactive visual-language reasoning in embodied agents by building allocentric cognitive maps from egocentric trajectories and contextual cues. The methodology involves a landmark memory module, a cognitive map module, and a working memory module, integrated with multi-modal large language models (MLLMs). BSC-Nav achieves state-of-the-art efficacy and efficiency across diverse navigation tasks, demonstrating strong zero-shot generalization with up to 78.5% Success Rate on HM3D object goal navigation. BSC-Nav offers a scalable and biologically grounded path toward general-purpose spatial intelligence by complementing MLLMs with structured spatial memory. |
