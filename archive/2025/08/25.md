

## Papers for 2025-08-25

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Machine Learning | AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs (Read more on [arXiv](https://arxiv.org/abs/2508.16153) or [HuggingFace](https://huggingface.co/papers/2508.16153))| Xue Yan, Siyuan Guo, Yihang Chen, linyiyang2023, Zhouhc | AgentFly introduces a novel memory-based reinforcement learning paradigm for adaptive LLM agents, eliminating the need for fine-tuning the underlying LLMs. The paper addresses the challenge of enabling continuous learning in LLM agents without the high computational cost of parameter tuning. AgentFly formalizes the learning process as a Memory-augmented Markov Decision Process (M-MDP) with a neural case-selection policy and a memory rewriting mechanism. AgentFly achieves top-1 performance on GAIA validation with 87.88% Pass@3. This work offers a scalable pathway for developing generalist LLM agents capable of real-time learning without gradient updates, advancing towards open-ended skill acquisition. |
| Reinforcement Learning | ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for
  Long-Horizon Tasks (Read more on [arXiv](https://arxiv.org/abs/2508.08240) or [HuggingFace](https://huggingface.co/papers/2508.08240))| Zeju Li, Jianuo Jiang, Mingyu Liu, Liqin Lu, Ka12un | The paper presents ODYSSEY, a unified mobile manipulation framework for quadruped robots in open-world environments. It addresses long-horizon tasks by integrating high-level task planning with low-level whole-body control, aiming to enable agile exploration and manipulation. A hierarchical vision-language planner decomposes instructions into executable actions, while a whole-body policy coordinates locomotion and manipulation. The system is evaluated on a new benchmark with diverse indoor and outdoor scenarios, demonstrating successful sim-to-real transfer. Experiments show strong generalization, achieving over 40% overall success rates and over 60% success for atomic actions, making legged manipulators practical in unstructured environments. |
| Reinforcement Learning | Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains
  RLVR (Read more on [arXiv](https://arxiv.org/abs/2508.14029) or [HuggingFace](https://huggingface.co/papers/2508.14029))| Ying Nian Wu, Yelong Shen, Yeyun Gong, Zhongzhi Li, MasterVito | This paper introduces a self-play strategy with variational problem synthesis (SVS) to sustain reinforcement learning with verifiable rewards (RLVR) training. The research aims to mitigate entropy collapse during RLVR to improve Pass@k performance. SVS uses correct solutions to generate variational problems, maintaining the original answers and policy entropy. Results show an absolute gain of 18.3% and 22.8% in Pass@32 performance on AIME24 and AIME25 benchmarks, respectively, when employing SVS. This approach enables more sustainable training and prolonged self-improvement in RLVR by effectively broadening the diversity of training problems. |
| Natural Language Processing | CRISP: Persistent Concept Unlearning via Sparse Autoencoders (Read more on [arXiv](https://arxiv.org/abs/2508.13650) or [HuggingFace](https://huggingface.co/papers/2508.13650))| Yonatan Belinkov, Martin Tutek, Aaron Mueller, Dana Arad, Tomertech | This paper introduces CRISP, a parameter-efficient method for persistent concept unlearning in large language models using sparse autoencoders. The research aims to selectively remove unwanted knowledge while preserving model utility. CRISP identifies salient SAE features across multiple layers and suppresses their activations through fine-tuning. Experiments on safety-critical unlearning tasks demonstrate that CRISP outperforms prior approaches, achieving state-of-the-art performance on the WMDP benchmark, improving overall scores by 5-34 points. The method enables more targeted knowledge removal, improving the trade-off between unlearning efficacy and benign knowledge retention. |
| Computer Vision | Selective Contrastive Learning for Weakly Supervised Affordance
  Grounding (Read more on [arXiv](https://arxiv.org/abs/2508.07877) or [HuggingFace](https://huggingface.co/papers/2508.07877))| Jae-Pil Heo, hynnsk, WJ0830 | The paper introduces Selective Contrastive Learning for Weakly Supervised Affordance Grounding (WSAG). It aims to improve the localization of action-affordable parts in egocentric images using exocentric images as context, overcoming limitations of relying solely on classification and class-specific patterns. The approach leverages CLIP to discover objects and then applies prototypical and pixel contrastive learning based on the reliability of discovered part clues, distinguishing affordance-relevant regions from irrelevant context. Experiments on AGD20K and HICO-IIF datasets demonstrate improved performance, achieving a KLD of 1.124 and SIM of 0.433 on AGD20K-Seen, surpassing previous methods. This allows practitioners to better train models with limited annotation, focusing on meaningful affordance cues for object interaction. |
| Machine Learning | AetherCode: Evaluating LLMs' Ability to Win In Premier Programming
  Competitions (Read more on [arXiv](https://arxiv.org/abs/2508.16402) or [HuggingFace](https://huggingface.co/papers/2508.16402))| Yidi Du, Markus Mak, Zhicheng Liu, Jiaze Chen, zhwang01 | The paper introduces AetherCode, a new benchmark for evaluating the reasoning and coding capabilities of LLMs in premier programming competitions. It aims to address limitations in existing benchmarks by providing problems with increased difficulty and scope, along with high-quality, expert-validated test cases. The benchmark incorporates problems from IOI and ICPC, achieving 100% TPR and 100% TNR on collected solutions. Evaluation of leading LLMs on AetherCode reveals a significant performance gap between models, with top performers demonstrating better exploration potential. The results highlight the need for further improvements in LLMs' reasoning and coding abilities to bridge the gap with top human experts. |
| Computer Vision | EgoTwin: Dreaming Body and View in First Person (Read more on [arXiv](https://arxiv.org/abs/2508.13013) or [HuggingFace](https://huggingface.co/papers/2508.13013))| Wentao Wang, Mengze Li, Yicong Li, Fangzhou Hong, Jingqiao Xiu | EgoTwin introduces a diffusion-based framework for jointly generating consistent egocentric videos and human motion. The research aims to model first-person view content aligned with camera motion patterns induced by body movements. EgoTwin employs a diffusion transformer with head-centric motion representation and a cybernetics-inspired interaction mechanism to capture causal interplay between video and motion. Experiments on a real-world dataset demonstrate EgoTwin's effectiveness, achieving a Translation Error of 0.67 and HandScore of 0.81 for video-motion consistency. The framework allows AI practitioners to generate realistic and synchronized egocentric videos and human motion, which can be further applied for scene reconstruction. |
| Multi-Modal | Do What? Teaching Vision-Language-Action Models to Reject the Impossible (Read more on [arXiv](https://arxiv.org/abs/2508.16292) or [HuggingFace](https://huggingface.co/papers/2508.16292))| Roei Herzig, Trevor Darrell, Dantong Niu, Elvis Hsieh, Wen-Han Hsieh | The paper introduces a framework for Vision-Language-Action (VLA) models to detect and respond to false-premise instructions. The main objective is to enable VLAs to recognize unfulfillable commands by incorporating language-based corrections. The proposed Instruct-Verify-and-Act (IVA) framework uses a contextually augmented dataset with paired positive and false-premise instructions and instruction tuning. Experiments show a 97.56% improvement in false premise detection accuracy and a 50.78% increase in successful responses in false-premise scenarios. This enables language-aware robots to handle ambiguous commands more safely and naturally. |
| Natural Language Processing | End-to-End Agentic RAG System Training for Traceable Diagnostic
  Reasoning (Read more on [arXiv](https://arxiv.org/abs/2508.15746) or [HuggingFace](https://huggingface.co/papers/2508.15746))| Pengcheng Qiu, Chaoyi Wu, Yuze Sun, Qiaoyu Zheng, Angelakeke | The paper introduces Deep-DxSearch, an end-to-end trained agentic RAG system for traceable medical diagnosis. It aims to improve diagnostic accuracy by addressing limitations in knowledge utilization and reasoning traceability in existing RAG and tool-augmented methods. The LLM is trained with reinforcement learning using tailored rewards for format, retrieval, reasoning structure, and diagnostic accuracy, evolving the agentic RAG policy from large-scale data. Deep-DxSearch achieves substantial gains in diagnostic accuracy, surpassing strong diagnostic baselines such as GPT-4o by up to 19% in top-1 accuracy for common diseases. The system enables more reliable and precise preliminary diagnoses by providing deeper insights into its performance gains. |
| Natural Language Processing | TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated
  Prefill \& Decode Inference (Read more on [arXiv](https://arxiv.org/abs/2508.15881) or [HuggingFace](https://huggingface.co/papers/2508.15881))| Di Yin, Yuxuan Wang, Pingzhi Tang, Fanxu Meng, xiaojuan0920 | The paper introduces Tensor Parallel Latent Attention (TPLA) to improve the efficiency of disaggregated prefill and decode inference in large language models. It addresses the memory bottleneck in tensor parallelism by partitioning both latent representations and input dimensions across devices, enabling efficient distributed attention computation. TPLA achieves up to 1.93x speedup compared to MLA at a 32K-token context length on the Kimi-K2 model, while maintaining performance on commonsense and LongBench benchmarks. The method is drop-in compatible with MLA-trained models and supports efficient tensor-parallel decoding without retraining. This technique enables practitioners to scale inference of MLA-based models efficiently across multiple devices with minimal accuracy degradation. |
| Machine Learning | AgentScope 1.0: A Developer-Centric Framework for Building Agentic
  Applications (Read more on [arXiv](https://arxiv.org/abs/2508.16279) or [HuggingFace](https://huggingface.co/papers/2508.16279))| Liuyi Yao, Weirui Kuang, Yuexiang Xie, Zitao Li, Dawei Gao | The paper introduces AgentScope 1.0, a developer-centric framework for building agentic applications based on Large Language Models (LLMs). The framework aims to enhance flexible and efficient tool-based agent-environment interactions. It leverages the ReAct paradigm and provides asynchronous execution and real-time steering, improving agent performance. The paper also includes several built-in agents tailored to practical scenarios, robust engineering support, and a scalable evaluation module. AgentScope offers runtime sandbox to ensure safe agent execution. |
| Natural Language Processing | InMind: Evaluating LLMs in Capturing and Applying Individual Human
  Reasoning Styles (Read more on [arXiv](https://arxiv.org/abs/2508.16072) or [HuggingFace](https://huggingface.co/papers/2508.16072))| Diping Song, Qi Chen, Yibin Wang, Chuanhao Li, Zizhen Li | The paper introduces InMind, a framework to evaluate LLMs' ability to capture and apply individualized human reasoning styles in social deduction games (SDGs). It aims to address whether LLMs can go beyond general reasoning to adapt to diverse strategies under identical conditions. InMind incorporates dual-layer cognitive annotations (strategy traces and reflective summaries) from both Observer and Participant modes to construct personalized reasoning profiles. The framework evaluates LLMs on tasks like player identification, reflection alignment, trace attribution, and role inference, achieving a top-1 accuracy of 0.240 with DeepSeek-R1 in player identification. The work highlights limitations in current LLMs' individualized and adaptive reasoning and provides a step toward cognitively aligned human-AI interaction. |
| Natural Language Processing | CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated
  Chain-of-Thought-based Reinforced Fine-Tuning (Read more on [arXiv](https://arxiv.org/abs/2508.15868) or [HuggingFace](https://huggingface.co/papers/2508.15868))| Yulun Zhang, Haipang Wu, Rongjuncheng Zhang, Ji Liu, Wenqiao Zhu | The paper introduces CARFT, a novel contrastive learning approach to enhance reasoning capabilities in LLMs via annotated Chain-of-Thought-based reinforced fine-tuning. It aims to improve LLM reasoning performance by exploiting annotated CoTs and stabilizing the fine-tuning process. CARFT constructs contrastive signals using CoT representations and an embedding-enhanced partial reward to guide fine-tuning. Experiments show CARFT achieves up to a 10.15% performance improvement over baselines and a 30.62% improvement in efficiency. CARFT provides AI practitioners with a more robust and efficient fine-tuning method for reasoning-centric LLM applications. |
| Computer Vision | Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose
  Inverse Kinematics (Read more on [arXiv](https://arxiv.org/abs/2508.13562) or [HuggingFace](https://huggingface.co/papers/2508.13562))| Xiao Sun, Zhihang Zhong, Wei Wang, Linfeng Dong, Charlie019 | The paper introduces Learnable SMPLify, a neural inverse kinematics framework for optimization-free human pose estimation. The main objective is to replace the iterative optimization process in SMPLify with a single-pass regression model, addressing challenges in data construction and generalization. The methodology involves a temporal sampling strategy for initialization-target pairs and a human-centric normalization scheme with residual learning. Experiments demonstrate a runtime speedup of nearly 200x compared to SMPLify, with an improvement of over 5mm PVE across datasets. This provides a practical and efficient baseline for human pose inverse kinematics without iterative optimization. |
| Natural Language Processing | Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts (Read more on [arXiv](https://arxiv.org/abs/2508.10390) or [HuggingFace](https://huggingface.co/papers/2508.10390))| Liming Fang, Jiafei Wu, Xiaogang Xu, Lu Zhou, AlienZhang1996 | The paper addresses the challenge of evaluating jailbreak attacks on black-box LLMs due to unsuitable prompts in existing datasets. The research focuses on creating a framework called MDH (Malicious content Detection based on LLMs with Human assistance) for malicious content detection in red-teaming datasets and developing new jailbreak attack methods. The key methodology combines LLM-based annotation with minimal human oversight for dataset cleaning and introduces D-Attack and DH-CoT jailbreak methods using developer messages. MDH achieves 95% accuracy in malicious content detection with less than 10% manual effort. The research implies AI practitioners can use MDH for efficient dataset cleaning and adopt D-Attack and DH-CoT strategies for more robust jailbreak attacks. |
