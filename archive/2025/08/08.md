

## Papers for 2025-08-08

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Machine Learning | On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification (Read more on [arXiv](https://arxiv.org/abs/2508.05629) or [HuggingFace](https://huggingface.co/papers/2508.05629))| Xinyu Ye, Yingzhe Peng, Zhou Ziheng, Yizhou Zhou, Yongliang Wu | This paper introduces Dynamic Fine-Tuning (DFT), an improvement to Supervised Fine-Tuning (SFT) for Large Language Models (LLMs) to enhance generalization. It addresses the limited generalization of SFT by rectifying a problematic reward structure implicitly encoded in its gradients via dynamic rescaling of the objective function with token probability. DFT achieves significantly improved generalization compared to standard SFT across several benchmarks, including an average gain of +15.66 points over the base model on Qwen2.5-Math-1.5B. The approach offers a simple yet effective alternative to Reinforcement Learning (RL) for fine-tuning, bridging theoretical insights with practical solutions. |
| Machine Learning | R-Zero: Self-Evolving Reasoning LLM from Zero Data (Read more on [arXiv](https://arxiv.org/abs/2508.05004) or [HuggingFace](https://huggingface.co/papers/2508.05004))| Zongxia Li, Hongming Zhang, Xiaoyang Wang, Wenhao Yu, Chengsong Huang | The paper introduces R-Zero, a fully autonomous framework for self-evolving reasoning in Large Language Models (LLMs) without relying on human-curated data. It addresses the limitation of existing LLMs that depend on human-annotated tasks by initializing two independent models, a Challenger and a Solver, optimized separately and co-evolving through interaction. The Challenger generates tasks targeting the Solver's capability edge, while the Solver is rewarded for solving increasingly challenging tasks. R-Zero improves reasoning, demonstrated by a +6.49 boost on the Qwen3-4B-Base model on math reasoning benchmarks.  This framework offers AI practitioners a scalable path toward superintelligence by enabling LLMs to learn from their own experiences without human intervention. |
| Multi-Modal | DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning (Read more on [arXiv](https://arxiv.org/abs/2508.05405) or [HuggingFace](https://huggingface.co/papers/2508.05405))| Ziming Wang, BÃ¶rje F. Karlsson, Ye Wang, Pi Bu, Xinrun Xu | The paper introduces DeepPHY, a novel benchmark for evaluating agentic Vision Language Models (VLMs) in interactive physical reasoning tasks. The main objective is to assess VLMs' ability to understand and reason about fundamental physical principles through simulated environments. The methodology involves integrating six diverse physics-based simulation environments with varying difficulty levels and fine-grained evaluation metrics. The evaluation reveals that even state-of-the-art VLMs struggle, achieving a success rate of only 23.1% on PHYRE tasks. This suggests a significant performance gap exists in translating descriptive physical knowledge into precise, predictive control for real-world agentic tasks. |
| Reinforcement Learning | Genie Envisioner: A Unified World Foundation Platform for Robotic
  Manipulation (Read more on [arXiv](https://arxiv.org/abs/2508.05635) or [HuggingFace](https://huggingface.co/papers/2508.05635))| Shengcong Chen, Donglin Yang, Siyuan Huang, Pengfei Zhou, Yue Liao | Genie Envisioner (GE) is introduced as a unified platform for robotic manipulation that integrates policy learning, evaluation, and simulation within a video-generative framework. The primary objective is to create a scalable and robust platform for learning and evaluating manipulation policies in a unified manner. GE utilizes a large-scale, instruction-conditioned video diffusion model (GE-Base) combined with a lightweight flow-matching decoder (GE-Act) and an action-conditioned neural simulator (GE-Sim). GE-Act achieves low-latency end-to-end control by generating 54-step torque trajectories within 200 ms on a commodity GPU, outperforming task-specific baselines. The platform offers AI practitioners a scalable and practical foundation for instruction-driven, general-purpose embodied intelligence. |
| Natural Language Processing | Are We on the Right Way for Assessing Document Retrieval-Augmented
  Generation? (Read more on [arXiv](https://arxiv.org/abs/2508.03644) or [HuggingFace](https://huggingface.co/papers/2508.03644))| Junjie Yang, Dongping Chen, Yaochen Wang, Mingjia Wang, Wenxuan Shen | The paper introduces DOUBLE-BENCH, a new large-scale multilingual and multimodal evaluation system for document Retrieval-Augmented Generation (RAG) systems. It aims to address the limitations of existing benchmarks by providing fine-grained assessments of each component within document RAG systems using real-world challenges. The methodology involves a dataset comprising 3,276 documents (72,880 pages) and 5,168 queries across 6 languages and 4 document types, along with manually verified evidence pages. Experiments across 9 embedding models, 4 MLLMs, and 4 RAG frameworks revealed a narrowing gap between text and visual embeddings, with Colqwen2.5-3b achieving a strong hit@5 score of 0.795. The study highlights the over-confidence dilemma within current document RAG frameworks, indicating a need for more robust document retrieval models and open-source benchmarks. |
| Natural Language Processing | Are Today's LLMs Ready to Explain Well-Being Concepts? (Read more on [arXiv](https://arxiv.org/abs/2508.03990) or [HuggingFace](https://huggingface.co/papers/2508.03990))| Huan Liu, Chengshuai Zhao, Zhen Tan, Dawei Li, Bohan Jiang | This paper investigates the ability of Large Language Models (LLMs) to explain well-being concepts tailored to different audiences. The core research question is whether LLMs are ready to generate high-quality, audience-aware explanations for well-being concepts. The methodology involves creating a large dataset of LLM-generated explanations, employing a principle-guided LLM-as-a-judge evaluation framework, and fine-tuning an open-source LLM using Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). The results indicate that DPO-fine-tuning improves explanation quality, achieving a win rate of 75.9% for the general public and 83.4% for domain experts, surpassing larger variants for expert explanations. The main implication is that preference-based learning can significantly enhance LLMs for specialized explanation tasks. |
| Multi-Modal | Can Large Multimodal Models Actively Recognize Faulty Inputs? A
  Systematic Evaluation Framework of Their Input Scrutiny Ability (Read more on [arXiv](https://arxiv.org/abs/2508.04017) or [HuggingFace](https://huggingface.co/papers/2508.04017))| Yuan Wu, Yi Chang, Gengxu Li, Jinzhe Li, Haiqi Yang | This paper introduces ISEval, a framework to evaluate Large Multimodal Models' (LMMs) ability to actively detect faulty inputs. The research investigates whether LMMs can scrutinize erroneous inputs without explicit instruction. ISEval includes seven categories of flawed premises and three evaluation metrics, assessed across ten advanced LMMs. Results indicate that most models struggle to detect flawed textual premises autonomously, achieving low Spontaneous Error Detection Rates (SEDR), but show improved Guided Error Detection Rates (GEDR) when explicitly prompted.  The study implies the need to enhance LMMs' proactive verification of input validity for reliable real-world applications. |
| Natural Language Processing | InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs
  to Enhance Reasoning Capabilities (Read more on [arXiv](https://arxiv.org/abs/2508.05496) or [HuggingFace](https://huggingface.co/papers/2508.05496))| Zhijie Sang, Kejing Yang, Qi Zhou, Su Lu, Shuo Cai | The paper introduces InfiAlign, a scalable framework for aligning LLMs to enhance reasoning with improved sample efficiency. It aims to reduce the computational cost and data requirements of post-training alignment through selective data curation. The core methodology involves integrating supervised fine-tuning (SFT) and Direct Preference Optimization (DPO) with a data selection pipeline that automatically curates high-quality alignment data from open-source reasoning datasets. InfiAlign achieves performance comparable to DeepSeek-R1-Distill-Qwen-7B using approximately 12% of the training data and demonstrates strong generalization. The implication for AI practitioners is a practical solution for aligning large reasoning models in a more scalable and data-efficient manner, potentially accelerating model development. |
| Natural Language Processing | Evaluating, Synthesizing, and Enhancing for Customer Support
  Conversation (Read more on [arXiv](https://arxiv.org/abs/2508.04423) or [HuggingFace](https://huggingface.co/papers/2508.04423))| Feng Chen, Lifan Guo, Junhui Li, Huaixia Dou, Jie Zhu | This paper introduces the Customer Support Conversation (CSC) task to train customer service supporters with well-defined strategies. It aims to address the lack of strategic guidance in existing dialogue datasets and the difficulty in accessing real-world service data. The methodology involves a structured CSC framework grounded in COPC guidelines, defining five conversational stages and twelve strategies, along with creating CSConv (an evaluation dataset) and RoleCS (a synthetic training dataset). Experiments demonstrate that fine-tuning strong LLMs on RoleCS significantly improves their ability to generate strategy-aligned responses on CSConv, achieving up to 43.29% strategy prediction accuracy and improved BLEU scores. The work provides AI practitioners with a framework and datasets for enhancing customer support conversations with structured strategies, demonstrating improved problem resolution capabilities. |
| Natural Language Processing | Don't Overthink It: A Survey of Efficient R1-style Large Reasoning
  Models (Read more on [arXiv](https://arxiv.org/abs/2508.02120) or [HuggingFace](https://huggingface.co/papers/2508.02120))| Fangzhou Yao, Weibo Gao, Yizhi Wang, Yichao Du, Linan Yue | This survey examines efficient reasoning methods for R1-style Large Reasoning Models (LRMs), addressing the problem of 'overthinking'. The paper categorizes existing methods into single-model optimization and model collaboration strategies to reduce redundant reasoning steps. It analyzes techniques like early exit, CoT compression, and LLM routing to improve computational efficiency without sacrificing accuracy. The study maintains a public GitHub repository and aims to provide a novel framework for understanding efficient reasoning by focusing on single-model versus model collaboration. The implications for AI practitioners are the potential for more resource-efficient deployment of LRMs in complex tasks. |
| Computer Vision | MOSEv2: A More Challenging Dataset for Video Object Segmentation in
  Complex Scenes (Read more on [arXiv](https://arxiv.org/abs/2508.05630) or [HuggingFace](https://huggingface.co/papers/2508.05630))| Xudong Jiang, Shuting He, Chang Liu, Kaining Ying, Henghui Ding | The paper introduces MOSEv2, a more challenging video object segmentation dataset designed for complex real-world scenarios. It aims to address limitations of existing datasets by incorporating frequent object disappearance/reappearance, severe occlusions, small objects, and adverse environmental conditions. The dataset consists of 5,024 videos with over 701,976 high-quality masks across 200 categories, significantly expanding upon its predecessor, MOSEv1. Benchmarking 20 VOS methods reveals performance drops, with SAM2 decreasing from 76.4% J&F on MOSEv1 to 50.9% on MOSEv2, indicating the increased difficulty. MOSEv2 serves as a benchmark to drive research toward more robust VOS algorithms capable of handling real-world complexities. |
| Multi-Modal | CoAct-1: Computer-using Agents with Coding as Actions (Read more on [arXiv](https://arxiv.org/abs/2508.03923) or [HuggingFace](https://huggingface.co/papers/2508.03923))| Taiwei Shi, Jieyu Zhang, Viraj Prabhu, Yutong Dai, Linxin Song | The paper introduces CoAct-1, a multi-agent system that combines GUI-based control with direct programmatic execution for computer automation. The research aims to enhance the robustness and efficiency of computer-using agents by integrating coding as an enhanced action. CoAct-1 dynamically delegates subtasks to either a GUI Operator or a Programmer agent which can write and execute Python or Bash scripts. Evaluated on the OSWorld benchmark, CoAct-1 achieves a state-of-the-art success rate of 60.76% and reduces the average number of steps to 10.15. This implies that integrating coding as a core action provides a more powerful and efficient path toward generalized computer automation. |
| Natural Language Processing | Marco-Voice Technical Report (Read more on [arXiv](https://arxiv.org/abs/2508.02038) or [HuggingFace](https://huggingface.co/papers/2508.02038))| Qingjuan Li, Haoqin Sun, Xuanfan Ni, Chenyang Lyu, Fengping Tian | The paper introduces Marco-Voice, a speech synthesis system integrating voice cloning and emotion control within a unified framework. The research aims to generate highly expressive, controllable, and natural speech while preserving speaker identity across diverse linguistic and emotional contexts. The system employs a speaker-emotion disentanglement mechanism using in-batch contrastive learning and rotational emotional embedding integration. Experiments on the CSEMOTIONS dataset demonstrate substantial improvements, with Marco-Voice achieving a speaker similarity score of 0.8275 in voice cloning evaluations. This offers AI practitioners a more effective approach for expressive and personalized speech synthesis applications. |
| Computer Vision | StrandDesigner: Towards Practical Strand Generation with Sketch Guidance (Read more on [arXiv](https://arxiv.org/abs/2508.01650) or [HuggingFace](https://huggingface.co/papers/2508.01650))| Xiaobin Hu, Han Feng, Chengming Xu, Moran Li, Na Zhang | The paper introduces StrandDesigner, a sketch-based strand generation model for creating realistic 3D hairstyles offering finer user control. It addresses challenges in strand interaction and sketch pattern diversity using a learnable strand upsampling strategy and a multi-scale adaptive conditioning mechanism. Experiments demonstrate that StrandDesigner outperforms existing methods, achieving a Point Cloud IoU of 64.54% compared to other approaches. The framework offers AI practitioners a more precise and user-friendly tool for generating detailed hairstyles, improving visual realism in digital avatars and virtual environments. The authors claim their method can adapt to varying granularity and density sketches. |
| Natural Language Processing | Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during
  Multi-Hop Analysis (Read more on [arXiv](https://arxiv.org/abs/2508.04699) or [HuggingFace](https://huggingface.co/papers/2508.04699))| Reshmi Ghosh, Yashwanth Babu, Srujana Pillarichety, Isha Nalawade, Anushka Yadav | This paper investigates the reasoning failures of language models (LMs) in multi-hop question answering (QA) tasks. The study introduces a diagnostic framework decomposing reasoning behavior into hops, coverage, and overthinking, applying it to analyze model traces from six LMs across three datasets. Through human annotation and automated metrics, the research uncovers intricate error patterns often hidden by accuracy-centric evaluations. The results show that while LMs perform well in simpler settings, they struggle with overthinking and synthesis failures in complex tasks. The authors conclude that evaluation and training strategies should focus on bridging the gap between correct answers and efficient, faithful reasoning to enhance the reliability of multi-hop QA systems. |
| Natural Language Processing | PRvL: Quantifying the Capabilities and Risks of Large Language Models
  for PII Redaction (Read more on [arXiv](https://arxiv.org/abs/2508.05545) or [HuggingFace](https://huggingface.co/papers/2508.05545))| Prajit Das, Lavanya Elluri, Aritran Piplai, Anantaa Kotal, Leon Garza | This paper presents PRvL, a comprehensive analysis of Large Language Models (LLMs) for privacy-preserving PII Redaction. It explores the impact of architectural and training choices on redaction performance, aiming to establish empirical foundations for customizable PII Redaction. The methodology includes evaluating a range of LLM architectures and training strategies, measuring redaction performance, semantic preservation, and PII leakage, and comparing outcomes against latency and cost. Results show that instruction-tuned models, particularly DeepSeek-Q1 and Llama3.1-8B, consistently demonstrate strong span-level accuracy, achieving up to 0.994 accuracy on span-correct evaluation. The main implication for AI practitioners is practical guidance for configuring LLM-based redactors that are accurate, efficient, and privacy-aware, supported by the release of the PRvL open-source suite. |
| Natural Language Processing | REINA: Regularized Entropy Information-Based Loss for Efficient
  Simultaneous Speech Translation (Read more on [arXiv](https://arxiv.org/abs/2508.04946) or [HuggingFace](https://huggingface.co/papers/2508.04946))| Xiao Yu, Mahesh Kumar Nandwana, Joseph Liu, Nameer Hirschkind | The paper introduces REINA, a novel loss function for efficient simultaneous speech translation (SimulST). The research aims to balance translation quality and latency in SimulST systems by optimizing when to wait for more input based on information gain. REINA, derived from information theory, trains an adaptive policy using a non-streaming translation model, achieving state-of-the-art streaming results on French, Spanish, and German using only open-source data; the method also shows improvements to the latency/quality trade-off by as much as 21%. The introduced metric NoSE allows AI practitioners to normalize streaming quality against underlying non-streaming model performance, better assessing the streaming policy itself. |
| Natural Language Processing | I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating
  Linguistic Shibboleth Detection in LLM Hiring Evaluations (Read more on [arXiv](https://arxiv.org/abs/2508.04939) or [HuggingFace](https://huggingface.co/papers/2508.04939))| Chirag Shah, Aman Chadha, Tanya Roosta, Julia Kharchenko | This paper presents a comprehensive benchmark for evaluating the impact of linguistic shibboleths on Large Language Models (LLMs) in hiring evaluations. The research investigates how LLMs inadvertently penalize certain linguistic patterns, such as hedging, despite equivalent content quality, leading to potential demographic biases. The methodology involves constructing interview simulations with controlled linguistic variations to isolate specific phenomena while maintaining semantic equivalence.  The benchmark demonstrates that hedged responses receive 25.6% lower ratings on average, indicating systematic bias against cautious language.  This work establishes a framework for detecting and measuring linguistic discrimination in AI hiring systems, facilitating fairness audits and mitigating unintended biases. |
| Computer Vision | RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation (Read more on [arXiv](https://arxiv.org/abs/2508.04190) or [HuggingFace](https://huggingface.co/papers/2508.04190))| Jian Yang, Yixuan Ding, Tianfang Zhang, Yimian Dai, fengyiwu | RPCANet++ is introduced as a novel deep learning framework for sparse object segmentation by unfolding Robust Principal Component Analysis (RPCA). The research aims to develop an interpretable and adaptable model for segmenting sparse objects in complex imaging scenarios, overcoming the limitations of traditional RPCA methods. The approach unfolds a relaxed RPCA model into a structured network with modules like Background Approximation Module (BAM) and Object Extraction Module (OEM), incorporating memory augmentation and deep contrast priors to enhance performance. Experiments on diverse datasets demonstrate state-of-the-art performance; for instance, achieving a 94.39% IoU on the NUDT-SIRST dataset. RPCANet++ provides a new baseline for reliable and interpretable sparse object segmentation by integrating the theoretical strengths of RPCA with efficient deep networks, offering better generalization and interpretability for AI practitioners. |
| Multi-Modal | I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal
  Entity Linking (Read more on [arXiv](https://arxiv.org/abs/2508.02243) or [HuggingFace](https://huggingface.co/papers/2508.02243))| Chao Wang, Tong Ruan, Kaiwen Li, Junwen Li, Ziyan Liu | This paper introduces I2CR, a novel LLM-based framework for multimodal entity linking (MEL) that leverages both textual and visual modalities. I2CR addresses the challenges of unnecessary image incorporation and one-time visual feature extraction in existing methods. The framework prioritizes textual information and employs an iterative, multi-round strategy integrating key visual clues when text is insufficient, incorporating intra- and inter-modal consistency checks. Experiments on WikiMEL, WikiDiverse, and RichMEL show that I2CR outperforms existing methods, achieving a top-1 accuracy of 92.2% on WikiMEL, a 3.2% improvement. The framework's design reduces image noise, enhancing applicability for AI practitioners working with noisy, multimodal data. |
