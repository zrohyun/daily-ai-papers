

## Papers for 2025-08-15

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Multi-Modal | We-Math 2.0: A Versatile MathBook System for Incentivizing Visual
  Mathematical Reasoning (Read more on [arXiv](https://arxiv.org/abs/2508.10433) or [HuggingFace](https://huggingface.co/papers/2508.10433))| Xiaowan Wang, Yanzi Wang, Peiqing Yang, Qiuna Tan, Runqi Qiao | The paper introduces WE-MATH 2.0, a versatile system to enhance visual mathematical reasoning in MLLMs. The objective is to improve mathematical reasoning abilities by integrating a structured knowledge system, model-centric data space modeling, and RL-based training. Their methodology includes constructing a MathBook Knowledge System, creating MathBook-Standard & Pro datasets, and implementing a two-stage RL framework (MathBook-RL). Experiments on MathBookEval show MathBook-RL performs competitively with existing baselines and achieves strong results, suggesting promising generalization in mathematical reasoning. The system provides a comprehensive framework and benchmark for incentivizing visual mathematical reasoning in MLLMs. |
| Computer Vision | NextStep-1: Toward Autoregressive Image Generation with Continuous
  Tokens at Scale (Read more on [arXiv](https://arxiv.org/abs/2508.10711) or [HuggingFace](https://huggingface.co/papers/2508.10711))| Quan Sun, Jingwei Wu, Guopeng Li, Chunrui Han, NextStep Team | NextStep-1 introduces a 14B autoregressive model for text-to-image generation using continuous image tokens, achieving state-of-the-art performance among autoregressive models. The research aims to advance autoregressive paradigms by pairing the large language model with a flow-matching head trained on discrete text and continuous image tokens. The methodology involves next-token prediction objectives without relying on diffusion models or vector quantization. NextStep-1 demonstrates exceptional compositional understanding, achieving 0.54 on WISE and 0.67 on the advanced GenAI-Bench prompts. This unified approach allows for high-fidelity image synthesis and strong performance in image editing, offering AI practitioners a versatile autoregressive approach for image generation. |
| Computer Vision | ToonComposer: Streamlining Cartoon Production with Generative
  Post-Keyframing (Read more on [arXiv](https://arxiv.org/abs/2508.10881) or [HuggingFace](https://huggingface.co/papers/2508.10881))| Xiaoyu Li, Yaowei Li, Zhaoyang Zhang, Guangzhi Wang, Lingen Li | The paper introduces ToonComposer, a generative model for streamlining cartoon production through a novel post-keyframing approach. It aims to unify inbetweening and colorization by precisely controlling cartoon generation using sparse keyframe sketches. ToonComposer employs a sparse sketch injection mechanism and a spatial low-rank adapter to tailor a video foundation model to the cartoon domain. Evaluated on a synthetic benchmark, ToonComposer achieves a significantly lower DISTS score (0.1785) compared to existing methods, indicating superior perceptual quality. This allows AI practitioners to generate stylistically coherent animations with minimal artist input, enhancing production efficiency. |
| Computer Vision | UI-Venus Technical Report: Building High-performance UI Agents with RFT (Read more on [arXiv](https://arxiv.org/abs/2508.10833) or [HuggingFace](https://huggingface.co/papers/2508.10833))| Shuheng Shen, Xingran Zhou, Zhenyu Xu, Zhengwen Zeng, Zhangxuan Gu | The paper introduces UI-Venus, a native UI agent leveraging a multimodal large language model for UI tasks. It addresses UI grounding and navigation challenges via reinforcement finetuning (RFT) using Qwen2.5-VL, incorporating self-evolving trajectory history alignment and sparse action enhancement. UI-Venus achieves SOTA performance on standard grounding benchmarks, surpassing previous baselines with 94.1%/50.8% and 95.3%/61.9% on Screenspot-V2/Pro, respectively. The method integrates reward functions and data cleaning strategies to improve performance. The open-source UI agents, data protocols, and novel self-evolving frameworks provide AI practitioners with new tools for developing more sophisticated UI agents. |
| Natural Language Processing | PRELUDE: A Benchmark Designed to Require Global Comprehension and
  Reasoning over Long Contexts (Read more on [arXiv](https://arxiv.org/abs/2508.09848) or [HuggingFace](https://huggingface.co/papers/2508.09848))| Rui Lu, Tong Li, Chulun Zhou, Tsz Ting Chung, Mo Yu | The paper introduces PRELUDE, a new benchmark designed to evaluate long-context understanding and reasoning in LLMs. It aims to address shortcomings in existing benchmarks by requiring global comprehension and deep reasoning beyond memorization or simple retrieval. The methodology involves presenting models with hypothetical prequels to characters in canonical books and assessing their consistency with the original narrative. Experiments with state-of-the-art LLMs reveal a significant performance gap compared to humans (over 15%) and flawed reasoning leading to over 30% gap in reasoning accuracy. The study implies that current LLMs require further advancements in long-context reasoning to improve their global comprehension capabilities. |
| Computer Vision | STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer (Read more on [arXiv](https://arxiv.org/abs/2508.10893) or [HuggingFace](https://huggingface.co/papers/2508.10893))| Honghua Chen, Shangchen Zhou, Fangzhou Hong, Yihang Luo, Yushi Lan | STREAM3R introduces a scalable approach to sequential 3D reconstruction using a causal transformer. The paper addresses the challenge of efficiently processing streaming image sequences for 3D reconstruction by leveraging causal attention mechanisms. The method caches features from previous frames to inform future inference, achieving state-of-the-art performance on both static and dynamic scene benchmarks, including a reported 95.5% inlier points within a 1.25-factor of true depth on the NYU-v2 dataset. This work presents a way for real-time 3D perception in streaming environments with inherent compatibility with LLM-style infrastructure, allowing for efficient large-scale pretraining. |
| Reinforcement Learning | Pass@k Training for Adaptively Balancing Exploration and Exploitation of
  Large Reasoning Models (Read more on [arXiv](https://arxiv.org/abs/2508.10751) or [HuggingFace](https://huggingface.co/papers/2508.10751))| Qinghao Ye, Yue Ling, Youbin Wu, Xiaobo Qin, Zhipeng Chen | This paper introduces Pass@k Training, a reinforcement learning method for adaptively balancing exploration and exploitation in large reasoning models. The research aims to address the limitations of RLVR, which typically uses Pass@1 as the reward and struggles with balancing exploration and exploitation, converging to local optima. Pass@k Training uses Pass@k as the reward, improving exploration ability; analytical derivation is used for efficiency. Experiments show Pass@k Training on Qwen2.5-7B-Ins boosts exploration ability, surpassing native RLVR and powerful LLMs; it also shows improvements in Pass@k performance without harming Pass@1 scores. The implication for AI practitioners is an effective method for enhancing the exploration capabilities of LLMs within RLVR frameworks. |
| Multi-Modal | HumanSense: From Multimodal Perception to Empathetic Context-Aware
  Responses through Reasoning MLLMs (Read more on [arXiv](https://arxiv.org/abs/2508.10576) or [HuggingFace](https://huggingface.co/papers/2508.10576))| Yi Yuan, Tianqi Li, Yabing Wang, Ruobing Zheng, Zheng Qin | This paper introduces HumanSense, a benchmark for evaluating human-centered perception and interaction in multimodal large language models (MLLMs). The research aims to assess MLLMs' abilities to understand human intentions and generate empathetic responses in complex, real-world scenarios. The authors designed a comprehensive benchmark with 15 tests and 3,882 questions and employed multi-stage, omni-modal reinforcement learning to enhance reasoning abilities. Evaluations reveal that current leading MLLMs still have room for improvement, with human evaluators achieving 87.5% accuracy on the HumanSense (tiny) dataset compared to the best performing model's 57.8% accuracy, and that omni-modal reasoning can significantly enhance cognitive and interactive capabilities. The findings suggest that appropriate feedback necessitates a thorough contextual analysis of interlocutors' needs and emotions. |
| Natural Language Processing | A Survey on Diffusion Language Models (Read more on [arXiv](https://arxiv.org/abs/2508.10875) or [HuggingFace](https://huggingface.co/papers/2508.10875))| Zhiqiang Shen, Bowei Guo, Mingda Chen, Tianyi Li | This survey provides a comprehensive overview of Diffusion Language Models (DLMs), a promising alternative to autoregressive models. It explores DLMs' evolution, principles, training methodologies, and inference strategies aimed at reducing inference latency and capturing bidirectional context. The paper surveys techniques from pre-training to post-training and optimizations for decoding parallelism and generation quality, including multimodal extensions. It identifies DLMs' limitations, such as efficiency and long-sequence handling, while highlighting future research directions. While no direct quantitative metrics are present, comparable performance to similarly sized LLaMA3-8B models are noted, making DLMs a compelling choice for various natural language processing tasks. |
| Natural Language Processing | From Black Box to Transparency: Enhancing Automated Interpreting
  Assessment with Explainable AI in College Classrooms (Read more on [arXiv](https://arxiv.org/abs/2508.10860) or [HuggingFace](https://huggingface.co/papers/2508.10860))| Ziyin Zhang, Zhaokun Jiang | This paper introduces a multi-dimensional framework for explainable automated interpreting assessment to address limitations in existing approaches. The study aims to enhance the assessment of interpreting quality across fidelity, fluency, and language use by incorporating feature engineering, data augmentation using Variational Autoencoders, and Shapley Value analysis. Results on an English-Chinese consecutive interpreting dataset demonstrate strong predictive performance, identifying BLEURT and CometKiwi scores as key features for fidelity. The framework provides transparent diagnostic feedback, supporting self-regulated learning and offering a scalable, reliable alternative to traditional human evaluation, which ultimately facilitates targeted interventions for improving interpreter proficiency. |
| Computer Vision | Processing and acquisition traces in visual encoders: What does CLIP
  know about your camera? (Read more on [arXiv](https://arxiv.org/abs/2508.10637) or [HuggingFace](https://huggingface.co/papers/2508.10637))| Giorgos Tolias, Yuta Nakashima, Giorgos Kordopatis-Zilos, Vladan Stojnić, Ryan Ramos | The paper investigates the influence of image processing and acquisition metadata on visual encoder representations. The research explores whether such metadata is encoded in the learned representations and if it impacts downstream task performance. The methodology involves training linear classifiers to predict metadata labels from image embeddings, assessing the classifiers' accuracy. Results show that contrastive vision-language models exhibit a high sensitivity to acquisition parameters, achieving over 70% accuracy in predicting camera models. This suggests that metadata traces can overshadow semantic content, potentially affecting the reliability and generalizability of AI models in practical applications. |
| Natural Language Processing | When Explainability Meets Privacy: An Investigation at the Intersection
  of Post-hoc Explainability and Differential Privacy in the Context of Natural
  Language Processing (Read more on [arXiv](https://arxiv.org/abs/2508.10482) or [HuggingFace](https://huggingface.co/papers/2508.10482))| Gjergji Kasneci, Florian Matthes, Ege Erdogan, Stephen Meisenbacher, Mahdi Dhaini | This paper investigates the privacy-explainability trade-off in NLP by examining the impact of differential privacy (DP) on post-hoc explainability methods. The study aims to quantify how DP text rewriting affects the explainability of fine-tuned language models. It employs DP text rewriting techniques (TEM, DP-Prompt, DP-BART) on three datasets (SST-2, AG News, Trustpilot) and evaluates explanations using AOPC-Comprehensiveness and AOPC-Sufficiency metrics. Results show that higher privacy levels generally degrade explainability, but LIME and SHAP outperform Gradient and IG explainers under strong privacy constraints; the composite scores varied significantly depending on privacy and dataset with the AG News performing the best. The study suggests that practitioners should consider dataset characteristics and choose appropriate DP methods to balance privacy and explainability. |
