

## Papers for 2025-08-12

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability (Read more on [arXiv](https://arxiv.org/abs/2508.07050) or [HuggingFace](https://huggingface.co/papers/2508.07050))| Yuchen Li, Yutao Zhu, Weiwei Sun, Xinyu Ma, Wenhan Liu | The paper introduces ReasonRank, a passage ranking method that leverages strong reasoning ability to improve information retrieval. It addresses the scarcity of reasoning-intensive training data by proposing an automated data synthesis framework using DeepSeek-R1 to generate high-quality training labels and a self-consistency filtering mechanism to ensure data quality. ReasonRank employs a two-stage post-training approach: cold-start supervised fine-tuning (SFT) for learning reasoning patterns and reinforcement learning (RL) with a multi-view ranking reward for enhancing ranking ability. Experiments on the BRIGHT benchmark demonstrate state-of-the-art performance with a score of 40.6, and improved efficiency over pointwise rerankers. ReasonRank provides AI practitioners with an effective approach to develop more powerful and efficient passage ranking systems that can reason effectively in complex search scenarios. |
| Natural Language Processing | WideSearch: Benchmarking Agentic Broad Info-Seeking (Read more on [arXiv](https://arxiv.org/abs/2508.07999) or [HuggingFace](https://huggingface.co/papers/2508.07999))| Yan Gao, Li Chen, Junjie Zhao, Jiawei Wang, Ryan Wong | The paper introduces WideSearch, a new benchmark to evaluate the reliability and completeness of AI agents in wide-scale information seeking tasks. It aims to address the current lack of benchmarks for evaluating agents' ability to perform reliable, complete information collection over a broad range of real user queries. The methodology involves curating 200 tasks from over 15 diverse domains, requiring agents to collect large-scale atomic information and arrange it into well-organized outputs. Results show that the best agentic search system achieves only a 5% success rate, demonstrating critical deficiencies in large-scale information seeking and indicating an urgent area for future research in improving agentic search. |
| Machine Learning | Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving
  Clipping Policy Optimization (Read more on [arXiv](https://arxiv.org/abs/2508.07629) or [HuggingFace](https://huggingface.co/papers/2508.07629))| Guanting Dong, Dening Liu, Xue Bai, Leiyu Pan, Zhenpeng Su | The paper introduces Klear-Reasoner, a model enhancing reasoning through a novel Gradient-Preserving clipping Policy Optimization (GPPO). It aims to address limitations in current clipping mechanisms by preserving gradients from clipped tokens, thereby improving exploration and learning from negative samples. The methodology involves long Chain-of-Thought supervised fine-tuning (SFT) followed by reinforcement learning with GPPO. Klear-Reasoner achieves 90.5% on AIME 2024 benchmark, showcasing superior reasoning capabilities in mathematics and programming. The GPPO method provides AI practitioners with a more efficient and stable approach to reinforcement learning by balancing training stability and gradient information preservation. |
| Natural Language Processing | UserBench: An Interactive Gym Environment for User-Centric Agents (Read more on [arXiv](https://arxiv.org/abs/2507.22034) or [HuggingFace](https://huggingface.co/papers/2507.22034))| Jianguo Zhang, Zhiwei Liu, Akshara Prabhakar, Zuxin Liu, Cheng Qian | The paper introduces UserBench, a user-centric gym environment for evaluating agents in multi-turn, preference-driven interactions. It aims to address the underexplored area of agents proactively collaborating with users having vague or evolving goals. UserBench utilizes simulated users who incrementally reveal preferences, requiring agents to clarify intent and make grounded decisions with tools. Evaluation of LLMs reveals a disconnect between task completion and user alignment, with models achieving only 20% full alignment with user intents on average. This highlights the need for agents to be collaborative partners and not just task executors. |
| Natural Language Processing | SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings
  and Speaks in Tokens (Read more on [arXiv](https://arxiv.org/abs/2508.05305) or [HuggingFace](https://huggingface.co/papers/2508.05305))| Anton Razzhigaev, Andrey Kuznetsov, Elizaveta Goncharova, Temurbek Rahmatullaev, Nikita Dragunov | SONAR-LLM is a decoder-only transformer that leverages sentence embeddings for autoregressive text generation. The paper addresses the limitations of both token-level language models and latent concept models by aligning continuous sentence embeddings with discrete token-level supervision through a frozen SONAR decoder. The method back-propagates token-level cross-entropy through the frozen SONAR decoder, aligning continuous predictions with discrete targets. Evaluated on summarization tasks, SONAR-LLM matches or exceeds the performance of other sentence-level approaches and shows favorable scaling behavior. Theoretically, SONAR-LLM demonstrates superior computational efficiency on long sequences compared to standard LLMs, suggesting potential for improved long-context handling. |
| Machine Learning | A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm
  Bridging Foundation Models and Lifelong Agentic Systems (Read more on [arXiv](https://arxiv.org/abs/2508.07407) or [HuggingFace](https://huggingface.co/papers/2508.07407))| Xinhao Yi, Yingxu Wang, Xi Zhang, Yanwen Peng, Jinyuan Fang | This survey provides a comprehensive overview of self-evolving AI agents, a new paradigm for bridging foundation models and lifelong agentic systems. The research aims to create a conceptual framework for understanding and comparing different strategies for agent evolution. The methodology involves reviewing existing techniques and categorizing them based on the components they target, including foundation models, prompts, memory, and tools. The survey identifies key evaluation, safety, and ethical considerations. The paper intends to provide researchers and practitioners with a systematic understanding of self-evolving AI agents, laying the foundation for the development of more adaptive, autonomous, and lifelong agentic systems, but does not present quantitative metrics. |
| Natural Language Processing | BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of
  Deep-Research Agent (Read more on [arXiv](https://arxiv.org/abs/2508.06600) or [HuggingFace](https://huggingface.co/papers/2508.06600))| Kai Zou, Ping Nie, Shengyao Zhuang, Xueguang Ma, Zijian Chen | This paper introduces BROWSECOMP-PLUS, a new benchmark for evaluating deep-research agents that integrates large language models (LLMs) with search tools. The research focuses on addressing fairness and transparency limitations in existing benchmarks by providing a fixed, carefully curated corpus with human-verified supporting documents and mined challenging negatives. The methodology involves constructing a 100k-document corpus from the original BrowseComp dataset, enabling controlled experimentation and disentangled analysis. Experiments with various LLMs and retrieval models show that GPT-5 with Qwen3-Embedding-8B achieves 70.1% accuracy, significantly outperforming open-source models like Search-R1 with BM25 at 3.86% accuracy. The primary implication is that BROWSECOMP-PLUS facilitates comprehensive evaluation and provides insights into retrieval effectiveness, citation accuracy, and context engineering for Deep-Research systems. |
| Natural Language Processing | OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks (Read more on [arXiv](https://arxiv.org/abs/2508.05614) or [HuggingFace](https://huggingface.co/papers/2508.05614))| Hongxing Li, Dingming Li, tricktreat, yanyc, wangzx1210 | The paper introduces OmniEAR, a benchmark for evaluating embodied agent reasoning in simulated environments. It aims to assess how language models reason about physical interactions, tool usage, and multi-agent coordination. OmniEAR utilizes structured text representation to model complex spatial relationships and continuous physical properties. Evaluation shows a significant performance drop when models are required to reason from constraints rather than explicit instructions, with success rates decreasing from 85-96% to 56-85% for tool reasoning. The benchmark reveals limitations in current models' abilities to understand embodied reasoning principles. |
| Multi-Modal | MolmoAct: Action Reasoning Models that can Reason in Space (Read more on [arXiv](https://arxiv.org/abs/2508.07917) or [HuggingFace](https://huggingface.co/papers/2508.07917))| Shuo Liu, Yuquan Deng, Haoquan Fang, Jiafei Duan, Jason Lee | The paper introduces MolmoAct, a vision-language-action model for robotic manipulation that incorporates spatial reasoning. The research aims to improve adaptability and explainability in robotic action by integrating perception, planning, and control within a structured pipeline. MolmoAct encodes observations into depth-aware tokens, generates spatial plans as editable trajectory traces, and predicts low-level actions using a three-stage process. The model achieves 70.5% zero-shot accuracy on SimplerEnv Visual Matching tasks and 86.6% average success on LIBERO, indicating strong performance across simulation and real-world settings. The release of MolmoAct and associated datasets offers AI practitioners a state-of-the-art robotics foundation model and a blueprint for building action reasoning models. |
| Natural Language Processing | Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts (Read more on [arXiv](https://arxiv.org/abs/2508.07785) or [HuggingFace](https://huggingface.co/papers/2508.07785))| Tieyuan Chen, Zhanchao Zhou, Xiaodong Chen, Haoxing Chen, Haoyuan Wu | The paper introduces Grove MoE, a novel Mixture of Experts (MoE) architecture designed for efficient and scalable large language models (LLMs). The primary objective is to overcome the limitations of traditional MoE models by incorporating experts of varying sizes with a dynamic activation mechanism. Grove MoE utilizes adjugate experts and upcycling strategies on the Qwen3-30B-A3B-Base model, creating GroveMoE-Base and GroveMoE-Inst. Empirical results demonstrate that the models dynamically activate 3.14-3.28B parameters and achieve performance comparable to SOTA open-source LLMs of similar or even larger sizes. The findings suggest that Grove MoE offers a computationally efficient approach to expand model capacity and enhance LLM performance. |
| Natural Language Processing | Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via
  Past-Future (Read more on [arXiv](https://arxiv.org/abs/2508.06026) or [HuggingFace](https://huggingface.co/papers/2508.06026))| Qiufeng Wang, Junfeng Fang, Cunxiang Wang, Xin Wang, Yidong Wang | This paper introduces Temporal Self-Rewarding Language Models to address diminishing preference signals in iterative self-improvement. The research aims to decouple chosen and rejected responses via past-future model generations for sustained learning. The methodology involves Anchored Rejection using past models and Future-Guided Chosen sampling using next-generation models. Experiments with Llama3.1-8B achieve a 29.44% win rate on AlpacaEval 2.0, a 9.75% improvement over self-rewarding. The findings suggest a new paradigm for iterative self-improvement by strategically coordinating models to maintain effective learning signals. |
| Computer Vision | Reinforcement Learning in Vision: A Survey (Read more on [arXiv](https://arxiv.org/abs/2508.08189) or [HuggingFace](https://huggingface.co/papers/2508.08189))| Qingwei Meng, Kevin Qinghong Lin, Joya Chen, Chen Gao, Weijia Wu | This survey synthesizes recent advances in visual reinforcement learning, focusing on the integration of RL with multimodal large models. It aims to provide a coherent overview of this rapidly expanding field and highlight promising research directions. The survey categorizes over 200 representative works into four key domains (MLLMs, visual generation, unified models, and VLA agents) and examines algorithmic design, reward engineering, and benchmark progress. Trends like curriculum-driven training and unified reward modeling are discussed. It also reviews evaluation protocols and open challenges. |
| Reinforcement Learning | Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning (Read more on [arXiv](https://arxiv.org/abs/2508.08221) or [HuggingFace](https://huggingface.co/papers/2508.08221))| Jiaheng Liu, Weixun Wang, Yancheng He, Jiashun Liu, Zihe Liu | This paper offers a deep dive into reinforcement learning (RL) techniques for large language model (LLM) reasoning. It addresses the absence of standardized guidelines and conflicting conclusions by systematically reviewing RL techniques, analyzing internal mechanisms, and conducting isolated evaluations within a unified framework. The results reveal that a minimalist combination of two techniques, advantage normalization and token-level loss aggregation (Lite PPO), enhances learning capacity in critic-free policies using vanilla PPO loss, consistently improving performance, surpassing strategies like GRPO and DAPO (accuracy improvements quantified in mathematical benchmarks, see paper). The study provides clear guidelines for selecting RL techniques tailored to specific setups and highlights the importance of contextual adaptability in technique selection for AI practitioners. It presents a reliable roadmap for practitioners navigating the RL for the LLM domain. |
| Computer Vision | Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided
  Region Control (Read more on [arXiv](https://arxiv.org/abs/2508.08134) or [HuggingFace](https://huggingface.co/papers/2508.08134))| Hongyu Liu, Xinhua Zhang, Kunyu Feng, Mingzhe Zheng, Zeqian Long | The paper introduces Follow-Your-Shape, a training-free framework for precise and controllable image editing of object shapes while preserving non-target content. It addresses the challenge of large-scale shape transformations by computing a Trajectory Divergence Map (TDM) to localize editable regions and guide Scheduled KV Injection. The method achieves state-of-the-art performance on a new benchmark, ReShapeBench, specifically designed for shape-aware editing. Quantitatively, it demonstrates superior background preservation with a PSNR of 35.79. This approach enables more controlled and faithful image editing, particularly in scenarios involving significant structural modifications. |
| Natural Language Processing | Less Is More: Training-Free Sparse Attention with Global Locality for
  Efficient Reasoning (Read more on [arXiv](https://arxiv.org/abs/2508.07101) or [HuggingFace](https://huggingface.co/papers/2508.07101))| Baihong Yuan, Shijie Cao, Arti Jain, Zhihao Zhang, Lijie Yang | The paper introduces LessIsMore, a training-free sparse attention mechanism designed to improve the efficiency of large reasoning models (LRMs). It addresses the issue of accuracy degradation in existing sparse attention methods due to accumulated errors during long sequence generation by exploiting spatial and recency locality in attention distributions. The methodology aggregates token selections from local attention heads with recent contextual information for a unified cross-head token ranking in decoding layers. Evaluation demonstrates LessIsMore preserves, and sometimes improves, accuracy while achieving a 1.1x average decoding speed-up compared to full attention and attends to 2x fewer tokens without accuracy loss. This approach allows AI practitioners to significantly reduce computational overhead in LRMs without sacrificing performance, making large-scale reasoning more accessible. |
| Multi-Modal | VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation
  for Multilingual Long Document Understanding (Read more on [arXiv](https://arxiv.org/abs/2508.07493) or [HuggingFace](https://huggingface.co/papers/2508.07493))| Tong Yu, Chenguang Wang, Jihyung Kil, Ming Li, Jian Chen | The paper introduces VisR-Bench, a multilingual benchmark for visual retrieval-augmented generation in long documents. It aims to evaluate MLLM retrieval performance in visually rich, multi-language documents. The benchmark consists of over 35K QA pairs across 1.2K documents in 16 languages and evaluates retrieval models including text-based, multimodal encoders, and MLLMs. Results show that MLLMs significantly outperform text-based methods but struggle with structured tables and low-resource languages, achieving a top-1 accuracy of 75.23% on the English split using ColQwen2. VisR-Bench provides a comprehensive resource for advancing multimodal document retrieval systems that are both robust and linguistically diverse. |
| Machine Learning | Shortcut Learning in Generalist Robot Policies: The Role of Dataset
  Diversity and Fragmentation (Read more on [arXiv](https://arxiv.org/abs/2508.06426) or [HuggingFace](https://huggingface.co/papers/2508.06426))| Hengtao Shen, Lianli Gao, Junlin Xie, Xu Luo, Youguang Xing | The paper investigates limited generalization in generalist robot policies trained on large-scale datasets, attributing it to shortcut learning. It aims to identify contributors to shortcut learning in robot policies. The methodology includes theoretical analysis and empirical evaluation, uncovering limited diversity within sub-datasets and distributional disparities across them. Experiments demonstrate that robotic data augmentation reduces shortcut learning, improving generalization in SIMPLER and real-world environments. The findings offer insights for dataset collection and augmentation to enhance generalist robot policy generalization. |
| Natural Language Processing | MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs (Read more on [arXiv](https://arxiv.org/abs/2508.05257) or [HuggingFace](https://huggingface.co/papers/2508.05257))| Jianguo Li, Jing Zhang, Zhenzhong Lan, Mingming Ha, Xiaodong Chen | This paper introduces Mixture-of-Basis-Experts (MoBE), a novel method for compressing Mixture-of-Experts (MoE) based Large Language Models (LLMs). The research aims to reduce memory requirements of MoE models while preserving accuracy. The key methodology involves factorizing expert weight matrices using a shared basis and expert-specific transformation matrices, optimized to minimize reconstruction error. Experiments demonstrate that MoBE reduces parameter counts by 24%-30% on models like Qwen3-235B-A22B-2507, DeepSeek-V3-0324, and Kimi-K2-Instruct with only a 1%-2% accuracy drop. This technique provides a practical solution for deploying large MoE models with limited resources. |
| Natural Language Processing | GLiClass: Generalist Lightweight Model for Sequence Classification Tasks (Read more on [arXiv](https://arxiv.org/abs/2508.07662) or [HuggingFace](https://huggingface.co/papers/2508.07662))| Alexander Yavorskyi, Oleksandr Lukashov, Dmytro Vodianytskyi, Mykhailo Shtopko, Ihor Stepanov | The paper introduces GLiClass, a generalist lightweight model for sequence classification tasks designed for high accuracy and efficiency. It addresses the challenge of balancing performance and scalability in text classification, especially with large label sets. GLiClass uses a novel uni-encoder architecture with joint text and label processing and layer-wise attention re-weighting. Experiments show GLiClass surpasses cross-encoder baselines by 5.5% in average F1 score while maintaining practical inference speeds. The model provides AI practitioners with a versatile solution for text classification tasks, excelling in scenarios requiring strong zero-shot capabilities and efficient processing of numerous labels. |
| Machine Learning | Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant
  Safeguards into Open-Weight LLMs (Read more on [arXiv](https://arxiv.org/abs/2508.06601) or [HuggingFace](https://huggingface.co/papers/2508.06601))| Robert Kirk, Tomek Korbak, Quentin Anthony, Stephen Casper, Kyle O'Brien | This paper introduces a method to build tamper-resistant safeguards into open-weight LLMs by filtering pretraining data. The research aims to prevent unwanted capabilities by removing dual-use content, specifically biothreat-related text. The methodology involves a multi-stage pipeline for scalable data filtering, combining rule-based and machine learning classifiers. Results show that pretraining multiple 6.9B-parameter models with filtered data exhibit substantial resistance to adversarial fine-tuning (up to 10,000 steps), outperforming existing post-training baselines. The main implication is that pretraining data curation offers a promising layer of defense for open-weight AI systems, but defense-in-depth approaches are still needed. |
| Machine Learning | Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System (Read more on [arXiv](https://arxiv.org/abs/2508.06059) or [HuggingFace](https://huggingface.co/papers/2508.06059))| Reynold Cheng, Dacheng Wen, Bin Benjamin Zhu, Yupeng Li, Haorui He | The paper introduces Fact2Fiction, a novel poisoning attack targeting agentic fact-checking systems that utilize LLMs for claim verification. The research investigates vulnerabilities in these systems by exploiting system-generated justifications to craft targeted malicious evidence against sub-claims. Fact2Fiction mirrors the claim decomposition strategy and allocates malicious evidence to emphasized sub-claims, achieving 8.9%-21.2% higher attack success rates than state-of-the-art attacks. Results demonstrate justifications introduce a transparency-security trade-off, improving attack effectiveness under constrained budgets. The findings highlight the urgent need for enhanced defensive countermeasures to protect these systems from sophisticated attacks and maintain trustworthy information ecosystems. |
| Multi-Modal | Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with
  Patch-level CLIP Latents (Read more on [arXiv](https://arxiv.org/abs/2508.05954) or [HuggingFace](https://huggingface.co/papers/2508.05954))| Mohit Bansal, Chuan Li, Amir Zadeh, Jaemin Cho, Han Lin | BIFROST-1 is a framework for integrating visual synthesis into large language models (LLMs) without sacrificing reasoning capabilities. The paper explores bridging pre-trained multimodal LLMs (MLLMs) and diffusion models using patch-level CLIP image embeddings. The key methodology involves integrating patch-level CLIP embeddings into a diffusion model with lightweight ControlNet adaptation and equipping the MLLM with a visual generation branch. Experiments demonstrate BIFROST-1 achieves comparable or better visual fidelity and multimodal understanding than previous methods with lower compute, obtaining a FID of 25.77 on ImageNet. This offers a training-efficient approach to enhancing MLLMs with high-fidelity controllable image generation. |
| Multi-Modal | When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with
  Benign Inputs (Read more on [arXiv](https://arxiv.org/abs/2508.03365) or [HuggingFace](https://huggingface.co/papers/2508.03365))| Dasol Choi, Taeyoun Kwon, Hiskias Dingeto, Bodam Kim, oneonlee | The paper introduces WHISPERINJECT, a two-stage adversarial attack framework targeting audio-language models. It investigates how to generate harmful content by using imperceptible perturbations in audio inputs that remain benign to human listeners. The method uses Reinforcement Learning with Projected Gradient Descent to circumvent safety protocols and Project Gradient Descent to inject payloads into benign audio carriers. Experiments demonstrate a success rate exceeding 86% across models like Qwen2.5-Omni-3B, Qwen2.5-Omni-7B, and Phi-4-Multimodal. The framework reveals a practical method for manipulating AI behavior, highlighting vulnerabilities beyond traditional text-based attacks. |
| Natural Language Processing | Compressing Chain-of-Thought in LLMs via Step Entropy (Read more on [arXiv](https://arxiv.org/abs/2508.03346) or [HuggingFace](https://huggingface.co/papers/2508.03346))| Zhijian Xu, Xiangyu Wen, Ziyang Zheng, Jianyuan Zhong, Zeju Li | This paper introduces a novel method for compressing Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs) using step entropy to identify and prune redundant steps. The research aims to reduce inference costs and improve efficiency by quantifying the informational contribution of each step.  The proposed method involves calculating step entropy, pruning low-entropy steps, and optionally fine-tuning the LLM to autonomously generate compressed CoTs.  Experiments on mathematical reasoning benchmarks show that up to 80% of low-entropy steps can be pruned with minimal accuracy degradation, achieving token reductions of 16-45%.  This compression framework allows for more efficient LLM deployment by reducing computational overhead without sacrificing accuracy. |
| Multi-Modal | Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations
  and Sentences (Read more on [arXiv](https://arxiv.org/abs/2508.03542) or [HuggingFace](https://huggingface.co/papers/2508.03542))| Matvey Skripkin, Elvir Karimov, Artyom Iudin, Dmitrii Tarasov, Dmitrii Korzh | This paper introduces a novel speech-to-LaTeX (S2L) dataset and models for converting spoken mathematical expressions and sentences. The primary objective is to address the limitations of existing approaches by providing a large-scale, open-source, multilingual dataset and exploring multimodal AI techniques for S2L conversion. The methodology combines ASR post-correction, few-shot prompting, and audio language models. The best models achieve an equation CER between 27.7% and 30.0% on English data and an equation CER of 40% for the S2L-sentences benchmark. This research offers resources and methodologies that can benefit AI practitioners by facilitating the development of more robust and accessible tools for mathematical content recognition. |
