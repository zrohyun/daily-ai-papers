

## Papers for 2025-08-29

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Computer Vision | Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable
  Text-to-Image Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2508.20751) or [HuggingFace](https://huggingface.co/papers/2508.20751))| Jiazi Bu, Yujie Zhou, Zhimin Li, yuhangzang, CodeGoat24 | This paper introduces Pref-GRPO, a novel pairwise preference reward-based GRPO method for stable text-to-image reinforcement learning. The research addresses the problem of reward hacking in existing pointwise RM-based GRPO methods due to illusory advantage. The method reformulates the GRPO optimization objective from absolute reward score maximization to pairwise preference fitting using a pairwise preference RM. Experiments show that Pref-GRPO achieves a 5.84% increase in overall score on UNIGENBENCH compared to UR-based methods. Pref-GRPO offers more stable advantages than pointwise scoring, mitigating reward hacking problems and enhancing T2I generation stability. |
| Reinforcement Learning | rStar2-Agent: Agentic Reasoning Technical Report (Read more on [arXiv](https://arxiv.org/abs/2508.20722) or [HuggingFace](https://huggingface.co/papers/2508.20722))| Weijiang Xu, Yi Zhu, Yifei Liu, Ning Shang, lynazhang | The paper introduces rStar2-Agent, a 14B math reasoning model trained with agentic reinforcement learning. It explores improving model performance by integrating Python coding tools and environment interactions for complex problem-solving. The methodology employs an efficient RL infrastructure (GRPO-RoC) and a multi-stage training recipe, boosting a pre-trained 14B model to state-of-the-art in 510 RL steps. Results show an average pass@1 score of 80.6% on AIME24 and 69.8% on AIME25, surpassing DeepSeek-R1 (671B). The main implication is a demonstration that targeted agentic reinforcement learning can significantly enhance reasoning abilities using modest compute resources. |
| Computer Vision | USO: Unified Style and Subject-Driven Generation via Disentangled and
  Reward Learning (Read more on [arXiv](https://arxiv.org/abs/2508.18966) or [HuggingFace](https://huggingface.co/papers/2508.18966))| Jiahe Tian, Mengqi Huang, wuwx, cb1cyf, fenfan | The paper presents USO, a unified framework for style and subject-driven image generation by disentangling content and style. It addresses the challenge of simultaneously achieving stylistic similarity and subject consistency through a cross-task co-disentanglement paradigm. The methodology includes a novel triplet curation framework, progressive style alignment, content-style disentanglement training, and a style reward learning paradigm (SRL). Experiments on the introduced USO-Bench show USO achieves state-of-the-art performance, reflected in a CSD score of 0.557 for style-driven generation. USO provides a unified approach to customization tasks, improving controllability and disentanglement capabilities for image generation models. |
| Reinforcement Learning | AWorld: Orchestrating the Training Recipe for Agentic AI (Read more on [arXiv](https://arxiv.org/abs/2508.20404) or [HuggingFace](https://huggingface.co/papers/2508.20404))| Qintong Wu, Dong Wang, Chenyi Zhuang, Chengyue Yu, IcyFish | This paper introduces AWORLD, an open-source system designed for large-scale agent-environment interaction to enhance agentic AI training. The main objective is to address the bottleneck of inefficient experience generation in complex benchmarks like GAIA through distributed task execution. AWORLD accelerates experience collection by 14.6x compared to single-node sequential execution by distributing tasks across a cluster using Kubernetes. By training a Qwen3-32B-based agent, the system improves overall GAIA accuracy from 21.59% to 32.23%, outperforming the base model and achieving competitive performance on challenging levels. AWORLD provides a practical and scalable pipeline for agentic AI training, facilitating efficient interaction and demonstrable model improvement. |
| Computer Vision | Mixture of Contexts for Long Video Generation (Read more on [arXiv](https://arxiv.org/abs/2508.21058) or [HuggingFace](https://huggingface.co/papers/2508.21058))| Junfei Xiao, Yuwei Guo, Lvmin Zhang, Ceyuan Yang, Shengqu Cai | The paper introduces Mixture of Contexts (MoC), a learnable sparse attention routing module for long video generation. The primary research objective is to mitigate the quadratic cost of self-attention in diffusion transformers when generating long-context videos by recasting video generation as an internal information retrieval task. MoC dynamically selects informative chunks and mandatory anchors using a top-k router with causal masking. Experiments show MoC prunes over 85% of token pairs, reducing attention FLOPs by up to 7x and achieving a 2.2x speedup on minute-scale scenes while maintaining or improving fidelity. The method offers AI practitioners a way to scale video generation to longer contexts without prohibitive computational costs. |
| Multi-Modal | CogVLA: Cognition-Aligned Vision-Language-Action Model via
  Instruction-Driven Routing & Sparsification (Read more on [arXiv](https://arxiv.org/abs/2508.21046) or [HuggingFace](https://huggingface.co/papers/2508.21046))| Liqiang Nie, Jie He, Rui Shao, Renshan Zhang, Wei Li | The paper introduces CogVLA, a novel Vision-Language-Action model, to enhance efficiency and performance by instruction-driven routing and sparsification. The research aims to address the computational overhead and semantic degradation prevalent in VLMs by incorporating a 3-stage architecture inspired by human multimodal coordination. CogVLA employs Encoder-FiLM based Aggregation Routing (EFA-Routing), LLM-FiLM based Pruning Routing (LFP-Routing), and V-L-A Coupled Attention (CAtten) for progressive visual sparsification and cross-modal alignment. Experimental results on the LIBERO benchmark demonstrate state-of-the-art performance with a 97.4% success rate and a 2.8x reduction in inference latency compared to OpenVLA. This suggests a more efficient and scalable approach to VLA tasks for AI practitioners. |
| Natural Language Processing | MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World
  Tasks via MCP Servers (Read more on [arXiv](https://arxiv.org/abs/2508.20453) or [HuggingFace](https://huggingface.co/papers/2508.20453))| Shashank Biju, Hemani Patel, Qi Chang, Zhenting Wang, ankits0052 | The paper introduces MCP-Bench, a novel benchmark for evaluating large language models (LLMs) in tool-use scenarios involving realistic, multi-step tasks. MCP-Bench leverages 28 Model Context Protocol (MCP) servers spanning 250 tools across diverse domains, such as finance and scientific computing, to test LLMs' ability to perform tool retrieval, cross-tool coordination, and complex planning. Experiments on 20 advanced LLMs reveal persistent challenges, with top-performing models achieving overall scores of around 0.75, while smaller models lag behind due to weaker dependency awareness and parallelism. The benchmark aims to address limitations in existing tool-use evaluations, which often rely on explicit tool specifications and isolated domain operations, offering a standardized platform for assessing agentic reasoning and tool-use capabilities. |
| Computer Vision | OneReward: Unified Mask-Guided Image Generation via Multi-Task Human
  Preference Learning (Read more on [arXiv](https://arxiv.org/abs/2508.21066) or [HuggingFace](https://huggingface.co/papers/2508.21066))| Yitong Wang, Shiyin Wang, Yuan Gong, wujie10, XionghuiWang | The paper introduces OneReward, a unified reinforcement learning framework for improving mask-guided image generation across multiple tasks. It addresses the challenge of training versatile image editing models by using a single vision-language model (VLM) as a generative reward model, facilitating multi-task learning without task-specific fine-tuning. The key methodology involves directly optimizing a pre-trained base model via multi-task reinforcement learning, guided by the VLM-based reward. Experimental results demonstrate superior performance compared to commercial and open-source alternatives, with Seedream 3.0 Fill achieving a usability rate of 69.04% on image fill. The framework's unified approach simplifies training and enhances generalization for image editing tasks, implying a more efficient route for developing versatile image generation models. |
| Natural Language Processing | Turning the Spell Around: Lightweight Alignment Amplification via
  Rank-One Safety Injection (Read more on [arXiv](https://arxiv.org/abs/2508.20766) or [HuggingFace](https://huggingface.co/papers/2508.20766))| Bernard Ghanem, George Turkiyyah, Hasan Abed Al Kader Hammoud, Harethah Abu Shairah | The paper introduces RANK-One SafetY INJECTION (ROSI), a lightweight method to enhance safety alignment in LLMs. It investigates whether safety can be systematically amplified by steering activations toward the refusal-mediating subspace. ROSI applies a fine-tuning-free rank-one weight modification to residual stream write matrices using a safety direction derived from harmful/harmless instruction pairs. Experiments show ROSI consistently increases safety refusal rates, as evaluated by Llama Guard 3, while preserving utility on standard benchmarks. The implication for AI practitioners is that targeted weight steering is a cheap and potent mechanism to improve LLM safety. |
| Natural Language Processing | Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability
  in Knowledge and Safety with DuET-PD (Read more on [arXiv](https://arxiv.org/abs/2508.17450) or [HuggingFace](https://huggingface.co/papers/2508.17450))| Roy Ka-Wei Lee, Nancy F. Chen, Zhengyuan Liu, Daniel Wai Kit Chin, Incomple | The paper introduces DuET-PD, a framework for evaluating and enhancing robustness and adaptability of LLMs in persuasive dialogues. It investigates how LLMs balance gullibility to misinformation and resistance to valid corrections in knowledge and safety domains. The methodology involves multi-turn stance-change dialogues with positive/corrective and negative/misleading persuasion, evaluated using MMLU-Pro and SALAD-Bench. Results show GPT-4o achieves only 27.32% accuracy in MMLU-Pro under misleading persuasion, and concerning sycophancy in newer models. To address this, they introduce Holistic DPO, improving Llama-3.1-8B-Instruct's safety accuracy from 4.21% to 76.54%, offering a pathway to more reliable and adaptable LLMs. |
| Computer Vision | Dress&Dance: Dress up and Dance as You Like It - Technical Preview (Read more on [arXiv](https://arxiv.org/abs/2508.21070) or [HuggingFace](https://huggingface.co/papers/2508.21070))| Yu-Xiong Wang, Minh Phuoc Vo, Aayush Bansal, Jun-Kun Chen | The paper introduces Dress&Dance, a video diffusion framework for high-quality virtual try-on with motion guidance. It addresses the challenge of generating temporally consistent and realistic videos of users wearing desired garments by unifying multi-modal inputs (text, images, and videos) through a novel conditioning network called CondNet. The method uses a multi-stage progressive training approach and synthetic triplets to enhance garment registration and motion fidelity. Experiments demonstrate that Dress&Dance outperforms existing open-source and commercial solutions, achieving a PSNR of 22.41 on a captured dataset. This research allows AI practitioners to generate high-resolution virtual try-on videos with precise motion control, improving user experience and flexibility. |
| Natural Language Processing | OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn
  Dialogue with Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2508.21061) or [HuggingFace](https://huggingface.co/papers/2508.21061))| Alex Endert, Eunyee Koh, Shunan Guo, Adam Coscia | The paper introduces OnGoal, an LLM chat interface that tracks and visualizes conversational goals to help users manage goal progress. It investigates how to enhance a linear chat interface to aid users in evaluating and reviewing their conversational goals during LLM interactions. The study employs a three-stage LLM-assisted goal pipeline for inferring, merging, and evaluating user goals. A user study with 20 participants shows that OnGoal reduced time and effort in achieving goals, leading to increased engagement and resilience. This suggests that tracking and visualizing goals can enhance user interaction in complex LLM dialogues, implying that future interfaces should improve goal communication and reduce cognitive load. |
| Computer Vision | Multi-View 3D Point Tracking (Read more on [arXiv](https://arxiv.org/abs/2508.21060) or [HuggingFace](https://huggingface.co/papers/2508.21060))| Irem Demir, Siyuan Li, Marko Mihajlovic, Haofei Xu, Frano Rajiƒç | The paper introduces a data-driven approach for multi-view 3D point tracking. It addresses the challenge of tracking arbitrary 3D points across multiple camera views by fusing multi-view features into a unified 3D point cloud and using kNN correlation with a transformer-based update. The method achieves median trajectory errors of 3.1 cm and 2.0 cm on Panoptic Studio and DexYCB, respectively. The results demonstrate robust and accurate online tracking with a practical number of cameras. This provides AI practitioners with a tool for real-world applications requiring accurate multi-view 3D tracking. |
| Computer Vision | FakeParts: a New Family of AI-Generated DeepFakes (Read more on [arXiv](https://arxiv.org/abs/2508.21052) or [HuggingFace](https://huggingface.co/papers/2508.21052))| Xi Wang, Awais Hussain Sani, Samy Aimeur, Soobash Daiboo, Gaetan Brison | This paper introduces FakeParts, a new class of deepfakes characterized by localized manipulations within otherwise authentic videos, addressing the challenge of detecting these subtle forgeries. The research aims to provide a benchmark dataset and analysis for partial deepfake detection due to the limitations of existing benchmarks. FakePartsBench, a large-scale dataset comprising over 25K videos with pixel-level annotations, is presented to facilitate comprehensive evaluation. Results from user studies demonstrate that FakeParts reduces human detection accuracy by over 30% compared to traditional deepfakes, while similar degradation is observed in state-of-the-art detection models. The study underscores the vulnerability of current deepfake detection methods to partial manipulations and offers resources for developing more robust defenses. |
| Natural Language Processing | Provable Benefits of In-Tool Learning for Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2508.20755) or [HuggingFace](https://huggingface.co/papers/2508.20755))| Vivien Cabannes, Charles Arnal, Ambroise Odonnat, Sam Houliston | This paper explores the theoretical benefits of in-tool learning (external retrieval) compared to in-weight learning (memorization) for large language models (LLMs). The research investigates the most efficient method for LLMs to acquire and utilize knowledge, questioning whether facts should be internalized or accessed externally. The study uses theoretical lower and upper bounds, along with circuit constructions, validated by controlled experiments where tool-using models outperform memorizing ones. The results show that in-weight memorization is fundamentally limited by parameter count, while tool-use enables unbounded factual recall via efficient circuit construction, further supported by experiments showing teaching tool-use is more effective than finetuning facts into memory. The findings suggest that tool-augmented workflows are provably more scalable for LLMs, offering a path to open-ended knowledge access and generalization. |
| Computer Vision | Collaborative Multi-Modal Coding for High-Quality 3D Generation (Read more on [arXiv](https://arxiv.org/abs/2508.15228) or [HuggingFace](https://huggingface.co/papers/2508.15228))| Ziwei Liu, Liang Pan, Zhaoxi Chen, Ziang Cao | The paper introduces TriMM, a collaborative multi-modal coding framework for high-quality 3D generation from limited training data. It addresses the scarcity of 3D training data by integrating information from RGB images, RGBD data, and point clouds using modality-specific encoders and a shared decoder. The framework incorporates 2D and 3D supervision, along with a triplane latent diffusion model, to enhance texture and geometry. Experiments on standard benchmarks demonstrate TriMM achieves competitive performance, with a PSNR of 27.81 on Objaverse dataset using RGB data, compared to state-of-the-art methods that rely on larger datasets. TriMM offers a promising pathway to address the challenge of 3D training data scarcity by effectively leveraging multi-modal information. |
| Computer Vision | ROSE: Remove Objects with Side Effects in Videos (Read more on [arXiv](https://arxiv.org/abs/2508.18633) or [HuggingFace](https://huggingface.co/papers/2508.18633))| Hantang Liu, Zixiang Gao, Jianshu Zeng, Yutong Feng, Chenxuan Miao | This paper introduces ROSE, a framework for removing objects from videos while addressing their side effects like shadows and reflections. It aims to overcome the scarcity of paired training data by using 3D rendering to generate synthetic datasets with diverse scenes, objects, and camera trajectories. ROSE is implemented as a diffusion transformer-based video inpainting model, employing reference-based erasing and difference mask prediction to localize object-correlated areas. Experiments on the newly introduced ROSE-Bench demonstrate ROSE achieves superior performance compared to existing models. The framework enables AI practitioners to generate realistic video edits by effectively removing objects along with their environmental side effects. |
