

## Papers for 2025-08-01

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Machine Learning | Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving (Read more on [arXiv](https://arxiv.org/abs/2507.23726) or [HuggingFace](https://huggingface.co/papers/2507.23726))| Zhicheng Jiang, Wenhao Huang, Liankai Huang, Jinming Gu, Luoxin Chen | This paper introduces Seed-Prover, a lemma-style whole-proof reasoning model for automated theorem proving. The research aims to enhance mathematical reasoning capabilities of LLMs by leveraging formal verification with long chain-of-thought reasoning. The methodology involves iteratively refining proofs based on Lean feedback, proved lemmas, and self-summarization, along with a geometry reasoning engine Seed-Geometry. Seed-Prover achieves 78.1% on formalized past IMO problems and outperforms previous state-of-the-art on multiple formal benchmarks. This advancement suggests the effectiveness of formal verification in improving automated mathematical reasoning, potentially enabling more robust and reliable AI systems for mathematical tasks. |
| Computer Vision | Phi-Ground Tech Report: Advancing Perception in GUI Grounding (Read more on [arXiv](https://arxiv.org/abs/2507.23779) or [HuggingFace](https://huggingface.co/papers/2507.23779))| Kai Qiu, Qi Dai, Jialiang Zhu, Ziqiang Xu, Miaosen Zhang | The paper introduces Phi-Ground, a model family designed to improve GUI grounding for Computer Use Agents. It addresses the challenge of achieving high accuracy in GUI grounding, especially on complex benchmarks like ScreenSpot-pro and UI-Vision. The methodology involves an empirical study of training grounding models, focusing on data collection and model training, with a two-phase approach using advanced MLLMs for location descriptions and a trained grounding model for coordinate output. Phi-Ground achieves state-of-the-art performance on five grounding benchmarks, reaching 55.0% and 36.2% on ScreenSpot-pro and UI-Vision in agent settings, respectively, and supporting the Pareto frontier regarding computational cost. The improved grounding capabilities have significant implications for enabling more effective CUAs and advancing perception tasks. |
| Natural Language Processing | C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring
  Challenges in Complex Conversations (Read more on [arXiv](https://arxiv.org/abs/2507.22968) or [HuggingFace](https://huggingface.co/papers/2507.22968))| Yiwen Guo, Wei Tao, Chengqian Ma | This paper introduces C³, a bilingual benchmark for evaluating spoken dialogue models (SDMs) on complex conversations. It aims to assess how well SDMs handle challenges like ambiguity and context-dependency in both English and Chinese. The methodology involves a novel dataset of 1,079 instances coupled with an LLM-based evaluation method. Experimental results reveal variations in SDM performance across languages and phenomena, with top models achieving accuracies of 55.68% (English) and 40.08% (Chinese) in overall accuracy; Specifically, SDMs often face greater difficulty dealing with semantically ambiguous dialogues in Chinese. C³ provides AI practitioners with a valuable resource for understanding and improving SDMs' ability to engage in nuanced, human-like interactions. |
| Natural Language Processing | RecGPT Technical Report (Read more on [arXiv](https://arxiv.org/abs/2507.22879) or [HuggingFace](https://huggingface.co/papers/2507.22879))| Jian Wu, Jiakai Tang, Gaoyang Guo, Dian Chen, Chao Yi | The paper introduces RecGPT, a next-generation recommender system framework centered on user intent modeling by integrating large language models (LLMs). RecGPT transforms log-fitting recommendation into an intent-centric process through user interest mining, item retrieval, and explanation generation. The framework incorporates a multi-stage training paradigm, guided by a Human-LLM cooperative judge system, to align general-purpose LLMs to domain-specific recommendation tasks at scale. Online experiments on Taobao App demonstrate RecGPT achieves consistent performance gains across stakeholders, including a +6.33% increase in CTR. This LMM-driven, intent-centric design fosters a more sustainable and mutually beneficial recommendation ecosystem. |
| Multi-Modal | villa-X: Enhancing Latent Action Modeling in Vision-Language-Action
  Models (Read more on [arXiv](https://arxiv.org/abs/2507.23682) or [HuggingFace](https://huggingface.co/papers/2507.23682))| Kaixin Wang, Chuheng Zhang, Pushi Zhang, Hangxing Wei, Xiaoyu Chen | The paper introduces villa-X, a Visual-Language-Latent-Action (ViLLA) framework that enhances latent action modeling for improved robot manipulation policies. It aims to improve how latent actions are learned and integrated into VLA pre-training by incorporating a proprio Forward Dynamics Model (FDM) module, grounding latent actions in robot dynamics.  The methodology involves jointly learning latent action and robot action experts through a joint diffusion process, conditioning robot action prediction on latent actions. Experimental results demonstrate that villa-X achieves superior performance across simulated and real-world environments, with a 59.6% average success rate on the Google robot SIMPLER benchmark, suggesting its effectiveness in various manipulation tasks. The villa-X framework offers AI practitioners a structured approach to leverage latent actions for more generalizable and effective robot learning. |
| Reinforcement Learning | Scalable Multi-Task Reinforcement Learning for Generalizable Spatial
  Intelligence in Visuomotor Agents (Read more on [arXiv](https://arxiv.org/abs/2507.23698) or [HuggingFace](https://huggingface.co/papers/2507.23698))| Anji Liu, Bowei Zhang, Haiwen Xia, Zhancun Mu, Shaofei Cai | The paper explores multi-task reinforcement learning (RL) to enhance spatial reasoning and interaction capabilities of visuomotor agents, aiming for zero-shot generalization in 3D environments. It addresses the challenge of multi-task RL representation by establishing cross-view goal specification as a unified goal space and proposes automated task synthesis in Minecraft for large-scale training. RL significantly boosts interaction success rates by 4x, enabling zero-shot generalization across diverse environments, including real-world settings. The findings imply that RL post-training can substantially augment the core competencies of visuomotor policies, endowing them with exceptional domain generalization. The method achieves a 48% success rate in handling complex, target-invisible Minecraft interaction tasks. |
| Natural Language Processing | Persona Vectors: Monitoring and Controlling Character Traits in Language
  Models (Read more on [arXiv](https://arxiv.org/abs/2507.21509) or [HuggingFace](https://huggingface.co/papers/2507.21509))| Jack Lindsey, Owain Evans, Henry Sleight, Andy Arditi, Runjin Chen | This paper introduces "persona vectors," linear directions in a language model's activation space that capture character traits. The research aims to identify and control personality shifts in large language models, specifically focusing on undesirable traits like evil, sycophancy, and hallucination. The methodology involves an automated pipeline to extract persona vectors from natural language descriptions and then applying these vectors to monitor and control personality shifts during training and deployment. The primary results show a strong correlation (r = 0.75-0.83) between activation changes along corresponding persona vectors and trait expression scores. This work offers AI practitioners a tool to monitor, mitigate, and proactively prevent unintended and harmful personality changes in language models. |
| Machine Learning | On the Expressiveness of Softmax Attention: A Recurrent Neural Network
  Perspective (Read more on [arXiv](https://arxiv.org/abs/2507.23632) or [HuggingFace](https://huggingface.co/papers/2507.23632))| Eric C. Larson, Gabriel Mongaras | This paper analyzes softmax attention's expressiveness through a recurrent neural network (RNN) lens. It investigates why softmax attention outperforms linear attention despite the latter's computational advantages. The methodology involves deriving a recurrent formulation of softmax attention using its Taylor series expansion and ablating components of this recurrent form. The results show that linear attention is a first-order approximation of softmax and a tenth-order Taylor series approximation is sufficient to achieve similar results; furthermore, the type of norm used in the denominator does not appear to be important. The recurrent perspective offers insights for designing more efficient and performant attention mechanisms by understanding the contribution of each component. |
| Multi-Modal | TARS: MinMax Token-Adaptive Preference Strategy for Hallucination
  Reduction in MLLMs (Read more on [arXiv](https://arxiv.org/abs/2507.21584) or [HuggingFace](https://huggingface.co/papers/2507.21584))| Jiasheng Tang, Chang Liu, Zhiming Luo, Keda Tao, Kejia Zhang | The paper introduces TARS, a token-adaptive preference strategy to reduce hallucinations in Multimodal Large Language Models (MLLMs). TARS addresses behavioral misalignment and lack of adaptability by reformulating direct preference optimization (DPO) as a min-max optimization problem. The methodology involves maximizing token-level distributional shifts under semantic constraints while minimizing expected preference loss under these perturbations.  Experiments show TARS reduces hallucination rates from 26.4% to 13.2% on the LLaVA-v1.5 model with 4.8k preference samples. TARS provides a lightweight, generalizable approach to enhance preference learning, improve causal grounding, and reduce hallucinations in MLLMs. |
| Computer Vision | Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for
  Culturally Diverse Art Style Classification (Read more on [arXiv](https://arxiv.org/abs/2507.23436) or [HuggingFace](https://huggingface.co/papers/2507.23436))| Abdelmalik Taleb-Ahmed, Cosimo Distante, Salah Eddine Bekhouche, Abdellah Zakaria Sellam | This paper introduces a novel self-supervised framework for culturally diverse art style classification. The primary objective is to enhance style feature extraction by addressing limitations in modeling non-linear feature interactions within dual-teacher knowledge distillation frameworks. The proposed methodology replaces traditional MLP projection heads with Kolmogorov-Arnold Networks (KANs), leveraging spline-based activations to model complex style-feature correlations. Experiments on WikiArt and Pandora18k datasets demonstrate that the KAN-based approach outperforms baseline methods, achieving up to a 1.26% improvement in Top-1 accuracy on Pandora18k using a ConvNeXt-Base architecture. The research implies that KANs can effectively disentangle complex style manifolds, leading to improved feature quality and classification performance for AI practitioners. |
| Natural Language Processing | Enhanced Arabic Text Retrieval with Attentive Relevance Scoring (Read more on [arXiv](https://arxiv.org/abs/2507.23404) or [HuggingFace](https://huggingface.co/papers/2507.23404))| Abdenour Hadid, Fadi Dornaika, Yazid Bounab, Azeddine Benlamoudi, Salah Eddine Bekhouche | The paper introduces an enhanced dense retrieval framework for Arabic text using Attentive Relevance Scoring (ARS). The research aims to improve Arabic text retrieval by modeling semantic relevance between questions and passages, addressing the challenges posed by Arabic's complex morphology. The proposed ARS module replaces standard vector similarity measures with an adaptive scoring function, integrated with pre-trained Arabic language models. Experiments on the ArabicaQA dataset show that the approach achieves a Top-1 accuracy of 37.01%, outperforming existing methods such as AraDPR. The enhanced retrieval capabilities provide AI practitioners with improved question-answering systems and digital libraries for Arabic-speaking users. |
| Computer Vision | NeRF Is a Valuable Assistant for 3D Gaussian Splatting (Read more on [arXiv](https://arxiv.org/abs/2507.23374) or [HuggingFace](https://huggingface.co/papers/2507.23374))| ZeSheng Wang, Yufeng Wang, Takeo Igarashi, I-Chao Shen, Shuangkang Fang | The paper introduces NeRF-GS, a novel framework for jointly optimizing Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). The primary objective is to leverage NeRF's continuous spatial representation to address limitations of 3DGS, such as initialization sensitivity and weak inter-Gaussian correlations. The method involves progressively aligning 3DGS spatial features with NeRF and optimizing residual vectors for both implicit features and Gaussian positions. Experimental results on benchmark datasets show that NeRF-GS surpasses existing methods, achieving state-of-the-art performance, for example, outperforming vanilla 3DGS by 1.8dB in PSNR. The approach offers AI practitioners a new hybrid method for efficient 3D scene representation by combining the strengths of NeRF and 3DGS. |
| Multi-Modal | AgroBench: Vision-Language Model Benchmark in Agriculture (Read more on [arXiv](https://arxiv.org/abs/2507.20519) or [HuggingFace](https://huggingface.co/papers/2507.20519))| Yoshitaka Ushiku, Masaki Onishi, Hirokatsu Kataoka, Nakamasa Inoue, Risa Shinoda | The paper introduces AgroBench, a vision-language benchmark for evaluating AI models in agriculture. It aims to assess the capabilities of vision-language models (VLMs) across seven agricultural tasks, using expert-annotated data. The methodology involves evaluating VLMs on 4,342 question-answer pairs covering 203 crop categories and 682 disease categories. Results show that VLMs achieve varying performance, with some performing near random on weed identification tasks. The benchmark enables detailed error analysis and future directions for VLM development in agriculture. |
| Machine Learning | Flow Equivariant Recurrent Neural Networks (Read more on [arXiv](https://arxiv.org/abs/2507.14793) or [HuggingFace](https://huggingface.co/papers/2507.14793))| T. Anderson Keller | This paper introduces flow equivariant recurrent neural networks (FERNNs) to capture continuous time-parameterized symmetries in sequence models. The research investigates how to build RNNs that are equivariant to transformations generated by one-parameter Lie subgroups (flows). The key methodology involves lifting the hidden state to a space indexed by generating vector fields and sharing weights across these fields. Empirically, FERNNs demonstrate improved length and velocity generalization, achieving, for example, a test accuracy of 0.716 on the Moving KTH dataset compared to 0.665 for standard G-RNNs. The findings suggest a novel approach to building sequence models that are robust to time-parameterized symmetries, enhancing generalization in dynamic environments. |
| Machine Learning | Efficient Machine Unlearning via Influence Approximation (Read more on [arXiv](https://arxiv.org/abs/2507.23257) or [HuggingFace](https://huggingface.co/papers/2507.23257))| Enhong Chen, Defu Lian, Chenwang Wu, Jiawei Liu | This paper introduces an efficient machine unlearning method via influence approximation. It aims to address the computational overhead of influence-based unlearning, particularly concerning Hessian matrix computations. The proposed Influence Approximation Unlearning (IAU) algorithm leverages incremental learning principles, integrating incremental approximation, gradient correction, and gradient restriction. Empirical evaluations demonstrate that IAU achieves a superior balance among removal guarantee, unlearning efficiency, and comparable model utility, outperforming state-of-the-art methods, achieving a top ranking in LeNet5 on CIFAR10 and ResNet18 on SVHN for removal guarantee and unlearning efficiency. This approach offers a more scalable and practical solution for privacy-aware machine learning systems. |
