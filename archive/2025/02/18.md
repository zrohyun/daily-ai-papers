

## Papers for 2025-02-18

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Reinforcement Learning | Learning Getting-Up Policies for Real-World Humanoid Robots (Read more on [arXiv](https://arxiv.org/abs/2502.12152) or [HuggingFace](https://huggingface.co/papers/2502.12152))| Saurabh Gupta, Zixuan Chen, Xialin He, RunpeiDong | This paper introduces HUMANUP, a reinforcement learning framework for training humanoid robots to get up from various lying positions on diverse terrains. The main research objective is to develop controllers that enable humanoid robots to recover from falls in real-world scenarios, addressing the limitations of hand-designed controllers. The key methodology is a two-stage training approach: Stage I discovers a getting-up trajectory with minimal constraints, and Stage II refines the motion into a deployable policy robust to variations in initial configuration and terrains, using a curriculum that progresses in complexity. In real-world experiments, HUMANUP achieved a 78.3% success rate in getting a Unitree G1 robot up from supine poses across various challenging surfaces. The framework offers a practical solution for enhancing the reliability of humanoid robots by enabling autonomous fall recovery, crucial for real-world deployment. |
| Natural Language Processing | Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention (Read more on [arXiv](https://arxiv.org/abs/2502.11089) or [HuggingFace](https://huggingface.co/papers/2502.11089))| Liang Zhao, Junyu Luo, Damai Dai, Huazuo Gao, Jingyang Yuan | This paper introduces NSA, a natively trainable sparse attention mechanism designed for efficient long-context modeling in language models. The research objective is to improve the efficiency of attention mechanisms while maintaining model capabilities, addressing the high computational cost of standard attention. NSA employs a dynamic hierarchical sparse strategy, combining coarse-grained token compression with fine-grained token selection and optimized for modern hardware.  Experiments show that NSA maintains or exceeds Full Attention models across various benchmarks, achieving up to 9.0x forward and 6.0x backward speedup on 64k-length sequences during training.  AI practitioners can utilize NSA to train and deploy more efficient and capable long-context language models. |
| Natural Language Processing | ReLearn: Unlearning via Learning for Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2502.11190) or [HuggingFace](https://huggingface.co/papers/2502.11190))| Sendong Zhao, Liming Yang, Ningyuan Zhao, Haoming Xu, Ningyu | This paper introduces ReLearn, a novel unlearning framework for large language models (LLMs) that leverages data augmentation and positive optimization to remove unauthorized knowledge. The research objective is to address the limitations of existing unlearning methods, which often degrade language generation capabilities by indiscriminately suppressing target token probabilities. ReLearn employs a data augmentation and fine-tuning pipeline, along with a comprehensive evaluation framework that includes Knowledge Forgetting Rate (KFR), Knowledge Retention Rate (KRR), and Linguistic Score (LS). Experiments show that ReLearn achieves a KFR of 0.85 on both KnowUnDo and TOFU datasets while maintaining high KRR, outperforming reverse optimization methods.  AI practitioners can use ReLearn for effective targeted forgetting while preserving model performance and linguistic coherence, especially concerning privacy and copyright regulations. |
| Natural Language Processing | SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering? (Read more on [arXiv](https://arxiv.org/abs/2502.12115) or [HuggingFace](https://huggingface.co/papers/2502.12115))| Johannes Heidecke, Tejal Patwardhan, Michele Wang, Samuel Miserendino | This paper introduces SWE-Lancer, a benchmark for evaluating large language models (LLMs) on real-world freelance software engineering tasks. The main research question is whether frontier LLMs can successfully complete and earn money from a set of freelance software engineering jobs sourced from Upwork. The key methodology involves evaluating LLMs on over 1,400 tasks, including individual contributor tasks graded with end-to-end tests and managerial tasks assessed against original hiring decisions. The best performing model, Claude 3.5 Sonnet, achieved 26.2% on individual contributor tasks and 44.9% on SWE management tasks on the diamond set, earning $208,050 out of a possible $500,800. The results suggest that while LLMs show promise in software engineering, further advancements are needed to achieve higher reliability for real-world deployment, and this benchmark can aid in mapping AI capabilities to economic impacts. |
| Multi-Modal | HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation (Read more on [arXiv](https://arxiv.org/abs/2502.12148) or [HuggingFace](https://huggingface.co/papers/2502.12148))| Minghao Xu, Chenming Shang, Ye Tian, Ling Yang, comin | HermesFlow is a novel framework designed to bridge the capability gap between multimodal understanding and generation in Multimodal Large Language Models (MLLMs). The research uncovers and addresses the phenomenon that MLLMs often exhibit significantly stronger understanding capabilities than generative ones. The proposed methodology, HermesFlow, leverages homologous data to create paired preference data for both understanding and generation, employing Pair-DPO and self-play iterative optimization for alignment. Experiments demonstrate that HermesFlow outperforms prior methods, notably narrowing the understanding-generation gap; for instance it improves Generation Score from 0.433 to 0.497 compared with the baseline Show-o, reducing the gap from 0.087 to 0.036. This research provides a general alignment framework for next-generation multimodal foundation models, enabling more balanced capabilities. |
| Multi-Modal | I Think, Therefore I Diffuse: Enabling Multimodal In-Context Reasoning in Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2502.10458) or [HuggingFace](https://huggingface.co/papers/2502.10458))| Runtao Liu, Hanrong Ye, Guocheng Qian, Kuan-Chieh Wang, Mifucius | This paper introduces ThinkDiff, a novel alignment paradigm that enhances text-to-image diffusion models with multimodal in-context understanding and reasoning capabilities. The research objective is to equip diffusion models with the reasoning capabilities of vision-language models (VLMs). ThinkDiff leverages vision-language training as a proxy task, aligning VLMs with the decoder of an encoder-decoder large language model (LLM), which shares an input space with diffusion decoders. Experiments demonstrate that ThinkDiff significantly improves accuracy from 19.2% to 46.3% on the CoBSAT benchmark for multimodal in-context reasoning generation, with only 5 hours of training. This suggests that AI practitioners can achieve significant reasoning improvements in diffusion models, using relatively small training time and cost by utilizing this vision-language-based methodology, removing the need for dedicated reasoning datasets. |
| Natural Language Processing | How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training (Read more on [arXiv](https://arxiv.org/abs/2502.11196) or [HuggingFace](https://huggingface.co/papers/2502.11196))| Jiacheng Sun, Hui Jin, Yunzhi Yao, Yixin Ou, Ningyu | This paper investigates how Large Language Models (LLMs) acquire and integrate new knowledge during continual pre-training from a knowledge circuit perspective. The main research question is how LLMs structurally embed acquired knowledge into their neural computations during continual pre-training. The authors analyze knowledge circuit evolution by identifying computational subgraphs that facilitate knowledge storage and processing across multiple training checkpoints. Key findings include that relevant knowledge integrates more efficiently than entirely new knowledge, knowledge circuits exhibit distinct phase shifts with topology changes, and that the Hit@10 metric for the knowledge circuits approached its upper bound during training. The main implication is that understanding knowledge circuit evolution can lead to improved continual pre-training strategies and better model performance. |
| Machine Learning | SURGE: On the Potential of Large Language Models as General-Purpose Surrogate Code Executors (Read more on [arXiv](https://arxiv.org/abs/2502.11167) or [HuggingFace](https://huggingface.co/papers/2502.11167))| Siqiao Huang, zcliang22, Bohan22 | This paper introduces SURGE, a benchmark for evaluating large language models (LLMs) as general-purpose surrogate code executors. The main research question is whether LLMs can predict the output and behavior of a program without actually running it. The authors evaluate various open-source and proprietary LLMs on SURGE, a benchmark with eight aspects of code execution, and conduct a scaling study. The best model (Claude-3.5-Sonnet) achieved an average accuracy of 39.66% across all tasks in a few-shot Chain-of-Thought setting, indicating that while LLMs show some capability, there are significant limitations. The study implies that while promising, LLMs still require significant improvement in becoming reliable, general purpose code execution surrogates and proposes prompt strategies to mitigate potential errors.  |
| Computer Vision | Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising Trajectory Sharpening (Read more on [arXiv](https://arxiv.org/abs/2502.12146) or [HuggingFace](https://huggingface.co/papers/2502.12146))| Mengdi Wang, Yunhai Tong, Ling Yang, Ye Tian, comin | This paper introduces Diffusion-Sharpening, a novel fine-tuning approach for diffusion models that optimizes sampling trajectories to improve alignment with user preferences. The research objective is to address limitations in existing fine-tuning methods that focus on single timesteps, neglecting trajectory-level optimization, and reduce high inference cost in sampling trajectory optimization method. The methodology employs a path integral framework during training to select optimal trajectories using reward feedback, and it has two variants: SFT-Diffusion-Sharpening and RLHF-Diffusion-Sharpening.  Primary results are presented in Table 1. Diffusion-Sharpening models outperforming baselines like standard fine tuning, diffusion-DPO and Free Guide, with the RLHF variant reaching a CLIP score of 0.338. For AI practitioners, this approach offers a more efficient and scalable solution for fine-tuning diffusion models, leading to superior performance across diverse metrics. |
| Natural Language Processing | SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL (Read more on [arXiv](https://arxiv.org/abs/2502.11438) or [HuggingFace](https://huggingface.co/papers/2502.11438))| Hwanhee Lee, Byeongjeong Kim, Ingeol Baek, Jimin Lee | This paper introduces SAFE-SQL, a novel framework for Text-to-SQL that improves SQL generation by creating and filtering self-augmented examples using large language models (LLMs). The main research objective is to overcome the limitations of existing methods that struggle in real-world scenarios where similar training examples are unavailable. SAFE-SQL employs a multi-step process involving schema linking, example generation, threshold-based example selection using embedding similarity, keyword, structural alignment, and reasoning path validity, then proceeds to final SQL inference. The proposed method achieves 87.9% execution accuracy on the Spider development set, significantly outperforming zero-shot and few-shot frameworks, especially on extra hard and unseen scenarios. The implication is that SAFE-SQL offers a robust and accurate approach, reducing reliance on predefined training sets and enhancing generalizability for Text-to-SQL tasks. |
| Natural Language Processing | CRANE: Reasoning with constrained LLM generation (Read more on [arXiv](https://arxiv.org/abs/2502.09061) or [HuggingFace](https://huggingface.co/papers/2502.09061))| Gagandeep Singh, Sasa Misailovic, Shubham Ugare, Tarun Suresh, Debangshu Banerjee | This paper introduces CRANE, a reasoning-augmented constrained decoding algorithm for Large Language Models (LLMs) that balances the correctness of constrained generation with the flexibility of unconstrained generation. The research aims to address the observed loss of reasoning capabilities in LLMs when strictly enforcing formal output constraints and determine how to maintain reasoning while ensuring syntactically correct outputs. CRANE theoretically augments output grammars with additional production rules and practically alternates between unconstrained generation for reasoning and constrained generation for output structure. Experiments on symbolic reasoning benchmarks (GSM-symbolic and FOLIO) show CRANE significantly outperforms state-of-the-art constrained decoding strategies and standard unconstrained decoding, showing up to a 10% points accuracy improvement. AI practitioners can use CRANE to improve the functional accuracy and syntactic correctness of LLM outputs in tasks requiring both reasoning and adherence to formal grammars. |
| Computer Vision | Intuitive physics understanding emerges from self-supervised pretraining on natural videos (Read more on [arXiv](https://arxiv.org/abs/2502.11831) or [HuggingFace](https://huggingface.co/papers/2502.11831))| Laurent Najman, Adrien Bardes, Mahmoud Assran, Nicolas Ballas, Quentin Garrido | This paper investigates the emergence of intuitive physics understanding in deep neural networks trained to predict masked regions in natural videos using a self-supervised approach. The main research question is whether general-purpose video prediction models can acquire an understanding of intuitive physics concepts, such as object permanence and shape consistency, without explicit programming or task-specific training. The key methodology involves training a Joint Embedding Predictive Architecture (V-JEPA) to predict masked video regions in a learned representation space, and then evaluating its understanding of intuitive physics using the violation-of-expectation paradigm.  A V-JEPA model trained on natural videos achieves 98% zero-shot accuracy on the IntPhys benchmark and 62% on the InfLevel benchmark, significantly outperforming pixel-space prediction models and large language models. The main implication is that jointly learning an abstract representation space and predicting missing parts of sensory input is sufficient for AI models to develop an understanding of intuitive physics, challenging the need for hard-wired core knowledge. |
| Natural Language Processing | Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM's Nest (Read more on [arXiv](https://arxiv.org/abs/2502.11275) or [HuggingFace](https://huggingface.co/papers/2502.11275))| Jingbo Shang, Feng Yao, Zilong Wang, Letian Peng | This paper introduces Cuckoo, a novel information extraction (IE) model that leverages the pre-training and post-training data of large language models (LLMs). The main objective is to develop a scalable and versatile IE model that can benefit from the massive data used to train LLMs, overcoming the limitations of traditional IE pre-training data scarcity. The key methodology is reframing next-token prediction into next-tokens extraction (NTE), using BIO tags to convert LLM training data into IE training data, and adapting prompts to guide extraction for various IE tasks.  Cuckoo, pre-trained on 102.6M instances from C4 and TuluV3, achieved an average F1 score of 66.34 on named entity recognition and 70.63 on relation extraction in few shot settings, outperforming existing pre-trained IE models.  This suggests that AI practitioners can leverage LLM training resources to develop high-performing and adaptable IE systems without extensive manual annotation. |
| Natural Language Processing | Dyve: Thinking Fast and Slow for Dynamic Process Verification (Read more on [arXiv](https://arxiv.org/abs/2502.11157) or [HuggingFace](https://huggingface.co/papers/2502.11157))| Qiang Xu, Xiangyu Wen, Zhijian Xu, Zeju Li, Jianyuan1 | Dyve is a dynamic process verifier for enhancing reasoning error detection in large language models by integrating fast and slow thinking, inspired by Kahneman's Systems Theory. The main objective is to improve the reliability of process verification in complex reasoning tasks, specifically within mathematical problem-solving. The methodology employs an adaptive mechanism combining immediate token-level confirmation (System 1) and comprehensive analysis (System 2) using step-wise consensus-filtered process supervision, which includes Monte Carlo estimation, LLM-as-a-Judge, and specialized reasoning models. Experimental results on ProcessBench show that Dyve achieves an F1 score of 68.5 on GSM8K, significantly outperforming existing process-based verifiers. The main implication is that AI practitioners can leverage Dyve's dual-system approach for more accurate and efficient process error detection, leading to improved performance and robustness in reasoning systems. |
| Multi-Modal | PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning (Read more on [arXiv](https://arxiv.org/abs/2502.12054) or [HuggingFace](https://huggingface.co/papers/2502.12054))| Jiaxing Huang, Yanrui Wu, Yuxuan Dong, Xinyu Zhang, ChengyouJia | This paper introduces PhysReason, a comprehensive benchmark for evaluating physics-based reasoning capabilities in large language models (LLMs). The main objective is to assess LLMs' ability to solve problems requiring integration of physics theorems, constraints, and multi-step reasoning, going beyond current evaluations that overlook this complex task. The benchmark comprises 1,200 problems with stratified difficulty levels, multi-modal inputs (text and diagrams), and detailed step-by-step solutions, scored using a novel Physics Solution Auto Scoring Framework (PSAS). Top-performing models like Deepseek-R1, Gemini-2.0-Flash-Thinking, and 03-mini-high achieved less than 60% on answer-level evaluation, with performance dropping significantly from knowledge-based questions (75.11%) to hard problems (31.95%). This benchmark highlights current LLM limitations in complex physics-based reasoning and provides a robust evaluation framework, guiding future improvements for AI practitioners working on real-world applications that need such skills. |
| Natural Language Processing | System Message Generation for User Preferences using Open-Source Models (Read more on [arXiv](https://arxiv.org/abs/2502.11330) or [HuggingFace](https://huggingface.co/papers/2502.11330))| Teakgyu Hong, Dawoon Jung, Minsoo Khang, Jungho Cho, Minbyul Jeong | This paper introduces SYSGEN, a pipeline for generating system messages for large language models (LLMs) to improve alignment with user preferences. The main objective is to address the scarcity and license constraints of publicly available data with system messages by automatically generating diverse, well-aligned system messages using open-source models. The methodology involves generating phrase-level system messages based on eight key functionalities, filtering mis-specified tags, verifying functionalities with an LLM-as-a-judge approach, and generating new assistant responses aligned with the refined system messages. Training on SYSGEN data demonstrated substantial improvements, such as a 0.9 absolute improvement on the Multifacet benchmark for the LLaMA-3.1-8B-instruct model and knowledge distillation leading 0.18, 0.57 absolute improvements for Gemma-2-9b-it, and Solar-10.7B-instruct models, respectively. This work enables AI practitioners to improve model response alignment with user instructions and system messages using open-source resources, minimizing performance degradation on unseen benchmarks. |
| Multi-Modal | video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model (Read more on [arXiv](https://arxiv.org/abs/2502.11775) or [HuggingFace](https://huggingface.co/papers/2502.11775))| Yixuan Li, Changli Tang, Jimin Zhuang, Yudong Yang, Guangzhi Sun | This paper introduces video-SALMONN-01, an open-source reasoning-enhanced audio-visual large language model (LLM) designed for general video understanding tasks. The research objective is to enhance the reasoning abilities of audio-visual LLMs in general video understanding, moving beyond limitations of prior work focused on mathematical problems and visual graphical inputs. The key methodology includes creating a reasoning-intensive dataset with step-by-step solutions, proposing process direct preference optimization (pDPO) for step-level reward modeling, and introducing RivaBench, a new reasoning-intensive video understanding benchmark. video-SALMONN-01 achieves 3-8% accuracy improvements over the LLaVA-OneVision baseline across different video reasoning benchmarks, and pDPO achieves 6-8% improvements compared to the supervised fine-tuning model on RivaBench. The main implication is that AI practitioners can leverage video-SALMONN-01 and its associated methods to develop more capable and interpretable video understanding systems with improved reasoning abilities. |
| Natural Language Processing | Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarsity (Read more on [arXiv](https://arxiv.org/abs/2502.11901) or [HuggingFace](https://huggingface.co/papers/2502.11901))| Tianran Sun, Justin Wang, Dylan Zhang | This paper introduces PoPilot, a specialized language model for proof-oriented programming in F*, designed to address data scarcity issues. The main objective is to improve the performance of large language models (LLMs) on project-level proof generation and repair tasks within the F* language. The key methodology involves a three-pronged approach: enhancing general programming capabilities with diverse code data, learning basic proof-oriented programming via synthetic tasks, and synthetic augmentation for proof synthesis and repair using existing repositories and novel provable properties. The primary result is that the fine-tuned 14B parameter model, PoPilot, exceeds the performance of models that outperform GPT-4o in project-level proof-oriented programming by a 64% relative margin. AI practitioners can leverage this approach to improve the performance of code-generating LLMs in low-resource and formally-verifiable domains. |
| Computer Vision | MagicArticulate: Make Your 3D Models Articulation-Ready (Read more on [arXiv](https://arxiv.org/abs/2502.12135) or [HuggingFace](https://huggingface.co/papers/2502.12135))| Yiwen Chen, Fan Yang, Xiu Li, Jianfeng Zhang, chaoyue7 | This paper presents MagicArticulate, a framework for automatically converting static 3D models into animation-ready assets with skeletons and skinning weights. The research objective is to address the time-consuming manual annotation process in 3D animation and the lack of large-scale benchmarks. The key methodology involves a two-stage approach: an auto-regressive transformer for skeleton generation, and a functional diffusion process for skinning weight prediction, incorporating volumetric geodesic distance priors. Experiments demonstrate superior performance over existing methods; for example, on Articulation-XL the method achieves CD-J2J, CD-J2B, and CD-B2B of 2.586, 1.959, and 1.661 respectively. The framework and the new large-scale dataset (Articulation-XL) can accelerate the creation of articulated 3D content for various applications. |
| Natural Language Processing | Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems (Read more on [arXiv](https://arxiv.org/abs/2502.11098) or [HuggingFace](https://huggingface.co/papers/2502.11098))| Shingo Takamatsu, Briti Gangopadhyay, Wei-Yao Wang, Sota Moriyama, Zhao Wang | This paper proposes TalkHier, a collaborative framework for Large Language Model (LLM) Multi-Agent Systems. The main objective is to address challenges in managing communication and refinement when agents collaborate on complex tasks. TalkHier introduces a structured communication protocol for context-rich exchanges and a hierarchical refinement system. The system outperforms various baselines, including inference scaling models and open-source multi-agent models, achieving an average accuracy of 88.38% on five sub-tasks of MMLU. The main implication is that TalkHier's structured communication and hierarchical refinement approach can significantly improve the performance and efficiency of LLM-based multi-agent systems. |
| Machine Learning | One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs (Read more on [arXiv](https://arxiv.org/abs/2502.10454) or [HuggingFace](https://huggingface.co/papers/2502.10454))| Xinnian Liang, Zhikun Xu, Haojing Huang, Jiayi Kuang, Yinghui Li | This paper introduces COUNTERMATH, a benchmark for evaluating counterexample-driven conceptual reasoning in mathematical Large Language Models (LLMs). The research objective is to assess and enhance LLMs' ability to understand nuanced mathematical concepts through counterexample-based proofs, moving beyond typical drill-based learning.  The methodology involves creating a dataset of 1,216 university-level statement-rationale pairs and developing a data engineering framework for automatically generating training data.  Evaluations show that current state-of-the-art LLMs, like Qwen-2.5-Math-72B-Instruct, achieve a relatively low F1 score of 41.8, indicating significant room for improvement in higher-level mathematical reasoning, while a fine-tuned model reaches 41.1 F1 with hint prompts. This work suggests that focusing on counterexample-driven reasoning is crucial for improving the overall mathematical capabilities of LLMs and provides a valuable resource for future research in this area. |
| Natural Language Processing | Better Embeddings with Coupled Adam (Read more on [arXiv](https://arxiv.org/abs/2502.08441) or [HuggingFace](https://huggingface.co/papers/2502.08441))| Tobias Stollenwerk, flxst | This paper introduces a modification to the Adam optimizer, called Coupled Adam, to improve word embeddings in Large Language Models (LLMs) by addressing the issue of anisotropy. The main research objective is to investigate the role of the Adam optimizer's second moment in causing anisotropic embeddings and propose a solution. The key methodology involves modifying the Adam optimizer to couple the second moments of the embedding update vectors, thereby enforcing a more uniform update scale. Primary results show significant improvements in embedding quality (isotropy often exceeding 0.90) and better upstream/downstream performance on sufficiently large datasets.  AI practitioners can use Coupled Adam to generate higher-quality word embeddings, potentially leading to improved performance in downstream tasks, especially with extensive datasets. |
| Natural Language Processing | Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking (Read more on [arXiv](https://arxiv.org/abs/2502.09083) or [HuggingFace](https://huggingface.co/papers/2502.09083))| Isabelle Augenstein, Irina Shklovski, gretawarren | This paper investigates the requirements of professional fact-checkers for explainable automated fact-checking systems. The central research question explores how automated explanations of fact-checking decisions can address the explanatory needs of fact-checkers and integrate into their workflows. The authors conducted semi-structured interviews with 10 fact-checking professionals from five continents to understand their decision-making processes, use of automated tools, and explanation needs. Key findings reveal that fact-checkers require explanations that trace the model's reasoning, reference specific evidence, highlight uncertainty, and facilitate replicability, but current automated fact-checking tools are often inadequate, for instance one tool evaluated by journalists was accurate in classifying claims for only 59% of instances, while 58% of evidence returned was relevant. The results call for the development of more human-centered fact-checking AI that focuses on transparency, aligns with established fact-checking procedures, and supports, rather than replaces, human expertise. |
| Machine Learning | Towards Data-Efficient Pretraining for Atomic Property Prediction (Read more on [arXiv](https://arxiv.org/abs/2502.11085) or [HuggingFace](https://huggingface.co/papers/2502.11085))| Bernard Ghanem, Yasir Ghunaim, hammh0a | This paper challenges the paradigm of large-scale pretraining in atomic property prediction by demonstrating that strategic data selection can achieve comparable or superior performance with significantly fewer resources. The research question is whether a smaller, strategically-selected dataset can yield results comparable to large-scale pretraining, while reducing computational costs. The key methodology involves introducing the Chemical Similarity Index (CSI) to quantify the alignment between upstream pretraining datasets and downstream tasks, and then pretraining on a smaller dataset chosen based on minimal CSI distance. Primary results show that models pretrained on a task-relevant dataset (ANI-1x) achieved a Mean Absolute Error (MAE) of 5.4 on rMD17, outperforming models pretrained on massive, mixed datasets (JMP-S MAE of 6.7) using only 1/24th of the computational budget. The main implication is that for atomic property prediction, quality and relevance of pretraining data often outweighs quantity, and AI practitioners can use CSI to design more efficient models by using more appropriate data. |
| Natural Language Processing | Large Language Models and Mathematical Reasoning Failures (Read more on [arXiv](https://arxiv.org/abs/2502.11574) or [HuggingFace](https://huggingface.co/papers/2502.11574))| birgermoell, jboye | This research paper investigates the mathematical reasoning capabilities of Large Language Models (LLMs) and identifies common failure modes. The main research objective is to evaluate how well LLMs can solve high-school-level mathematical word problems, going beyond simple answer correctness to analyze the reasoning process. The key methodology involves constructing a new dataset of 50 word problems and manually evaluating the solutions and answers of eight state-of-the-art LLMs, including Mixtral, Llama, and GPT-4o. The primary results show varying performance across models, with the best model (o3-mini) correctly solving 40 out of 50 problems; however, all models exhibited flaws in spatial reasoning, strategic planning, and arithmetic. The main implication is that AI practitioners should not overestimate LLMs' problem-solving proficiency and must carefully evaluate the reasoning process, not just the final answers, when using them for tasks requiring mathematical reasoning. |
| Natural Language Processing | Language Complexity Measurement as a Noisy Zero-Shot Proxy for Evaluating LLM Performance (Read more on [arXiv](https://arxiv.org/abs/2502.11578) or [HuggingFace](https://huggingface.co/papers/2502.11578))| jboye, birgermoell | This paper investigates using language complexity metrics as a zero-shot proxy for evaluating the performance of Large Language Models (LLMs). The main research objective is to examine the performance of state-of-the-art LLMs on two analytical tasks related to language complexity: computing the LIX readability metric and performing dependency parsing to calculate the Average Dependency Distance (ADD). The methodology involves evaluating six LLMs on Swedish essays, comparing their LIX and dependency parsing outputs against established ground truths, and correlating these with MMLU benchmark scores. A strong negative correlation (-0.875, p=0.026) was found between LIX error and MMLU performance, with the 01-mini model achieving the best accuracy. The results suggest that language complexity measurement can serve as a practical, noisy proxy for assessing general LLM capabilities, offering a quick evaluation method without needing extensive datasets. |
