

## Papers for 2025-02-24

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | SurveyX: Academic Survey Automation via Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2502.14776) or [HuggingFace](https://huggingface.co/papers/2502.14776))| UglyToilet, Ki-Seki, siminniu, fan2goa1, HaruTeru | This paper introduces SurveyX, a system for automated academic survey generation using Large Language Models (LLMs). The main objective is to address the challenges of automated survey generation, such as limited context windows, lack of in-depth content, and absence of systematic evaluation. SurveyX employs a two-phase approach: Preparation (retrieving and pre-processing references) and Generation (creating the survey outline and content), enhanced by online reference retrieval and a novel pre-processing method called AttributeTree. Experimental results show SurveyX outperforms existing systems, achieving a content quality improvement of 0.259 and a citation quality enhancement of 1.76, approaching human expert performance. The main implication is that SurveyX can serve as an efficient tool for automated survey generation, assisting researchers in literature synthesis. |
| Computer Vision | MaskGWM: A Generalizable Driving World Model with Video Mask Reconstruction (Read more on [arXiv](https://arxiv.org/abs/2502.11663) or [HuggingFace](https://huggingface.co/papers/2502.11663))| Rui Chen, Yuxin Guo, Jingcheng Ni, wzhgba, lyclyc52 | This paper introduces MaskGWM, a generalizable driving world model for autonomous driving that combines diffusion-based video prediction with masked reconstruction for improved fidelity and generalization. The research aims to address the limitations of existing driving world models in long-horizon prediction and zero-shot generalization. The key methodology involves a Diffusion Transformer (DiT) architecture trained with an additional mask construction task, using diffusion-related mask tokens and a row-wise mask for spatial-temporal modeling. The proposed method achieves a Frechet Video Distance (FVD) of 59.4 and Frechet Inception Distance (FID) of 4.0 on the nuScenes dataset in a zero-shot setting, outperforming prior methods. The results indicate improved video generation quality for world modeling tasks and suggest that the proposed method is effective for long-term and generalizable predictions of driving scenarios. |
| Multi-Modal | Mol-LLaMA: Towards General Understanding of Molecules in Large Molecular Language Model (Read more on [arXiv](https://arxiv.org/abs/2502.13449) or [HuggingFace](https://huggingface.co/papers/2502.13449))| Sung Ju Hwang, Wonbin Lee, DongkiKim | Mol-LLaMA is a large molecular language model designed for general understanding of molecules across structural, chemical, and biological aspects. The main research objective is to create a model that can serve as a general-purpose assistant for molecular analysis, overcoming the limitations of existing models that struggle with fundamental molecular characteristics. The key methodology involves multi-modal instruction tuning using a newly designed dataset encompassing core levels of molecular understanding and a blending module that integrates information from 2D and 3D molecular encoders.  Experimental results demonstrate that Mol-LLaMA outperforms baselines including LLMs and other molecular LLMs; it shows superior performance on a molecular property prediction task achieving 79.61 accuracy on the PAMPA task in the CoT setting. The implication for AI practitioners is that such detailed molecular understanding and reasoning can help to solve scientific problems based on language models. |
| Natural Language Processing | LLM-Microscope: Uncovering the Hidden Role of Punctuation in Context Memory of Transformers (Read more on [arXiv](https://arxiv.org/abs/2502.15007) or [HuggingFace](https://huggingface.co/papers/2502.15007))| Polina Druzhinina, Elizaveta Goncharova, Temurbek Rahmatullaev, Matvey Mikhalchuk, Anton Razzhigaev | The paper introduces LLM-Microscope, a framework for analyzing how Large Language Models (LLMs) encode and store contextual information, with a focus on the role of seemingly minor tokens like punctuation. The research investigates how LLMs utilize contextual information and how 'filler' tokens contribute to maintaining context. The methodology includes assessing token-level nonlinearity, measuring contextual memory via prefix reconstruction, and analyzing intermediate layer contributions. A key finding is that removing punctuation and stopwords degrades performance on the MMLU benchmark (e.g., Llama-3.2-3B drops from 0.398 to 0.342 when removing punctuation). The main implication is that AI practitioners should be aware of the significant role that 'filler' tokens can have for maintaining accuracy in tasks that need domain knowledge or extended context and when applying model interpretability techniques. |
| Computer Vision | PhotoDoodle: Learning Artistic Image Editing from Few-Shot Pairwise Data (Read more on [arXiv](https://arxiv.org/abs/2502.14397) or [HuggingFace](https://huggingface.co/papers/2502.14397))| Xueyin Wang, Hailong Guo, Yuxuan Zhang, Yiren Song, Shijie Huang | PhotoDoodle is a novel image editing framework designed to facilitate artistic photo doodling by enabling the overlay of decorative elements onto photographs, maintaining consistency between pre- and post-edit states. The main objective is to learn an artist's unique editing style from few-shot pairwise data and apply it to new images, addressing challenges like seamless integration, background preservation, and efficient style acquisition. The method employs a two-stage training strategy: first pre-training a general-purpose image editing model (OmniEditor) and then fine-tuning it with EditLoRA using an artist-curated dataset and a positional encoding reuse mechanism. The results show significant improvements over baseline methods; for example, PhotoDoodle achieves a CLIP Score of 0.279, a GPT Score of 63.207, and a CLIPimg score of 0.854 in customized image editing tasks. The implication is that AI practitioners can leverage this framework to develop tools for customized image editing, expanding creative possibilities in artistic image manipulation. |
| Natural Language Processing | SIFT: Grounding LLM Reasoning in Contexts via Stickers (Read more on [arXiv](https://arxiv.org/abs/2502.14922) or [HuggingFace](https://huggingface.co/papers/2502.14922))| Zhijie Deng, Boxiu Li, Xuyao Huang, Zihao Zeng | This paper introduces Stick to the Facts (SIFT), a post-training approach to improve the reasoning capabilities of large language models (LLMs) by grounding them in the context using model-generated summaries called Stickers. The research question is whether explicitly emphasizing key information within the input context can mitigate factual drift, where LLMs misinterpret or overlook critical details during reasoning. SIFT leverages Stickers to summarize key facts, generates predictions from both the original query and the query augmented with the Sticker, and refines the Sticker through bidirectional optimization if predictions differ. SIFT improves the pass@1 accuracy of DeepSeek-R1 on AIME2024 from 78.33% to 85.67%, establishing a new state-of-the-art. AI practitioners can use SIFT to improve the accuracy and reliability of LLM reasoning without additional training or data, particularly in contexts where factual accuracy is paramount. |
| Multi-Modal | VLM$^2$-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues (Read more on [arXiv](https://arxiv.org/abs/2502.12084) or [HuggingFace](https://huggingface.co/papers/2502.12084))| Yi R., Paul Pu Liang, Renjie Pi, RainJamesY, Sterzhang | The paper introduces VLM$^2$-Bench, a benchmark to assess how well Vision-Language Models (VLMs) link explicit matching visual cues. The research aims to evaluate the ability of VLMs to visually link matching cues across images/frames, crucial for coherent multimodal reasoning. The benchmark consists of 9 subtasks and over 3,000 test cases, evaluating different language-side and vision-side prompting methods on VLMs. Results show even GPT-4o underperforms significantly compared to humans, lagging by 34.80%. The findings imply a need for improved visual capabilities and better integration of language-based reasoning in vision-centric tasks for VLMs to achieve more effective multimodal reasoning. |
| Natural Language Processing | LightThinker: Thinking Step-by-Step Compression (Read more on [arXiv](https://arxiv.org/abs/2502.15589) or [HuggingFace](https://huggingface.co/papers/2502.15589))| Mengshu Sun, Yuqi Zhu, Jintian Zhang, Ningyu, GoooDte | LightThinker is a novel method designed to improve the efficiency of Large Language Models (LLMs) in complex reasoning tasks by dynamically compressing intermediate thoughts during generation. The main research objective is to reduce the substantial memory and computational costs associated with generating lengthy tokens in LLMs while maintaining competitive accuracy. LightThinker compresses verbose thought steps into compact representations using gist tokens and discards the original reasoning chains, guided by data reconstruction, hidden state mapping, and specialized attention masks. Experiments on four datasets with the Qwen model show that LightThinker reduces peak token usage by 70% and inference time by 26% compared to the Vanilla model, with only a 1% drop in accuracy. This work offers a new direction for enhancing LLM efficiency in complex reasoning tasks, enabling more practical applications by reducing computational demands. |
| Natural Language Processing | StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction Following (Read more on [arXiv](https://arxiv.org/abs/2502.14494) or [HuggingFace](https://huggingface.co/papers/2502.14494))| Yuan Wu, Yi Chang, Yue Wang, Jinzhe Li, Jinnan Li | This paper introduces StructFlowBench, a new benchmark for evaluating multi-turn instruction-following capabilities in large language models (LLMs). The main objective is to assess LLMs' ability to understand and maintain structural dependencies across dialogue turns, beyond simple constraint satisfaction. The methodology involves defining a structural flow framework with six inter-turn relationships and a dual-constraint evaluation system combining intra-turn and structural constraints. Primary results from evaluating 13 LLMs show that the best model, DeepSeek-v3, achieved a Weighted Constraint Satisfaction Rate (WCSR) of 0.98, but performance varied significantly across different structural constraint types. The main implication is that while some LLMs demonstrate strong performance, there's still room for improvement, especially in handling complex structural relationships like refinement. |
| Multi-Modal | KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding (Read more on [arXiv](https://arxiv.org/abs/2502.14949) or [HuggingFace](https://huggingface.co/papers/2502.14949))| Ghazi Ahmed, Rania Hossam, Abdullah Sohail, mukul54, ahmedheakl | This paper introduces KITAB-Bench, a comprehensive benchmark for evaluating Arabic Optical Character Recognition (OCR) and document understanding systems. The main objective is to address the lack of standardized evaluation frameworks for Arabic OCR, which faces unique challenges due to the script's cursive nature and right-to-left orientation. The benchmark comprises 8,809 samples across 9 major domains and 36 sub-domains, including handwritten text, tables, and charts, and evaluates tasks like layout detection, text recognition, and PDF-to-Markdown conversion.  Results show that modern vision-language models outperform traditional OCR approaches by an average of 60% in Character Error Rate (CER), but still struggle with specific tasks like PDF-to-Markdown conversion, where the best model achieves only 65% accuracy. This benchmark provides a rigorous evaluation framework to drive improvements in Arabic document analysis methods, and the findings highlight performance gaps that need to be addressed to advance Arabic OCR technology to the level of English OCR. |
| Multi-Modal | InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback (Read more on [arXiv](https://arxiv.org/abs/2502.15027) or [HuggingFace](https://huggingface.co/papers/2502.15027))| Mike Zheng Shou, Haiyang Mei, Yifei Tao, Wenqi Pei, Henry Hengyuan Zhao | This paper introduces InterFeedback, a framework and benchmark for evaluating the interactive intelligence of Large Multimodal Models (LMMs) through human feedback. The main research question is how well LMMs can improve their problem-solving abilities by incorporating human feedback. The methodology involves an interactive framework where LMMs attempt to solve multimodal tasks, receive feedback from either simulated or real humans, and then refine their answers. Primary results show that even state-of-the-art LMMs, like OpenAI-01, can correct their results through human feedback less than 50% of the time. This highlights the need for methods that can enhance LMMs' ability to understand and use feedback effectively, which is crucial for developing general-purpose AI assistants. |
| Machine Learning | Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer a Safer Path? (Read more on [arXiv](https://arxiv.org/abs/2502.15657) or [HuggingFace](https://huggingface.co/papers/2502.15657))| Pietro Greiner, Joumana Ghosn, Damiano Fornasiere, Michael Cohen, Yoshua Bengio | This paper explores the potential catastrophic risks associated with uncontrolled superintelligent agents and proposes a safer alternative called Scientist AI, designed for understanding rather than goal-seeking. The main research objective is to develop a non-agentic AI system that is trustworthy and safe by design, minimizing the risks of misuse or loss of human control. The key methodology involves building a Bayesian world model that generates causal theories to explain observations and an inference machine that computes the probability of answers to given questions, explicitly handling uncertainty. The paper does not provide quantitative results, focusing on design, but the implication for AI practitioners is that a shift towards non-agentic AI could improve safety for advanced AI systems. The document mentions an anytime preparedness strategy with short-term safety measures like a guardrail from fine-tuning existing frontier models. |
| Machine Learning | The Relationship Between Reasoning and Performance in Large Language Models -- o3 (mini) Thinks Harder, Not Longer (Read more on [arXiv](https://arxiv.org/abs/2502.15631) or [HuggingFace](https://huggingface.co/papers/2502.15631))| Vincent Ginis, Andres Algaba, Marthe Ballon | This paper investigates the relationship between reasoning chain length and performance in large language models (LLMs), specifically comparing different versions of OpenAI's o-series models. The main research question is whether more capable LLMs achieve higher performance through longer reasoning chains or more efficient reasoning. The authors systematically analyze chain-of-thought length across o1-mini and o3-mini variants on the Omni-MATH benchmark, controlling for question difficulty and domain. Primary results show that o3-mini (m) achieves superior accuracy without requiring longer reasoning chains than o1-mini, and accuracy generally declines with longer reasoning across all models, with a decrease of 3.16%, 1.96%, and 0.81% per 1000 reasoning tokens for o1-mini, o3-mini(m), and o3-mini(h), respectively. The main implication is that constraining the chain-of-thought can be beneficial, especially for weaker reasoning models, and that improvements come from effective, rather than extended, reasoning processes. |
| Machine Learning | ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation (Read more on [arXiv](https://arxiv.org/abs/2502.14637) or [HuggingFace](https://huggingface.co/papers/2502.14637))| Hongteng Xu, EatEatEatEat, AngxiaoYue | This paper introduces ReQFlow, a novel rectified quaternion flow matching method for fast and high-quality protein backbone generation. The main research objective is to address the limitations of existing diffusion and flow-based generative models, specifically their computational inefficiency and tendency to produce proteins with low designability. The key methodology involves representing 3D rotations as unit quaternions and constructing a flow using spherical linear interpolation (SLERP) in an exponential format, trained via quaternion flow (QFlow) matching and rectified for improved inference. ReQFlow achieves a state-of-the-art Fraction score of 0.972 when sampling 500 steps and is significantly faster than existing methods (e.g. 37x faster than RFDiffusion when generating a backbone of 300 residue length). This method enables AI practitioners to generate high-quality protein backbones with greater efficiency and designability, especially for long protein chains. |
| Natural Language Processing | MoBA: Mixture of Block Attention for Long-Context LLMs (Read more on [arXiv](https://arxiv.org/abs/2502.13189) or [HuggingFace](https://huggingface.co/papers/2502.13189))| Tao Jiang, Yulun Du, Jingyuan Liu, Zhejun Jiang, Enzhe Lu | This paper introduces Mixture of Block Attention (MoBA), a novel attention architecture for large language models (LLMs) that improves efficiency and scalability for long-context tasks. The main research question is how to design a robust and adaptable attention architecture that retains the original Transformer framework while allowing the model to determine where to attend without predefined biases. MoBA applies the principles of Mixture of Experts (MoE) to the attention mechanism, partitioning the context into blocks and using a gating mechanism to selectively route query tokens to the most relevant key-value blocks. Experimental results demonstrate that MoBA achieves comparable performance to full attention, with a validation loss difference consistently within a range of 1e-3, and offers a significant speedup ratio (up to 6.5x when prefilling 1M tokens). AI practitioners can leverage MoBA to enhance the efficiency of LLMs for handling longer and more complex inputs, seamlessly transitioning between full and sparse attention without compromising performance. |
| Machine Learning | One-step Diffusion Models with $f$-Divergence Distribution Matching (Read more on [arXiv](https://arxiv.org/abs/2502.15681) or [HuggingFace](https://huggingface.co/papers/2502.15681))| Arash Vahdat, Weili Nie, Yilun Xu | This paper introduces a novel framework, f-distill, for accelerating diffusion models by distilling a multi-step diffusion model into a single-step student generator using f-divergence minimization. The main research objective is to generalize distribution matching in diffusion model distillation beyond the commonly used reverse Kullback-Leibler (KL) divergence, exploring divergences with different trade-offs in mode coverage and training variance. The key methodology involves deriving the gradient of the f-divergence between teacher and student distributions, expressed as a product of score differences and a weighting function determined by their density ratio. Primary results show that using Jensen-Shannon divergence, f-distill achieves a state-of-the-art one-step generation FID score of 1.16 on ImageNet-64 and 7.42 on zero-shot MS-COCO text-to-image generation. The implication for AI practitioners is that different choices of f-divergences during distillation can lead to significant improvement in one-step diffusion model training and sampling, especially when it comes to balancing between sample fidelity and diversity. |
| Natural Language Processing | Think Inside the JSON: Reinforcement Strategy for Strict LLM Schema Adherence (Read more on [arXiv](https://arxiv.org/abs/2502.14905) or [HuggingFace](https://huggingface.co/papers/2502.14905))| Viktoria Rojkova, Ishan Joshi, Bhavik Agarwal | The paper addresses strict schema adherence in large language model (LLM) generation by leveraging LLM reasoning capabilities. It aims to enforce schema consistency in LLM outputs for structured data extraction. The methodology involves training a 1.5B parameter model using reinforcement learning and supervised fine-tuning on synthetic reasoning datasets, including custom reward functions under Group Relative Policy Optimization (GRPO). The model achieves a 62.41% mean match, demonstrating robust performance in enforcing schema consistency with minimal extraneous output. This approach offers a resource-efficient framework for schema-constrained text generation, crucial for applications like bio-manufacturing compliance. |
| Multi-Modal | Evaluating Multimodal Generative AI with Korean Educational Standards (Read more on [arXiv](https://arxiv.org/abs/2502.15422) or [HuggingFace](https://huggingface.co/papers/2502.15422))| Geewook Kim, sangheeeee | This paper introduces KoNET, a new benchmark for evaluating Multimodal Generative AI systems using Korean national educational tests. The main research objective is to assess the performance of AI models across different educational levels and in a less-explored language (Korean) compared to existing English-centric benchmarks. The methodology involves using four Korean exams (KoEGED, KoMGED, KoHGED, and KoCSAT) and evaluating various open-source, open-access, and closed API models by analyzing difficulty, subject diversity, and human error rates.  A key result is that the EXAONE-3.0-7.8B-Instruct model achieved a KoNET score of 45.5, outperforming similar-sized models, and model performance generally decreases with increased curriculum difficulty.  This benchmark can help AI practitioners identify strengths and weaknesses of Multimodal Generative AI Systems for non-English languages and highlights the need for diverse language consideration and comparison with human performance in practical AI applications, particularly education. |
| Multi-Modal | CrossOver: 3D Scene Cross-Modal Alignment (Read more on [arXiv](https://arxiv.org/abs/2502.15011) or [HuggingFace](https://huggingface.co/papers/2502.15011))| Iro Armeni, Daniel Barath, Marc Pollefeys, Ondrej Miksik, sayandsarkar | CrossOver is a novel framework for cross-modal 3D scene understanding via flexible, scene-level modality alignment, supporting tasks like scene retrieval and object localization. The main research objective is to achieve robust 3D scene understanding across different modalities (RGB images, point clouds, CAD models, floorplans, text) even with missing or incomplete data. The key methodology involves using dimensionality-specific encoders, a multi-stage training pipeline, and a modality-agnostic embedding space, trained without explicit object semantics. Evaluations on ScanNet and 3RScan datasets show superior performance, with a scene-level matching recall of 99.31% (R@25) on ScanNet for the I -> R modality pair. CrossOver offers AI practitioners a robust and adaptable solution for integrating and interpreting multi-modal 3D scene data, even under imperfect real-world conditions, by allowing to relax the need of per-object instance paired data. |
| Natural Language Processing | Beyond No: Quantifying AI Over-Refusal and Emotional Attachment Boundaries (Read more on [arXiv](https://arxiv.org/abs/2502.14975) or [HuggingFace](https://huggingface.co/papers/2502.14975))| Grant Rosario, David Noever | This paper presents a benchmark and evaluation framework for assessing emotional boundary handling in Large Language Models (LLMs). The main objective is to quantify and analyze how LLMs respond to user prompts that attempt to establish emotional connections or cross emotional boundaries, specifically focusing on "over-refusal" behavior. The methodology involves a dataset of 1156 prompts across six languages, evaluating LLMs' responses using pattern-matched analysis across seven key patterns, such as direct refusal, apology, and explanation. Results show significant variation in boundary-handling approaches, with Claude-3.5 achieving the highest overall score (8.69/10) and English responses demonstrating a much higher refusal rate (43.20%) than those in other languages. AI practitioners should consider these findings when developing and aligning LLMs to balance appropriate emotional boundaries with user needs for support and connection, paying close attention to multilingual performance. |
| Computer Vision | JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework (Read more on [arXiv](https://arxiv.org/abs/2502.13407) or [HuggingFace](https://huggingface.co/papers/2502.13407))| Jingyu Ma, Yuanxiu Zhou, Long Gao, Ruifei Zhu, circleLZY | This paper introduces JL1-CD, a new benchmark dataset for remote sensing change detection (CD), and proposes a Multi-Teacher Knowledge Distillation (MTKD) framework to improve CD model performance. The research addresses the scarcity of high-resolution, all-inclusive CD datasets and the difficulty of achieving consistent detection results across images with varying change areas. The methodology involves a novel Origin-Partition (O-P) strategy to train models on data partitions based on Change Area Ratio (CAR), and then uses MTKD to train a student model leveraging multiple teacher models specialized in different CAR ranges. Experiments on JL1-CD and SYSU-CD datasets show significant performance gains; for example, the MTKD framework improved TTP model mIoU to 76.85, the new state-of-the-art on the JL1-CD dataset. The main implication is that AI practitioners can use the provided dataset and MTKD framework to develop and apply more robust and generalizable CD models for analyzing dual-temporal remote sensing images. |
| Machine Learning | UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning (Read more on [arXiv](https://arxiv.org/abs/2502.15082) or [HuggingFace](https://huggingface.co/papers/2502.15082))| Mohit Bansal, Elias Stengel-Eskin, vaidehi99 | This paper introduces UPCORE, a method-agnostic data selection framework for mitigating collateral damage during machine unlearning in large language models (LLMs). The research investigates what properties of the data to be forgotten correlate with collateral damage, proposing a way to select a 'core forget set' that balances deletion effectiveness and model utility preservation. UPCORE identifies and prunes outlier data points in the forget set based on hidden state variance, using Isolation Forests to minimize model degradation after unlearning.  Empirically, UPCORE improves Area-Under-the-Curve (AUC) metrics across multiple unlearning methods and achieves a 3-7 AUC point improvement on the Counterfact dataset over baselines, which demonstrates better trade-off between unlearning undesired knowledge and retaining unrelated information. The main implication is that AI practitioners can apply UPCORE to better balance effective unlearning and preservation of the existing capabilities of a model, which is helpful with complying with data removal. |
