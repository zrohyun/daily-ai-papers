

## Papers for 2025-02-20

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Multi-Modal | Qwen2.5-VL Technical Report (Read more on [arXiv](https://arxiv.org/abs/2502.13923) or [HuggingFace](https://huggingface.co/papers/2502.13923))| Keqin Chen, Shuai Bai, xhyandwyy, darkpromise, ayumiymk | Qwen2.5-VL is a state-of-the-art vision-language model that achieves significant advancements in multimodal understanding and interaction. The main research objective is to enhance visual recognition, object localization, document parsing, and long-video comprehension within a single unified model, moving towards more agentic applications. The key methodology involves dynamic resolution processing, absolute time encoding, window attention, and a native dynamic-resolution Vision Transformer (ViT) trained from scratch. The flagship Qwen2.5-VL-72B model matches or surpasses leading models like GPT-4o and Claude 3.5 Sonnet, particularly excelling in document and diagram understanding with a score of 88.6 on MMBench-EN. AI practitioners can leverage Qwen2.5-VL for a wide range of applications requiring complex visual-linguistic understanding, particularly where fine-grained perception and robust generalization are crucial. |
| Reinforcement Learning | RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2502.13144) or [HuggingFace](https://huggingface.co/papers/2502.13144))| Yiang Shi, Bencheng Liao, Bo Jiang, Shaoyu Chen, Hao605 | This paper introduces RAD, a novel 3DGS-based closed-loop Reinforcement Learning (RL) framework for training end-to-end autonomous driving policies. The research objective is to address the limitations of Imitation Learning (IL), such as causal confusion and the open-loop gap, by leveraging RL in a photorealistic environment. The methodology constructs a digital replica of the real world using 3D Gaussian Splatting (3DGS), enabling extensive exploration and incorporating IL as a regularization term. RAD achieves a 3x lower collision rate compared to IL-based methods in closed-loop evaluations, demonstrating improved safety. The main implication is that combining RL with 3DGS environments provides a promising approach for developing more robust and safer autonomous driving policies, particularly in handling out-of-distribution scenarios. |
| Multi-Modal | SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation (Read more on [arXiv](https://arxiv.org/abs/2502.13128) or [HuggingFace](https://huggingface.co/papers/2502.13128))| Pan Zhang, Xiaoyi Dong, Zhixiong Zhang, Shuangrui Ding, Zihan Liu | SongGen is a fully open-source, single-stage auto-regressive transformer designed for controllable text-to-song generation, facilitating fine-grained control over diverse musical attributes. The paper's main research objective is to investigate whether a single-stage model, as opposed to previous multi-stage processes, can achieve effective text-to-song generation. The methodology utilizes a unified auto-regressive transformer that supports mixed and dual-track modes with various token pattern strategies and an automated data preprocessing pipeline. Primary results show that SongGen achieves a CLAP score of 0.35 in mixed pro mode, indicating reasonable alignment between the generated audio and text description. AI practitioners can leverage SongGen as a simplified yet strong baseline for text-to-song generation, reducing pipeline complexity and offering enhanced controllability. |
| Natural Language Processing | MoM: Linear Sequence Modeling with Mixture-of-Memories (Read more on [arXiv](https://arxiv.org/abs/2502.13685) or [HuggingFace](https://huggingface.co/papers/2502.13685))| Yu Cheng, Jiaxi Hu, Disen Lan, Jusen Du, weigao266 | This paper introduces Mixture-of-Memories (MoM), a novel architecture for linear sequence modeling inspired by neuroscience principles of memory management. The research objective is to improve the performance of linear sequence models on recall-intensive tasks by addressing limitations in memory capacity and interference. MoM utilizes multiple independent memory states with a router network directing input tokens, enhancing memory capacity and minimizing interference through selective updates. Experimental results show that MoM significantly outperforms existing linear sequence models on downstream language tasks, particularly on recall-intensive tasks, achieving an average accuracy of 36.04 on recall-intensive tasks in the 1.3B parameter setting. The main implication is that MoM offers a more efficient and effective approach to sequence modeling, particularly for tasks requiring strong recall capabilities, bridging the performance gap with Transformer models. |
| Natural Language Processing | Craw4LLM: Efficient Web Crawling for LLM Pretraining (Read more on [arXiv](https://arxiv.org/abs/2502.13347) or [HuggingFace](https://huggingface.co/papers/2502.13347))| Chenyan Xiong, Zhiyuan Liu, yushi | This paper introduces Craw4LLM, an efficient web crawling method designed to improve the quality of pretraining data for large language models (LLMs). The main research objective is to address the inefficiency of current web crawlers, which often collect large amounts of low-quality data that is subsequently discarded during LLM pretraining. Craw4LLM achieves this by prioritizing webpages based on their predicted influence on LLM pretraining, using a pretraining influence scorer derived from data-filtering pipelines, rather than traditional graph-connectivity metrics. Experiments on a web graph of 900 million pages show that LLMs pretrained on data collected by Craw4LLM reach the same downstream performance as previous crawls with only 21% of the URLs, reducing crawling waste. This approach suggests that AI practitioners can significantly improve data collection efficiency for LLM pretraining by integrating pretraining-specific signals directly into the web crawling process. |
| Natural Language Processing | LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization (Read more on [arXiv](https://arxiv.org/abs/2502.13922) or [HuggingFace](https://huggingface.co/papers/2502.13922))| Lidong Bing, Michael Qizhe Shieh, Xin Li, Guanzheng Chen | This paper introduces LongPO, a novel long-context alignment method that enables Large Language Models (LLMs) to transfer short-context capabilities to long-context scenarios. The research objective is to address the challenges of long-context alignment, including the scarcity of annotated data and the difficulty of balancing short- and long-context performance. LongPO leverages LLMs to learn from self-generated short-to-long preference data and incorporates a short-to-long KL constraint to mitigate performance decline on short contexts. When applied to Mistral-7B-Instruct-v0.2, LongPO improved the model's performance on InfiniteBench by 25.45 points and achieved results comparable to or surpassing those of superior LLMs like GPT-4-128K. This approach offers a more efficient and balanced method for developing long-context LLMs, reducing the need for extensive long-context annotation. |
| Machine Learning | Small Models Struggle to Learn from Strong Reasoners (Read more on [arXiv](https://arxiv.org/abs/2502.12143) or [HuggingFace](https://huggingface.co/papers/2502.12143))| Luyao Niu, Fengqing Jiang, Xiang Yue, Yuetai Li, flydust | This paper investigates the phenomenon of "Small Model Learnability Gap," where small language models (≤3B parameters) struggle to learn from complex reasoning traces generated by larger models. The main research question is why small models do not consistently benefit from long chain-of-thought (CoT) reasoning or distillation from larger models, unlike their larger counterparts. The authors propose "Mix Distillation," a strategy that combines training data of varying complexity (long/short CoT or large/small teacher outputs) to address this. Experiments show that Mix Distillation significantly improves small model reasoning, for example, Qwen2.5-3B-Instruct improved by over 8 points on MATH and AMC using Mix-Long compared to training on long CoT data alone. AI practitioners should adapt reasoning complexity during distillation to the capacity of smaller student models for effective knowledge transfer, rather than directly distilling from the strongest models. |
| Machine Learning | Autellix: An Efficient Serving Engine for LLM Agents as General Programs (Read more on [arXiv](https://arxiv.org/abs/2502.13965) or [HuggingFace](https://huggingface.co/papers/2502.13965))| Tianjun Zhang, Colin Cai, Xiaoxiang Shi, Michael Luo, Chrisyichuan | Autellix is a new LLM inference serving system designed to optimize the end-to-end latency of agentic programs, treating them as first-class citizens. The research objective is to minimize program-level latencies by addressing head-of-line blocking caused by existing LLM serving systems that optimize individual LLM calls, ignoring program-level context. Autellix introduces two scheduling algorithms, PLAS and ATLAS, that prioritize LLM calls based on program-level statistics like cumulative service time and critical path, along with a data locality-aware load balancer. Evaluations show that Autellix improves program throughput by 4-15x compared to state-of-the-art systems like vLLM, across various LLMs and agentic workloads. This implies that AI practitioners should consider program-level context when designing and deploying LLM serving systems for complex agentic applications, significantly improving performance. |
| Natural Language Processing | Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region (Read more on [arXiv](https://arxiv.org/abs/2502.13946) or [HuggingFace](https://huggingface.co/papers/2502.13946))| Wenjie Li, Jian Wang, Qingyu Yin, Chak Tou Leong | This paper investigates why safety-aligned large language models (LLMs) are vulnerable to jailbreak attacks, identifying a phenomenon called template-anchored safety alignment (TASA). The main research objective is to understand how TASA contributes to inference-time vulnerabilities and propose mitigation strategies. The authors conduct experiments analyzing attention weight distributions, perform activation patching to assess causal roles of different regions, and probe harmfulness features in intermediate states. Results show that safety-tuned LLMs rely more on information from the template region for safety decisions; intervening information in the template region increases attack success rate significantly (e.g. achieving comparable or higher ASR than specialized jailbreak methods on several models), and detaching safety mechanism from template position during generation phase reduced attack success rates on LLaMA-3-8B-Instruct model with AmpleGCG attack by 26.5%. This highlights the need for developing safety alignment techniques that reduce reliance on potential shortcuts like the template region. |
| Natural Language Processing | SearchRAG: Can Search Engines Be Helpful for LLM-based Medical Question Answering? (Read more on [arXiv](https://arxiv.org/abs/2502.13233) or [HuggingFace](https://huggingface.co/papers/2502.13233))| Tianming Liu, Quanzheng Li, Canyu Chen, Tianze Yang, YuchengShi | SearchRAG is a novel retrieval-augmented generation framework designed to enhance the performance of Large Language Models (LLMs) in medical question answering. The main research objective is to investigate how real-time search engines can improve LLM-based medical question answering by addressing the limitations of static knowledge bases. The key methodology involves synthetic query generation to create search-engine-friendly queries and uncertainty-based knowledge selection to filter and incorporate the most relevant information. Experimental results demonstrate significant improvements; for example, the LLaMA 8B model with SearchRAG achieved absolute accuracy gains of +16.16% on MedMCQA compared to Chain-of-Thought baselines. AI practitioners can leverage this approach to improve the accuracy and reliability of LLM responses in specialized domains requiring up-to-date, fine-grained knowledge. |
| Natural Language Processing | Presumed Cultural Identity: How Names Shape LLM Responses (Read more on [arXiv](https://arxiv.org/abs/2502.11995) or [HuggingFace](https://huggingface.co/papers/2502.11995))| Lucie-Aimée Kaffee, Arnav Arora, Siddhesh Pawar, IAugenstein | This paper investigates how Large Language Models (LLMs) exhibit cultural presumptions in their responses based on user names. The main research objective is to quantify the extent to which LLMs associate names with specific cultural identities and how this affects the personalization of responses. The methodology involves prompting LLMs with common suggestion-seeking queries, including names from 30 cultures, and measuring cultural presumptions in the generated responses using an LLM-as-a-judge approach.  Results showed significant cultural biases, with responses to names from East Asian and Russian cultures demonstrating particularly strong presumptions (bias values ranging 0.3-0.45 for certain models and facets), while other cultures showed a larger variance or prompted more generic responses.  AI practitioners should design more nuanced personalization systems that avoid reinforcing stereotypes while maintaining meaningful customization, considering the ethical implications of name-based cultural assumptions. |
| Natural Language Processing | Thinking Preference Optimization (Read more on [arXiv](https://arxiv.org/abs/2502.13173) or [HuggingFace](https://huggingface.co/papers/2502.13173))| Xiaotian Han, Vipin Chaudhary, Jingfeng Yang, Hongye Jin, Wang Yang | This paper introduces Thinking Preference Optimization (ThinkPO), a post-Supervised Fine-Tuning (SFT) method designed to enhance the chain-of-thought (CoT) reasoning capabilities of Large Language Models (LLMs) without requiring additional long CoT responses. The primary research objective is to improve the reasoning performance of SFT-ed models using readily available short CoT responses, addressing the limitations of acquiring new high-quality long CoT data and the performance plateau observed with repeated training. ThinkPO utilizes short CoT reasoning responses as rejected answers and long CoT responses as chosen answers, applying direct preference optimization to encourage longer, more structured reasoning outputs. Experiments show that ThinkPO increases math reasoning accuracy of SFT-ed models by 8.6% and output length by 25.9%, significantly improving a distilled SFT model's performance on MATH500 from 87.4% to 91.2%. This approach offers a simple and resource-efficient method for continuously enhancing the reasoning capabilities of LLMs, minimizing the need for extensive new training data or multiple training iterations. |
| Natural Language Processing | Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering (Read more on [arXiv](https://arxiv.org/abs/2502.13962) or [HuggingFace](https://huggingface.co/papers/2502.13962))| Benjamin Van Durme, Jeffrey Cheng, wjurayj | This paper explores how test-time compute scaling in large language models affects selective question answering, where models can abstain from answering. The research investigates the relationship between compute budget, confidence thresholds, and answer accuracy/utility in question answering.  The methodology involves evaluating models with varying compute budgets and confidence thresholds, using a selection function to accept or reject answers based on model confidence. The primary result shows that increasing test time compute budget increases the model's confidence in correct answers, with the DeepSeek R1-32B model showcasing improved performance in the 'Jeopardy Odds' utility when using confidence threshold 0.95. The main implication is that AI practitioners should consider both compute budget and confidence thresholds for improved performance in question answering scenarios where incorrect answers are penalized. |
| Natural Language Processing | AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence (Read more on [arXiv](https://arxiv.org/abs/2502.13943) or [HuggingFace](https://huggingface.co/papers/2502.13943))| Jason Klein Liu, Chaofeng Qu, Zhaoling Chen, Junjie Lu, Yuliang Liu | This paper introduces AdaptiveStep, a novel method for automatically dividing reasoning steps in large language models (LLMs) based on model confidence. The primary research objective is to address the limitations of rule-based step division in Process Reward Models (PRMs) by proposing a more informative and efficient approach. AdaptiveStep divides reasoning steps based on the model's confidence in predicting the next word, providing more granular decision-making information. Experiments on mathematical reasoning and code generation tasks show that AdaptiveStep-trained PRMs achieve state-of-the-art Best-of-N performance, for instance, outperforming greedy decoding by 3.15% on the GSM8k dataset and by 6.54% on the Leetcode dataset when used with Token Level Value-Guided Decoding, and reduces data construction costs by more than 30% compared to existing Open-Source PRMs. This methodology offers a more efficient and generally applicable approach to training PRMs, leading to improved LLM performance and reasoning capabilities. |
| Machine Learning | NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation (Read more on [arXiv](https://arxiv.org/abs/2502.12638) or [HuggingFace](https://huggingface.co/papers/2502.12638))| Enzhi Zhang, Han Huang, Yanchen Luo, Zhiyuan Liu, xiangwang1223 | This paper introduces NExT-Mol, a foundation model for 3D molecule generation that combines 3D diffusion models with 1D language modeling. The research objective is to improve 3D molecule generation by leveraging the strengths of both 1D SELFIES-based Language Models (LMs) and 3D diffusion models, addressing validity and data scarcity issues. NExT-Mol first generates 1D molecule representations using a pretrained LM (MoLlama) and then predicts 3D conformers with a diffusion model (DMT), enhanced by transfer learning from the LM. The model achieves a 26% relative improvement in 3D FCD for de novo 3D generation on GEOM-DRUGS and shows enhanced performance in conditional 3D generation and conformer prediction. This offers AI practitioners a robust approach to generate valid and diverse 3D molecular structures, by suggesting a way to incorporate chemical inductive biases without compromising model scalability. |
| Machine Learning | ActionPiece: Contextually Tokenizing Action Sequences for Generative Recommendation (Read more on [arXiv](https://arxiv.org/abs/2502.13581) or [HuggingFace](https://huggingface.co/papers/2502.13581))| Wang-Cheng Kang, Noveen Sachdeva, Zhankui He, Jianmo Ni, hyp1231 | This paper introduces ActionPiece, a novel context-aware tokenization method for action sequences in generative recommendation systems. The research objective is to address the limitation of existing generative recommendation models that tokenize actions independently, ignoring contextual relationships. ActionPiece represents each action as a set of item features and constructs a vocabulary by merging feature patterns based on their co-occurrence frequency, incorporating set permutation regularization to handle unordered feature sets. Experiments on public datasets demonstrate that ActionPiece consistently outperforms existing methods, improving NDCG@10 by 6.00% to 12.82%. This implies that AI practitioners can leverage this contextual tokenization approach to enhance the performance of generative recommendation models. |
| Natural Language Processing | Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2502.13533) or [HuggingFace](https://huggingface.co/papers/2502.13533))| Ke Chen, Lidan Shou, Huan Li, Jue Wang, junzhang98 | This paper introduces LoRAM, a memory-efficient Low-Rank Adaptation (LoRA) training scheme for large language models (LLMs) that reduces memory consumption during training while achieving strong inference performance. The primary research question is how to reduce the memory overhead of LoRA fine-tuning for LLMs without significantly sacrificing inference accuracy. LoRAM trains a pruned (smaller) model to obtain pruned low-rank matrices, which are then recovered and used with the original (large) model for inference, combined with minimal-cost continual pre-training to align knowledge between pruned and original models. For a 70 billion parameter model, LoRAM enables training on a GPU with only 20G HBM, reducing parameter storage cost by up to 16.95x while achieving performance gains over both the original and LoRA-trained smaller models. This technique allows AI practitioners to fine-tune very large language models with significantly reduced hardware requirements, making advanced LLM customization more accessible. |
| Multi-Modal | GIMMICK -- Globally Inclusive Multimodal Multitask Cultural Knowledge Benchmarking (Read more on [arXiv](https://arxiv.org/abs/2502.13766) or [HuggingFace](https://huggingface.co/papers/2502.13766))| Anne Lauscher, Chris Biemann, Carolin Holtermann, floschne | The paper introduces GIMMICK, a new multimodal benchmark for evaluating cultural knowledge in vision-language models (LVLMs). It investigates regional cultural biases across 144 countries using six tasks built upon three novel datasets, evaluating 31 models. The primary research question explores regional biases in LLMs' and LVLMs' cultural understanding. The methodology involves systematically examining regional biases, model size influence, input modalities, and external cues. Results show strong biases toward Western cultures and correlations between model size and performance, with models excelling at recognizing broad cultural origins but struggling with nuanced understanding. |
| Natural Language Processing | InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning (Read more on [arXiv](https://arxiv.org/abs/2502.11573) or [HuggingFace](https://huggingface.co/papers/2502.11573))| Zhijie Sang, Pengxiang Li, Wenjun Wang, Shuo Cai, Congkai Xie | This paper introduces InfiR, a framework for developing efficient small language models (SLMs) and multimodal small language models (MSLMs) with strong reasoning capabilities. The main objective is to create compact models that can perform reasoning tasks on par with larger models, while being deployable on edge devices and reducing development costs. The key methodology involves a novel pre- and post-training pipeline that incorporates heuristic filtering, reasoning-oriented text recall, and specialized data synthesis for enhancing reasoning in both language and multimodal contexts. The InfiR-1B-Instruct model achieves state-of-the-art performance at the 1B parameter scale, with reasoning-related average score improvements of 1.33x over Llama3.2-1B-Instruct. This research provides a practical approach for AI practitioners to develop and deploy efficient, high-performing reasoning models, addressing user privacy concerns and reducing computational demands. |
| Machine Learning | Noise May Contain Transferable Knowledge: Understanding Semi-supervised Heterogeneous Domain Adaptation from an Empirical Perspective (Read more on [arXiv](https://arxiv.org/abs/2502.13573) or [HuggingFace](https://huggingface.co/papers/2502.13573))| Qiang Yang, Jian Jin, Yu Zhang, Xiaopu Zhang, yyyaoyuan | This paper provides an empirical study on Semi-supervised Heterogeneous Domain Adaptation (SHDA), exploring the nature of transferable knowledge across domains with distinct feature representations. The main research question is: "What is the transferable knowledge in SHDA?" The authors conduct extensive experiments on about 330 SHDA tasks, using a unified Knowledge Transfer Framework (KTF) and creating synthesized noise domains to serve as source data. The results on the NUS-WIDE+ImageNet-8 dataset, for example, demonstrated comparable performance between vanilla SHDA tasks (Text → Image) and noise-based tasks (Noise → Image) with multiple methods (Fig 2 provides accuracy values for various baselines on these tasks, with all methods exhibiting similar values across both types of tasks). The implication is that ensuring the transferability and discriminability of the source domain, regardless of source sample origin (text, image, or even noise), is crucial for effective knowledge transfer in SHDA, rather than the source domain's category or feature information. |
