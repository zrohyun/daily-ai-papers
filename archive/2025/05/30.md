

## Papers for 2025-05-30

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | Table-R1: Inference-Time Scaling for Table Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.23621) or [HuggingFace](https://huggingface.co/papers/2505.23621))| Arman Cohan, Lyuhao Chen, Zheyuan Yang, yilunzhao | The paper investigates inference-time scaling for table reasoning tasks. It addresses the research question of improving table reasoning capabilities of LLMs through inference-time scaling. The methodology involves developing two post-training strategies: distillation from DeepSeek-R1 reasoning traces and reinforcement learning with verifiable rewards (RLVR) via the GRPO algorithm. The Table-R1-Zero model matches or exceeds the performance of GPT-4.1 and DeepSeek-R1 using a 7B-parameter LLM and achieves a BLEU score of 32.7 on FeTaQA for FF-TQA. The results suggest that inference-time scaling, particularly RLVR, is an effective approach for enhancing table reasoning capabilities in LLMs, with implications for real-world applications involving structured data analysis. |
| Multi-Modal | VF-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC
  Videos (Read more on [arXiv](https://arxiv.org/abs/2505.23693) or [HuggingFace](https://huggingface.co/papers/2505.23693))| Yilun Zhao, Guo Gan, entropyhu, songtingyu | This paper introduces VF-EVAL, a new benchmark for evaluating the reliability of Multimodal Large Language Models (MLLMs) in generating feedback on AI-Generated Content (AIGC) videos. The research addresses the underexplored capabilities of MLLMs in interpreting synthetic AIGC videos, contrasting with the focus on natural video analysis in existing evaluations. VF-EVAL consists of four tasks: coherence validation, error awareness, error type detection, and reasoning evaluation, to systematically measure feedback generation capabilities. Experiments on 13 frontier MLLMs reveal that even the best models struggle to achieve consistent performance across all tasks, with GPT-4.1 achieving 66.3% accuracy on Coherence Validation. A REPROMPT experiment demonstrates that aligning MLLM feedback with human preferences can potentially benefit video generation. |
| Natural Language Processing | The Climb Carves Wisdom Deeper Than the Summit: On the Noisy Rewards in
  Learning to Reason (Read more on [arXiv](https://arxiv.org/abs/2505.22653) or [HuggingFace](https://huggingface.co/papers/2505.22653))| Rui Yan, Zhanhui Kang, Xingwu Sun, Ang Lv, Ruobing-Xie | This paper investigates the impact of noisy rewards in post-training large language models (LLMs) for reasoning tasks. It examines how LLMs perform under noisy reward functions, which are more realistic in real-world scenarios. The study introduces random reward flipping and a reasoning pattern reward (RPR) mechanism to train LLMs. Results show that LLMs exhibit robustness to reward noise, achieving 72% accuracy on MATH-500 with 40% reward flipping, and that RPR helps calibrate noisy rewards, enhancing performance on open-ended tasks. The findings suggest focusing on foundational reasoning abilities during pre-training to improve post-training techniques. |
| Computer Vision | Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial
  Intelligence (Read more on [arXiv](https://arxiv.org/abs/2505.23747) or [HuggingFace](https://huggingface.co/papers/2505.23747))| Yueqi Duan, Yi-Hsin Hung, Fangfu Liu, Diankun Wu | The paper introduces Spatial-MLLM, a novel method for enhancing visual-based spatial intelligence in video MLLMs. It aims to improve spatial reasoning from 2D observations without relying on additional 3D or 2.5D data. The methodology employs a dual-encoder architecture with a spatial encoder initialized from a visual geometry model and a space-aware frame sampling strategy. Experiments on VSI-Bench demonstrate state-of-the-art performance with Spatial-MLLM achieving a 3.0% higher average accuracy than Gemini-1.5 Pro, indicating its effectiveness in a wide range of visual-based spatial understanding and reasoning tasks. The architecture could improve robotics and augmented reality where 3D information is sparse. |
| Reinforcement Learning | ZeroGUI: Automating Online GUI Learning at Zero Human Cost (Read more on [arXiv](https://arxiv.org/abs/2505.23762) or [HuggingFace](https://huggingface.co/papers/2505.23762))| Yue Yu, Xuan Dong, Shi Liu, Shiqian Su, cyyang822 | The paper introduces ZeroGUI, a scalable online learning framework for automating GUI agent training at zero human cost. It addresses the limitations of offline learning by automating task generation and reward estimation. ZeroGUI integrates VLM-based automatic task generation, reward estimation, and two-stage online reinforcement learning for continuous interaction with GUI environments. Experiments on UI-TARS and Aguvis in OSWorld show that ZeroGUI boosts performance, achieving a 14% relative improvement for UI-TARS-7B.  This approach potentially reduces the need for human annotation and improves GUI agent adaptability. |
| Computer Vision | D-AR: Diffusion via Autoregressive Models (Read more on [arXiv](https://arxiv.org/abs/2505.23660) or [HuggingFace](https://huggingface.co/papers/2505.23660))| mikeshou, sebgao | The paper introduces Diffusion via Autoregressive Models (D-AR), a new paradigm recasting image diffusion as an autoregressive next-token prediction task. It aims to bridge diffusion and autoregressive modeling by linearizing the diffusion process through a coarse-to-fine tokenizer. The method uses a standard autoregressive transformer to generate discrete tokens corresponding to diffusion steps and decodes them into images. On ImageNet, D-AR achieves 2.09 FID using a 775M Llama backbone with 256 tokens. D-AR offers benefits like fast inference via KV caching, consistent previews, and zero-shot layout control, offering AI practitioners a new approach to image generation with potential for integration with LLMs. |
| Natural Language Processing | Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software
  Engineering (Read more on [arXiv](https://arxiv.org/abs/2505.23604) or [HuggingFace](https://huggingface.co/papers/2505.23604))| Subhro Das, Zhenting Qi, Delin Chen, Guangtao Zeng, maohaos2 | The paper introduces EvoScale, an evolutionary test-time scaling method to improve the performance of language models on software engineering tasks. It addresses the challenge of sample inefficiency in test-time scaling for software engineering tasks where large models are computationally expensive. The proposed method iteratively refines outputs via selection and mutation, shifting the output distribution towards higher-scoring regions and reducing the number of samples required to find correct solutions. It trains the model to self-evolve using reinforcement learning, internalizing the reward model's guidance and refining its own outputs without external verifiers at inference time. Evaluated on SWE-Bench-Verified, Satori-SWE-32B with EvoScale achieves a comparable performance with models exceeding 100B parameters while requiring only a small number of samples, reaching an accuracy of 41.6% when using Best@50 decoding. The method provides a path toward sample-efficient test-time scaling for software engineering tasks. |
| Computer Vision | VideoReasonBench: Can MLLMs Perform Vision-Centric Complex Video
  Reasoning? (Read more on [arXiv](https://arxiv.org/abs/2505.23359) or [HuggingFace](https://huggingface.co/papers/2505.23359))| Lin Sui, Yi Liu, Haoning Wu, Yuanxin Liu, RUBBISHLIKE | This paper introduces VideoReasonBench, a novel benchmark for evaluating vision-centric complex video reasoning in multimodal large language models (MLLMs). The research investigates whether MLLMs can perform intricate reasoning tasks grounded in visual information extracted from videos. They achieve this by evaluating MLLMs on video tasks requiring precise visual information recall, latent state inference, and future state prediction. Results show that state-of-the-art MLLMs generally perform poorly, with GPT-4o achieving only 6.9% accuracy, though Gemini-2.5-Pro reaches 56% with thinking enhancements, indicating visual reasoning still poses significant challenges and requires extended chain-of-thought reasoning. |
| Computer Vision | AnySplat: Feed-forward 3D Gaussian Splatting from Unconstrained Views (Read more on [arXiv](https://arxiv.org/abs/2505.23716) or [HuggingFace](https://huggingface.co/papers/2505.23716))| Kerui Ren, Tao Lu, Linning Xu, Lihan Jiang, matthewmao | AnySplat introduces a feed-forward network for novel-view synthesis from uncalibrated multi-view image collections, predicting 3D Gaussian primitives and camera parameters in a single pass. The research aims to achieve high-quality 3D scene reconstruction and novel view synthesis without precise camera calibration or per-scene optimization. AnySplat employs a geometry transformer, differentiable voxelization, and self-supervised knowledge distillation from a pretrained VGGT model. In zero-shot evaluations, AnySplat matches pose-aware baselines and surpasses pose-free approaches while achieving real-time rendering, e.g., 23.09 PSNR under the dense-view VRNeRF dataset. AnySplat enables efficient 3D scene reconstruction and rendering from casually captured data, reducing preprocessing requirements and enabling real-time applications. |
| Natural Language Processing | Are Reasoning Models More Prone to Hallucination? (Read more on [arXiv](https://arxiv.org/abs/2505.23646) or [HuggingFace](https://huggingface.co/papers/2505.23646))| Junfeng Fang, Jianhui Chen, Yanxu Chen, Yantao Liu, Zijun Yao | This paper investigates the hallucination phenomenon in large reasoning models (LRMs). The main research question is whether reasoning models are more prone to hallucination in fact-seeking tasks compared to their non-reasoning counterparts.  The methodology involves a comprehensive evaluation of different LRMs trained with various post-training pipelines, behavior analysis characterizing flaw repetition and think-answer mismatch, and model uncertainty probing. The results indicate that LRMs post-trained with SFT-only or RL-only pipelines are more prone to hallucination, with a performance decrease on SimpleQA and TriviaQA, while SFT+RL alleviates it; also, these pipelines show corrupted calibration. This implies that post-training strategies significantly impact factuality and calibration in LRMs, impacting their reliability for practical applications. |
| Computer Vision | cadrille: Multi-modal CAD Reconstruction with Online Reinforcement
  Learning (Read more on [arXiv](https://arxiv.org/abs/2505.22914) or [HuggingFace](https://huggingface.co/papers/2505.22914))| Ilya Zisman, Alexander Nikulin, Denis Tarasov, Maksim Kolodiazhnyi, zhemchuzhnikov | The paper introduces cadrille, a multi-modal CAD reconstruction model using online reinforcement learning. It aims to improve CAD model generation from point clouds, images, and text by leveraging VLMs and a two-stage training process. The methodology involves supervised fine-tuning on procedurally generated data followed by reinforcement learning fine-tuning using online feedback. The model achieves state-of-the-art reconstruction quality on the DeepCAD dataset, with further improvement via RL fine-tuning, reaching an IoU of 90.2% on CC3D with Dr. CPPO. This work demonstrates the efficacy of online RL for enhancing LLMs in CAD tasks and provides a robust approach for generalizing CAD reconstruction across different modalities and real-world datasets. |
| Natural Language Processing | Multi-Domain Explainability of Preferences (Read more on [arXiv](https://arxiv.org/abs/2505.20088) or [HuggingFace](https://huggingface.co/papers/2505.20088))| Roi Reichart, Liat Ein-Dor, Nitay Calderon | This paper introduces a fully automated method for generating concept-based explanations of preferences across multiple domains. The research aims to identify underlying concepts driving preferences in LLMs and human evaluations, crucial for alignment and evaluation. The method uses an LLM to discover differentiating concepts between chosen and rejected responses, representing them as concept-based vectors, and models the concept-preference relationship using a Hierarchical Multi-Domain Regression model (HMDR). Evaluations across eight diverse domains demonstrate strong preference prediction performance with HMDR achieving accuracy comparable to or better than black-box alternatives while being explainable. The implication is a new paradigm for explainability in LLMs, enabling better understanding and guidance of preference mechanisms. |
| Multi-Modal | UniRL: Self-Improving Unified Multimodal Models via Supervised and
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.23380) or [HuggingFace](https://huggingface.co/papers/2505.23380))| Mike Zheng Shou, Zhenheng Yang, Weijia Mao | The paper introduces UniRL, a self-improving post-training approach for unified multimodal models. The research addresses the challenge of improving both generation and understanding tasks in these models without external data. UniRL uses the model itself to generate training images iteratively, optimizing with supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO). Experiments on Show-o achieved a GenEval score of 0.77, and 0.65 on Janus. The method offers AI practitioners a way to refine existing models and reduce task imbalance with limited data and computational resources. |
| Machine Learning | SWE-bench Goes Live! (Read more on [arXiv](https://arxiv.org/abs/2505.23419) or [HuggingFace](https://huggingface.co/papers/2505.23419))| Bowen Li, Yu Kang, Chaoyun Zhang, Shilin He, Linghao Zhang | The paper introduces SWE-bench-Live, a live-updatable benchmark for evaluating large language models (LLMs) on real-world software bug resolution.  It aims to address limitations of existing benchmarks like staleness, limited repository coverage, and heavy manual effort.  The core methodology is REPOLAUNCH, an automated curation pipeline that streamlines instance creation and environment setup using Docker. Evaluation of agent frameworks revealed a substantial performance gap compared to static benchmarks, with the best-performing combination achieving only 19.25% resolved rate on SWE-bench-Live.  This highlights the need for dynamic benchmarks to accurately assess LLMs in dynamic, real-world software development settings. |
| Machine Learning | Train Sparse Autoencoders Efficiently by Utilizing Features Correlation (Read more on [arXiv](https://arxiv.org/abs/2505.22255) or [HuggingFace](https://huggingface.co/papers/2505.22255))| Nikita Balagansky, Daniil Gavrilov, Daniil Laptev, Yaroslav Aksenov, Vadim Kurochkin | This paper introduces KronSAE, a novel sparse autoencoder architecture for efficient feature learning in language models. The research aims to address the encoder bottleneck in traditional SAEs by factorizing the latent representation using Kronecker product decomposition and a differentiable AND-like gating mechanism (mAND). KronSAE reduces computational and memory overhead while preserving reconstruction fidelity, achieving up to a 4.3% increase in explained variance with roughly 54.7% fewer parameters on Qwen-1.5B with a 100M token budget. This allows for training larger SAEs with fixed compute resources, leading to more interpretable and disentangled features, facilitating downstream causal interventions. |
| Natural Language Processing | Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV
  Cache and Parallel Decoding (Read more on [arXiv](https://arxiv.org/abs/2505.22618) or [HuggingFace](https://huggingface.co/papers/2505.22618))| Shizhe Diao, Hao Zhang, Chengyue Wu, zhijianliu, Cauthyyy | The paper introduces Fast-dLLM, a training-free method to accelerate diffusion-based large language models (dLLMs) by enabling KV cache and parallel decoding. It addresses the inference speed gap by incorporating a novel block-wise approximate KV Cache and a confidence-aware parallel decoding strategy. Fast-dLLM mitigates dependency violations during parallel decoding by selectively decoding tokens based on a confidence threshold, leading to improved generation quality. Experiments on LLaDA and Dream models demonstrate up to 27.6x throughput improvement with minimal accuracy loss on LLM benchmarks. This advancement closes the performance gap with autoregressive models, paving the way for practical deployment of diffusion LLMs. |
| Multi-Modal | Muddit: Liberating Generation Beyond Text-to-Image with a Unified
  Discrete Diffusion Model (Read more on [arXiv](https://arxiv.org/abs/2505.23606) or [HuggingFace](https://huggingface.co/papers/2505.23606))| Kaidong Yu, Wenhao Chai, Zhuoran Zhao, BryanW, QingyuShi | The paper introduces Muddit, a unified discrete diffusion transformer for text and image generation. It aims to overcome limitations of autoregressive and existing discrete diffusion models in multimodal generation. Muddit leverages a pretrained text-to-image backbone and parallel discrete diffusion to achieve efficient generation. Empirical results on GenEval show Muddit achieves a strong overall accuracy of 0.61 for text-to-image generation. This suggests that purely discrete diffusion, when combined with strong visual priors, can be a scalable and effective backbone for unified generation. |
| Computer Vision | LoRAShop: Training-Free Multi-Concept Image Generation and Editing with
  Rectified Flow Transformers (Read more on [arXiv](https://arxiv.org/abs/2505.23758) or [HuggingFace](https://huggingface.co/papers/2505.23758))| Pinar Yanardag, Hidir Yesiltepe, ydalva | The paper introduces LoRAShop, a training-free framework for multi-concept image generation and editing using LoRA models and rectified flow transformers. The research aims to seamlessly blend multiple personalized concepts into an original image while preserving global context and fine details, addressing the issue of LORA crosstalk. LoRAShop extracts coarse masks delineating regions where concepts contribute significantly by leveraging the internal representations of rectified-flow models. Experiments demonstrate better identity preservation compared to baselines, with quantitative evaluations reaching 0.740 ± 0.066 for identity similarity, outperforming competing FLUX-based approaches. LoRAShop enables rapid creative iteration by eliminating retraining and external constraints, making personalized diffusion models more accessible for complex image editing tasks. |
| Reinforcement Learning | On-Policy RL with Optimal Reward Baseline (Read more on [arXiv](https://arxiv.org/abs/2505.23585) or [HuggingFace](https://huggingface.co/papers/2505.23585))| Zewen Chi, Shaohan Huang, Xun Wu, Li Dong, Yaru Hao | This paper introduces On-Policy RL with Optimal reward baseline (OPO), a novel algorithm designed for stable and effective reinforcement learning. It aims to improve training stability and reduce computational inefficiency in RL algorithms for aligning large language models. The key methodology involves exact on-policy training and deriving the optimal reward baseline to minimize gradient variance. OPO demonstrates superior performance on mathematical reasoning benchmarks and achieves lower policy shifts with higher output entropy. This suggests that OPO provides a promising direction for stable and effective reinforcement learning by maintaining lower policy shifts and higher output entropy, resulting in more diverse responses. |
| Computer Vision | GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action
  Control (Read more on [arXiv](https://arxiv.org/abs/2505.22421) or [HuggingFace](https://huggingface.co/papers/2505.22421))| Kun Zhan, Xueyang Zhang, Wenzhao Zheng, wangyida, antonio-c | The paper introduces GeoDrive, a driving world model integrating 3D geometry for precise action control in autonomous driving simulations. It addresses the challenge of maintaining 3D geometric consistency in dynamic environments by extracting a 3D representation, rendering video along specified trajectories, and employing a dynamic editing module during training. GeoDrive improves ego-car action controllability, reducing trajectory following errors by 42% compared to Vista, and enhances video quality metrics, such as FID and FVD. This approach enables more realistic and adaptable scene modeling, offering interactive scene editing capabilities. The incorporation of robust 3D conditions enhances spatial understanding and action controllability for safer autonomous driving systems. |
| Natural Language Processing | ATLAS: Learning to Optimally Memorize the Context at Test Time (Read more on [arXiv](https://arxiv.org/abs/2505.23735) or [HuggingFace](https://huggingface.co/papers/2505.23735))| Yuan Deng, Majid Daliri, Praneeth Kacham, Zeman Li, Ali Behrouz | The paper introduces ATLAS, a novel long-term memory module for enhancing context understanding in Transformers. It addresses limitations in memory capacity, online updating, and memory management by optimizing memory based on local context windows using a sliding window update rule termed the Omega rule. The methodology involves designing DeepTransformers, a new family of Transformer-like architectures that are strict generalizations of the original Transformer architecture. Experimental results demonstrate that ATLAS surpasses Transformers and linear recurrent models, achieving +80% accuracy on the 10M context length BABILong benchmark. This enables AI practitioners to build more effective models for tasks requiring long context understanding and extrapolation. |
| Natural Language Processing | KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction (Read more on [arXiv](https://arxiv.org/abs/2505.23416) or [HuggingFace](https://huggingface.co/papers/2505.23416))| Sangdoo Yun, Jae W. Lee, Sangwoo Kwon, jusjinuk, Jang-Hyun | The paper introduces KVzip, a novel query-agnostic KV cache eviction method that improves the efficiency of large language model (LLM) inference. The research aims to optimize KV cache compression for reusability across diverse queries by reconstructing the original context. KVzip quantifies the importance of KV pairs using the LLM to reconstruct the context and evicts less important pairs. Evaluations show that KVzip reduces KV cache size by 3-4x and FlashAttention decoding latency by approximately 2x, with negligible performance loss in question-answering, retrieval, reasoning, and code comprehension tasks. This method enables AI practitioners to significantly reduce the memory footprint and latency of LLM inference without compromising performance, particularly in multi-query scenarios. |
| Natural Language Processing | SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents (Read more on [arXiv](https://arxiv.org/abs/2505.23559) or [HuggingFace](https://huggingface.co/papers/2505.23559))| Ziheng Qi, Jiaxun Zhang, HakHan, m-serious, Leozkl | This paper introduces SafeScientist, an AI scientist framework designed to enhance safety and ethical responsibility in AI-driven scientific exploration. The research aims to address ethical and safety concerns in automated scientific discovery by LLM agents. It integrates defensive mechanisms like prompt monitoring and an ethical reviewer component and is evaluated using SciSafetyBench, a novel benchmark with 240 high-risk scientific tasks across 6 domains, alongside 30 scientific tools. Experimental results demonstrate that SafeScientist improves safety performance by 35% compared to traditional AI scientist frameworks without compromising output quality. The findings imply that integrating safety-oriented designs can lead to more responsible and trustworthy scientific AI systems. |
| Natural Language Processing | ToMAP: Training Opponent-Aware LLM Persuaders with Theory of Mind (Read more on [arXiv](https://arxiv.org/abs/2505.22961) or [HuggingFace](https://huggingface.co/papers/2505.22961))| Jiaxuan You, m-serious, HakHan | The paper introduces ToMAP, a novel approach for training LLMs to be more persuasive by incorporating theory of mind (ToM) modules. It aims to address the limitation of current LLMs in modeling opponent's thoughts during persuasion dialogues. ToMAP employs a counterclaim predictor and an opponent attitude predictor, enhanced through reinforcement learning, to generate more effective arguments. Experiments show that ToMAP, a 3B parameter model, outperforms larger baselines like GPT-4o with a 39.4% relative gain in persuasiveness. This indicates that incorporating ToM can significantly improve LLM persuaders, leading to more context-aware and adaptable strategies. |
| Computer Vision | Uni-Instruct: One-step Diffusion Model through Unified Diffusion
  Divergence Instruction (Read more on [arXiv](https://arxiv.org/abs/2505.20755) or [HuggingFace](https://huggingface.co/papers/2505.20755))| Weijian Luo, Debing Zhang, Colin Zhang, Weimin Bai, smallAI | This paper introduces Uni-Instruct, a unified framework for one-step diffusion model distillation based on a novel diffusion expansion theory of f-divergences. It aims to consolidate existing distillation methods and improve generation performance. The method derives a tractable loss that minimizes the expanded f-divergence family and unifies more than 10 existing diffusion distillation methods. Experiments on CIFAR10 achieved a record-breaking FID of 1.46 for unconditional generation, and ImageNet64 × 64 achieved a new SOTA one-step generation FID of 1.02. Uni-Instruct provides a new perspective for understanding one-step diffusion models and helps improve knowledge transferring. |
| Natural Language Processing | PatientSim: A Persona-Driven Simulator for Realistic Doctor-Patient
  Interactions (Read more on [arXiv](https://arxiv.org/abs/2505.17818) or [HuggingFace](https://huggingface.co/papers/2505.17818))| Jae Ho Sohn, Jiho Kim, Seongsu Bae, Hyunseung Chung, Daeun Kyung | The paper introduces PatientSim, a persona-driven patient simulator for evaluating doctor LLMs in realistic, multi-turn, context-aware interactions. It addresses the research question of generating realistic and diverse patient personas grounded in medical expertise. PatientSim operates using clinical profiles derived from MIMIC-ED and MIMIC-IV datasets, combined with personas defined by four axes. Evaluated on factual accuracy and persona consistency, the top-performing open-source model, Llama 3.3, was further validated by clinicians, achieving an average quality score of 3.89 out of 4 across six criteria. PatientSim provides a customizable, privacy-compliant testbed for medical dialogue systems, showing promise as an educational tool. |
| Natural Language Processing | DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural
  Language and Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.23754) or [HuggingFace](https://huggingface.co/papers/2505.23754))| Qiuzhi Liu, Tian Liang, Zhiwei He, Jiahao Xu, Ziyin Zhang | The paper introduces DeepTheorem, a new framework for informal theorem proving using LLMs. It addresses the misalignment between formal proof systems and LLMs' natural language knowledge by creating a dataset of 121K IMO-level theorems with correctness labels and difficulty annotations.  The study employs a reinforcement learning strategy (RL-Zero) to incentivize robust mathematical inference, achieving improved LLM theorem-proving performance, specifically, 47.22% outcome score on the DeepTheorem dataset, compared to 30.0% from the baselines. The results demonstrate that DeepTheorem has the potential to fundamentally advance automated informal theorem proving and mathematical exploration. DeepTheorem leverages verifiable theorem variants to enhance LLM reasoning capabilities. |
| Computer Vision | MAGREF: Masked Guidance for Any-Reference Video Generation (Read more on [arXiv](https://arxiv.org/abs/2505.23742) or [HuggingFace](https://huggingface.co/papers/2505.23742))| Jacob Zhiyuan Fang, Yuanyang Yin, Xun Guo, Yufan Deng, BestWishYsh | The paper introduces MAGREF, a novel framework for any-reference video generation that maintains visual consistency and adheres to textual instructions. It addresses the challenge of multi-subject consistency in video generation by using masked guidance conditioned on diverse reference images and textual prompts. MAGREF employs a region-aware dynamic masking mechanism and pixel-wise channel concatenation to preserve appearance features, achieving state-of-the-art video generation quality. Experiments demonstrate a Face Similarity score of 0.567 on single-ID and 0.581 on multi-subject benchmarks. MAGREF enables scalable and controllable multi-subject video synthesis, offering AI practitioners a means to generate high-fidelity videos with precise control over subjects and scenes. |
| Natural Language Processing | FAMA: The First Large-Scale Open-Science Speech Foundation Model for
  English and Italian (Read more on [arXiv](https://arxiv.org/abs/2505.22759) or [HuggingFace](https://huggingface.co/papers/2505.22759))| Mauro Cettolo, Alessio Brutti, Luisa Bentivogli, Marco Gaido, Sara Papi | FAMA is introduced as the first family of open-science speech foundation models for English and Italian. The research aims to develop transparent and reproducible SFMs using only OS-compliant data. The models are trained using a two-stage approach involving ASR pre-training and ASR+ST training on 150k+ hours of speech data, along with a novel 16k-hour dataset of pseudo-labeled speech. FAMA achieves competitive ASR performance compared to existing SFMs, improving WER by up to 4.2 while being up to 8 times faster. The release of FAMA's codebase, datasets, and models under OS-compliant licenses promotes greater inclusivity and advancement in speech technology research. |
| Reinforcement Learning | Afterburner: Reinforcement Learning Facilitates Self-Improving Code
  Efficiency Optimization (Read more on [arXiv](https://arxiv.org/abs/2505.23387) or [HuggingFace](https://huggingface.co/papers/2505.23387))| Dong Huang, Yuhao Qing, Yue Liu, Luu Tuan Tuan, Mingzhe Du | This paper introduces Afterburner, a novel framework for test-time iterative code efficiency optimization using reinforcement learning. The research aims to address the challenge of LLMs generating functionally correct but inefficient code by iteratively refining it based on empirical performance feedback. The proposed methodology employs a closed-loop system leveraging Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Group Relative Policy Optimization (GRPO) with execution feedback. The results demonstrate that GRPO significantly boosts PASS@1 from 47% to 62% and increases the likelihood of outperforming human submissions in efficiency from 31% to 45%. The main implication is that RL can effectively teach LLMs to self-improve code efficiency, surpassing static methods. |
| Computer Vision | Differentiable Solver Search for Fast Diffusion Sampling (Read more on [arXiv](https://arxiv.org/abs/2505.21114) or [HuggingFace](https://huggingface.co/papers/2505.21114))| Xubin Li, Qipeng zhang, Zexian Li, sthuihui, wangsssssss | This paper introduces a differentiable solver search algorithm to accelerate diffusion model sampling. The research aims to optimize the numerical solver used in reverse diffusion by directly learning solver parameters (time steps and coefficients). The core methodology involves defining a compact search space for solver parameters and using gradient descent to identify optimal configurations on a specific pre-trained diffusion model. Experiments demonstrate improved FID scores, such as achieving 2.33 on ImageNet 256x256 with a DDPM model using only 10 steps. The implication is that practitioners can significantly reduce the computational cost of inference with pre-trained diffusion models without retraining, improving the efficiency of image generation. |
| Computer Vision | To Trust Or Not To Trust Your Vision-Language Model's Prediction (Read more on [arXiv](https://arxiv.org/abs/2505.23745) or [HuggingFace](https://huggingface.co/papers/2505.23745))| Olga Fink, Eleni Chatzi, Jian Liang, Moru Liu, hdong51 | The paper introduces TrustVLM, a training-free framework for estimating the trustworthiness of Vision-Language Model (VLM) predictions. It addresses the challenge of confident misclassification in VLMs by leveraging the image embedding space to improve misclassification detection. TrustVLM employs an auxiliary vision encoder to create visual prototypes and assesses prediction reliability through image-to-image similarity. Evaluated across 17 datasets, results show state-of-the-art performance with improvements up to 51.87% in AURC compared to existing baselines. TrustVLM provides AI practitioners a method to enhance the reliability of VLM deployments in safety-critical applications without retraining. |
| Computer Vision | UniTEX: Universal High Fidelity Generative Texturing for 3D Shapes (Read more on [arXiv](https://arxiv.org/abs/2505.23253) or [HuggingFace](https://huggingface.co/papers/2505.23253))| Hongyu Yan, Rui Chen, Xiao Chen, Kunming Luo, Yixun Liang | The paper introduces UniTEX, a novel framework for generating high-fidelity and consistent textures for 3D shapes. It addresses the topological ambiguity inherent in UV mapping by operating directly in a unified 3D functional space using Texture Functions (TFs). UniTEX employs a transformer-based Large Texturing Model (LTM) to predict these TFs from images and geometry inputs and uses a LoRA-based strategy to adapt Diffusion Transformers (DiTs) for multi-view texture synthesis. Experiments demonstrate that UniTEX achieves superior visual quality and texture integrity with CMMD score of 0.826 on artist-created meshes. The approach offers a more generalizable and scalable solution for automated 3D texture generation by eliminating the limitations of UV-based refinement. |
| Multi-Modal | CXReasonBench: A Benchmark for Evaluating Structured Diagnostic
  Reasoning in Chest X-rays (Read more on [arXiv](https://arxiv.org/abs/2505.18087) or [HuggingFace](https://huggingface.co/papers/2505.18087))| Hyuk Gi Hong, Hangyul Yoon, Jung-Oh Lee, Geon Choi, ttumyche | The paper introduces CXReasonBench, a benchmark for evaluating structured diagnostic reasoning in chest X-rays using Large Vision-Language Models (LVLMs). It aims to address the lack of clinically meaningful reasoning assessment in existing benchmarks, which primarily focus on final diagnostic answers. The methodology involves a structured pipeline (CheXStruct) to automatically derive intermediate reasoning steps from chest X-rays, such as segmenting anatomical regions and computing diagnostic indices. Evaluation of 10 LVLMs shows even the strongest models struggle with structured reasoning and generalization, with models often failing to connect abstract diagnostic knowledge with anatomically grounded visual interpretation; structured guidance helps diagnostic reasoning but models fail in visual grounding and accurate anatomical region identification. CXReasonBench enables fine-grained assessment of diagnostic reasoning. |
| Computer Vision | Breaking Down Video LLM Benchmarks: Knowledge, Spatial Perception, or
  True Temporal Understanding? (Read more on [arXiv](https://arxiv.org/abs/2505.14321) or [HuggingFace](https://huggingface.co/papers/2505.14321))| Simon Wang, Zizhen Wang, Shiyu Li, Zhengfeng Lai, Bo Feng | This paper analyzes existing video Large Language Model (LLM) benchmarks to identify limitations in evaluating true temporal understanding. It addresses the research question of whether current benchmarks adequately isolate temporal reasoning from language priors and static visual understanding. The authors propose VBenchComp, an automated pipeline to categorize questions into LLM-Answerable, Semantic, and Temporal domains, and perform frame shuffling to assess temporal sensitivity. Results show that models can achieve high accuracy (up to 50% on VideoMME with GPT-40) without video input, and performance is often invariant to frame shuffling, indicating reliance on non-temporal cues. VBenchComp enables a more fine-grained evaluation, facilitating targeted improvements in video LLMs and the design of more robust benchmarks. |
| Machine Learning | Differential Information: An Information-Theoretic Perspective on
  Preference Optimization (Read more on [arXiv](https://arxiv.org/abs/2505.23761) or [HuggingFace](https://huggingface.co/papers/2505.23761))| Minjoon Seo, Hyeonbin Hwang, Hyunji Lee, yunjae-won | This paper presents an information-theoretic perspective on preference optimization, introducing the Differential Information Distribution (DID). It aims to theoretically justify the effectiveness of DPO's log-ratio reward parameterization by analyzing information gain during policy updates. The key methodology involves using the DID to characterize how preferences encode differential information and its impact on policy behavior. The paper proves the log-ratio reward of DPO is uniquely optimal under certain conditions and validates findings in synthetic experiments and real-world instruction-following datasets; results suggest high-entropy differential information is crucial for general instruction-following. The framework provides a unifying perspective on the DPO objective and its relationship to preference data structure. |
| Computer Vision | REOrdering Patches Improves Vision Models (Read more on [arXiv](https://arxiv.org/abs/2505.23751) or [HuggingFace](https://huggingface.co/papers/2505.23751))| Trevor Darrell, Yutong Bai, David M. Chan, RitwikGupta, d3tk | The paper explores the sensitivity of long-sequence vision models to patch ordering and introduces a method to learn optimal orderings. It investigates how different patch linearization strategies impact model performance, given that modern long-sequence transformers often break permutation equivariance. The authors propose REOrder, a two-stage framework combining compressibility analysis with reinforcement learning to discover task-optimal patch orderings. REOrder improves top-1 accuracy by up to 3.01% on ImageNet-1K and 13.35% on Functional Map of the World relative to row-major ordering. This suggests that practitioners can improve the performance of existing long-sequence vision models by optimizing patch ordering strategies rather than relying on fixed, arbitrary arrangements. |
| Machine Learning | ZeroSep: Separate Anything in Audio with Zero Training (Read more on [arXiv](https://arxiv.org/abs/2505.23625) or [HuggingFace](https://huggingface.co/papers/2505.23625))| Yunlong Tang, Susan Liang, Junxuan Huang, Yuesheng Ma, Chao Huang | The paper introduces ZeroSep, a zero-training framework for audio source separation using pre-trained text-guided diffusion models. It explores whether a pre-trained generative model can be repurposed for discriminative separation tasks without task-specific training. ZeroSep inverts mixed audio into the diffusion model's latent space and uses text conditioning to guide denoising for individual source recovery. Experiments on the MUSIC dataset demonstrate that ZeroSep surpasses supervised methods in some metrics, such as achieving a FAD score of 0.377. This implies that pre-trained generative models possess inherent separation capabilities, reducing the reliance on supervised training for audio source separation. |
| Computer Vision | Re-ttention: Ultra Sparse Visual Generation via Attention Statistical
  Reshape (Read more on [arXiv](https://arxiv.org/abs/2505.22918) or [HuggingFace](https://huggingface.co/papers/2505.22918))| Di Niu, Chao Gao, LiyaoJiang, kgmills, crc5577 | The paper introduces Re-ttention, a method for ultra-sparse visual generation in Diffusion Transformers. It addresses the bottleneck of quadratic complexity in the attention mechanism by statistically reshaping the attention distribution distorted by sparse attention using cached softmax statistics. Re-ttention achieves as high as 96.9% sparsity while maintaining visual quality, outperforming existing sparse attention techniques on text-to-video and text-to-image tasks. Experimental results on an H100 GPU demonstrate over 92% self-attention latency reduction with negligible overhead. Re-ttention enables AI practitioners to generate high-quality visual content with significantly reduced computational resources by extreme sparsification of attention. |
| Natural Language Processing | StressTest: Can YOUR Speech LM Handle the Stress? (Read more on [arXiv](https://arxiv.org/abs/2505.22765) or [HuggingFace](https://huggingface.co/papers/2505.22765))| Yossi Adi, gallilmaimon, iyosha | This paper introduces StressTest, a new benchmark for evaluating the ability of speech-aware language models (SLMs) to understand sentence stress. The research investigates whether SLMs can distinguish spoken sentence meanings based on different stress patterns. They propose a novel synthetic data generation pipeline and create Stress-17k, a training dataset to improve performance. Empirical results demonstrate that finetuning SLMs with Stress-17k significantly outperforms existing models on sentence stress reasoning and detection tasks, achieving 81.6% accuracy on SSR, while also maintaining ASR and SER performance. The main implication is that stress-aware training is crucial for SLMs to capture nuances in spoken language, enabling more accurate audio reasoning. |
| Natural Language Processing | One-shot Entropy Minimization (Read more on [arXiv](https://arxiv.org/abs/2505.20282) or [HuggingFace](https://huggingface.co/papers/2505.20282))| Bryan Dai, Joey Zhou, Lynx Chen, zgao3186 | The paper introduces One-shot Entropy Minimization (EM) as a novel post-training technique for large language models. It aims to improve model performance by minimizing token-level entropy using a single unlabeled data sample. The methodology involves training the model for a few steps (e.g., 10) to reduce uncertainty in its predictions. The study reports a significant improvement on MATH500 benchmark by 25.8 points, demonstrating the effectiveness of the approach. This suggests that practitioners can achieve competitive results with minimal data and computation by employing entropy minimization to reshape the model's output distribution. |
| Multi-Modal | ChartLens: Fine-grained Visual Attribution in Charts (Read more on [arXiv](https://arxiv.org/abs/2505.19360) or [HuggingFace](https://huggingface.co/papers/2505.19360))| Ryan A. Rossi, Nedim Lipka, Manan Suri, Franck-Dernoncourt, puneetm | This paper introduces ChartLens for fine-grained visual attribution in charts to address hallucinations in multimodal large language models (MLLMs). The research aims to identify specific chart elements that validate a given chart-associated response. ChartLens uses segmentation-based techniques to identify chart objects and employs set-of-marks prompting with MLLMs for fine-grained visual attribution. Evaluations show that ChartLens improves fine-grained attributions by 26-66%. The enhanced visual grounding capabilities provided by ChartLens improve the reliability of chart understanding in MLLMs. |
| Natural Language Processing | A Graph Perspective to Probe Structural Patterns of Knowledge in Large
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.19286) or [HuggingFace](https://huggingface.co/papers/2505.19286))| Yongjia Lei, Zhisheng Qi, Utkarsh Sahu, mhalappa, Franck-Dernoncourt | This paper investigates the structural patterns of knowledge encoded within large language models (LLMs) from a graph perspective. The study aims to quantify LLM knowledgeability at both the triplet and entity levels and relate it to graph structural properties.  The methodology involves prompting LLMs to evaluate triplets, constructing knowledge graphs, and using graph machine learning models to estimate entity knowledge. Empirical results show that GNN-based models can predict entity knowledgeability, and fine-tuning with actively selected triplets improves performance (e.g., in one experiment graph-FT led to a final score of 89.05 compared to a baseline of 63.25).  The findings provide insights for efficient knowledge retrieval and editing in LLMs by leveraging structured knowledge organization, and demonstrate an effective active learning strategy for knowledge injection. |
| Natural Language Processing | Unsupervised Word-level Quality Estimation for Machine Translation
  Through the Lens of Annotators (Dis)agreement (Read more on [arXiv](https://arxiv.org/abs/2505.23183) or [HuggingFace](https://huggingface.co/papers/2505.23183))| Arianna Bisazza, Malvina Nissim, Vilém Zouhar, gsarti | This paper introduces unsupervised word-level quality estimation (WQE) for machine translation by leveraging annotator disagreement. The research investigates efficient alternatives exploiting language model interpretability and uncertainty quantification to identify translation errors. The methodology involves evaluating 10 unsupervised metrics derived from models' inner representations across 12 translation directions, quantifying the impact of human label variation on metric performance. The results demonstrate that distribution-based unsupervised metrics can reach performance comparable to supervised methods, with Surprisal MCDVAR achieving strong results (e.g., precision of 34% on DivEMT). The findings suggest that human label variation should be considered in WQE evaluations for generalizable findings. |
| Multi-Modal | Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of
  Pre-trained Multimodal Representation via Text Updates (Read more on [arXiv](https://arxiv.org/abs/2505.22943) or [HuggingFace](https://huggingface.co/papers/2505.22943))| Gunhee Kim, Dayoon Ko, Heeseung Yun, ahnpersie | The paper introduces Multimodal Adversarial Compositionality (MAC), a benchmark to evaluate the compositional vulnerabilities of pre-trained multimodal representations. It aims to determine if Large Language Models (LLMs) can generate deceptive text updates to manipulate the judgments of models like CLIP. The study uses LLMs to generate deceptive captions by subtly modifying ground-truth captions and employs both sample-wise and group-wise evaluation metrics, along with a self-training approach based on rejection-sampling fine-tuning. Using a smaller language model Llama-3.1-8B the approach demonstrates improved performance in revealing compositional vulnerabilities, achieving better attack success rates and sample diversity. This work offers AI practitioners a new benchmark and methodology for assessing and improving the robustness of multimodal representations. |
| Natural Language Processing | When Models Reason in Your Language: Controlling Thinking Trace Language
  Comes at the Cost of Accuracy (Read more on [arXiv](https://arxiv.org/abs/2505.22888) or [HuggingFace](https://huggingface.co/papers/2505.22888))| Danielle S. Bitterman, Raquel Fernández, Zidi Xiong, Shan Chen, Jirui Qi | This paper investigates the multilingual reasoning capabilities of Large Reasoning Models (LRMs) and the trade-off between reasoning language and answer accuracy. The research aims to evaluate whether LRMs can effectively reason in languages other than English. The methodology involves evaluating two families of LRMs on the XReasoning benchmark and employing prompt hacking and post-training techniques to promote reasoning in the user's language. The primary result shows that prompt hacking can increase language matching from roughly 45-50% to above 90%, but reduces answer accuracy. The main implication for AI practitioners is the identification of a trade-off between explainability and accuracy in multilingual LRMs, highlighting the need for user-friendly multilingual LRMs. |
| Computer Vision | CLIPGaussian: Universal and Multimodal Style Transfer Based on Gaussian
  Splatting (Read more on [arXiv](https://arxiv.org/abs/2505.22854) or [HuggingFace](https://huggingface.co/papers/2505.22854))| Marcin Mazur, Tadeusz Dziarmaga, Piotr Borycki, Joanna Waczyńska, Kornel Howil | The paper introduces CLIPGaussian, a universal style transfer model supporting various data modalities like images, videos, 3D objects, and 4D dynamic scenes. It addresses the challenge of applying style transfer to Gaussian Splatting representations beyond simple color changes. The method operates directly on Gaussian primitives, integrating into existing GS pipelines without retraining, enabling joint optimization of color and geometry. Experimental results show superior style fidelity and consistency across tasks with a CLIP-S score of 26.86 for text-conditioned style transfer. CLIPGaussian offers AI practitioners a unified and efficient solution for multimodal style transfer by leveraging Gaussian Splatting. |
| Computer Vision | VidText: Towards Comprehensive Evaluation for Video Text Understanding (Read more on [arXiv](https://arxiv.org/abs/2505.22810) or [HuggingFace](https://huggingface.co/papers/2505.22810))| Yu Li, Yan Zhang, Zhifei Yang, Yan Shu, Zhoufaran Yang | The paper introduces VidText, a new benchmark for comprehensive evaluation of video text understanding. It aims to address the lack of robust benchmarks that capture the interaction between text and dynamic visual contexts in videos. The benchmark includes a hierarchical evaluation framework with video-level, clip-level, and instance-level tasks, along with paired perception-reasoning tasks. Experiments on 18 large multimodal models reveal that current models struggle across most tasks, achieving an average score of 46.8% by Gemini 1.5 Pro, indicating significant room for improvement. VidText provides a foundation for future research on multimodal reasoning with video text in dynamic environments, highlighting the need for improved OCR capabilities and contextual understanding. |
| Computer Vision | SridBench: Benchmark of Scientific Research Illustration Drawing of
  Image Generation Model (Read more on [arXiv](https://arxiv.org/abs/2505.22126) or [HuggingFace](https://huggingface.co/papers/2505.22126))| Chuanhao Li, Jiaxin Ai, Jianwen Sun, Yukang Feng, Yifan Chang | The paper introduces SridBench, a new benchmark for evaluating AI models in generating scientific illustrations. It aims to address the lack of standardized methods for assessing the quality of automatically generated scientific diagrams. The benchmark consists of 1,120 instances from 13 scientific disciplines, evaluated along six dimensions including semantic fidelity and structural accuracy. Experiments showed that even advanced models like GPT-4o-image fall short of human-level performance, highlighting limitations in semantic understanding. The study implies the need for further research into reasoning-driven visual generation models with improved text and visual information integration for scientific illustration tasks. |
| Natural Language Processing | Adaptive Classifier-Free Guidance via Dynamic Low-Confidence Masking (Read more on [arXiv](https://arxiv.org/abs/2505.20199) or [HuggingFace](https://huggingface.co/papers/2505.20199))| Ruichuan An, Renrui Zhang, Joey Tsai, Shilin Yan, Pengxiang Li | The paper introduces Adaptive Classifier-Free Guidance (A-CFG) to enhance controllability in iterative masked diffusion language models. It aims to improve guidance by dynamically tailoring the unconditional input based on the model's predictive confidence. A-CFG identifies and re-masks low-confidence tokens during each denoising step to create a localized unconditional state. Experiments show that A-CFG improves performance on various language generation tasks, achieving a 3.9 point gain on GPQA compared to standard CFG. The method provides AI practitioners with a more effective way to steer text generation in diffusion models by dynamically adapting to model uncertainty. |
| Natural Language Processing | Evaluating Text Creativity across Diverse Domains: A Dataset and Large
  Language Model Evaluator (Read more on [arXiv](https://arxiv.org/abs/2505.19236) or [HuggingFace](https://huggingface.co/papers/2505.19236))| Fang Luo, Yahui Liu, Yuzhuo Yuan, Xiting Wang, Aman | This paper introduces CreataSet, a dataset and LLM evaluator (CrEval) for assessing text creativity across diverse domains. It addresses the challenge of efficiently evaluating creativity by proposing a pairwise comparison framework using shared contextual instructions. The key methodology involves creating a large-scale dataset with human-level and synthetic creative instruction-response pairs and training an LLM-based evaluator on it. CrEval demonstrates superior alignment with human judgments, outperforming GPT-4o by 18.7% in agreement. This work provides AI practitioners with a practical tool for boosting the creativity of LLMs and enables further research in automated creativity evaluation. |
