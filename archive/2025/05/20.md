

## Papers for 2025-05-20

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | Chain-of-Model Learning for Language Model (Read more on [arXiv](https://arxiv.org/abs/2505.11820) or [HuggingFace](https://huggingface.co/papers/2505.11820))| tricktreat, Chengruidong, iofu728, xutan, KaitaoSong | The paper introduces Chain-of-Model (CoM), a novel learning paradigm for language models. It aims to improve scaling efficiency and deployment flexibility by incorporating causal relationships into hidden states as a chain. The methodology involves a Chain-of-Representation (CoR) and the Chain-of-Language-Model (CoLM) architecture based on the Transformer, enabling progressive scaling and elastic inference. Experimental results demonstrate comparable performance to standard Transformers while offering greater flexibility in model size, such as prefilling speedups. The CoM framework presents a novel approach to building language models with increased scaling efficiency and adaptable inference capabilities. |
| Natural Language Processing | AdaptThink: Reasoning Models Can Learn When to Think (Read more on [arXiv](https://arxiv.org/abs/2505.13417) or [HuggingFace](https://huggingface.co/papers/2505.13417))| Ling Feng, Lei Hou, juanli, linny2002, NeoZ123 | The paper introduces AdaptThink, a method to improve the efficiency of reasoning models by adaptively selecting between Thinking (chain-of-thought) and NoThinking modes based on problem difficulty. It aims to reduce inference overhead without sacrificing performance by using reinforcement learning to train models to make this selection. AdaptThink uses a constrained optimization objective and importance sampling to balance exploration of both thinking modes during training. Experiments show AdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B by 53% and improves its accuracy by 2.4% on three math datasets. This adaptive approach allows practitioners to optimize the trade-off between reasoning quality and efficiency in LLMs. |
| Reinforcement Learning | AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.11896) or [HuggingFace](https://huggingface.co/papers/2505.11896))| Shuangzhi, qingping95, Swtheking, sunzewei2715, louchenwei | The paper introduces AdaCoT, a reinforcement learning framework for adaptive Chain-of-Thought (CoT) triggering in Large Language Models (LLMs) to balance performance and computational cost. The research aims to optimize LLM reasoning by dynamically deciding when to invoke CoT based on query complexity. AdaCoT employs Proximal Policy Optimization (PPO) with Selective Loss Masking (SLM) to control CoT invocation, optimizing for Pareto optimality. Experiments show AdaCoT reduces CoT triggering rates to as low as 3.18% and decreases average response tokens by 69.06% while maintaining high performance.  AdaCoT provides a practical solution for developing more efficient and cost-effective LLMs by intelligently managing reasoning complexity. |
| Natural Language Processing | Delta Attention: Fast and Accurate Sparse Attention Inference by Delta
  Correction (Read more on [arXiv](https://arxiv.org/abs/2505.11254) or [HuggingFace](https://huggingface.co/papers/2505.11254))| Sung Ju Hwang, gmlwns5176, jeffwillette | This paper introduces Delta Attention (Δ Attention), a novel method to improve the accuracy of sparse attention inference in transformers. It addresses the distributional shift induced by sparse attention, which impairs query-key alignment. The method corrects this shift by adding a post-processing term derived from a subset of densely computed attention outputs. Experiments on the RULER benchmark demonstrate an average 36%pt performance increase, recovering 88% of quadratic attention accuracy, while maintaining 98.5% sparsity and achieving 32x speedup over Flash Attention 2 for 1M token prefills. Δ Attention is designed to be seamlessly integrated with existing sparse attention kernels, offering a practical solution for efficient and accurate long-sequence processing. |
| Multi-Modal | Scaling Computer-Use Grounding via User Interface Decomposition and
  Synthesis (Read more on [arXiv](https://arxiv.org/abs/2505.13227) or [HuggingFace](https://huggingface.co/papers/2505.13227))| Mayome, RadioBlue, lixiaochuan2020, MillanK, tianbaoxiexxx | This paper introduces OSWORLD-G, a GUI grounding benchmark, and JEDI, a large-scale synthetic dataset, to address limitations in current computer-use agent development. The research aims to improve the ability of agents to map natural language instructions to specific GUI actions. The methodology involves creating a comprehensive benchmark with finely annotated samples and synthesizing a dataset through multi-perspective decoupling of tasks. Results demonstrate improved grounding on ScreenSpot-v2, ScreenSpot-Pro, and OSWORLD-G, with agentic capabilities on OSWorld improving from 5% to 27%. Improved grounding with large-scale data enables compositional generalization to novel interfaces for AI practitioners. |
| Natural Language Processing | Thinkless: LLM Learns When to Think (Read more on [arXiv](https://arxiv.org/abs/2505.13379) or [HuggingFace](https://huggingface.co/papers/2505.13379))| wxcTest, horseee, Vinnnf | The paper introduces Thinkless, a learnable framework that enables language models to adaptively select between short-form and long-form reasoning. It addresses the question of whether LLMs can learn when to think, balancing computational efficiency and accuracy. Thinkless employs a reinforcement learning paradigm with a Decoupled Group Relative Policy Optimization (DeGRPO) algorithm, using control tokens to govern reasoning mode selection and response accuracy. Empirical results on benchmarks like GSM8K demonstrate a 50%-90% reduction in long-chain thinking usage. This approach offers AI practitioners a method to significantly improve the efficiency of reasoning language models without substantial performance degradation. |
| Machine Learning | Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient
  in Latent Space (Read more on [arXiv](https://arxiv.org/abs/2505.13308) or [HuggingFace](https://huggingface.co/papers/2505.13308))| zlzheng, vickyandkekey, ColorfulAI, xuekai, henry12348 | The paper introduces LATENTSEEK, a framework enhancing LLM reasoning through test-time instance-level adaptation in latent space. It explores optimizing latent representations using policy gradient methods guided by self-generated rewards. Evaluated on reasoning benchmarks such as GSM8K, LATENTSEEK consistently outperforms Chain-of-Thought, achieving an average improvement of 10.75% on GSM8K. The approach positions latent space test-time scaling as a lightweight and effective solution for improving LLM reasoning capabilities. This implies that practitioners can leverage latent space optimization for enhancing LLM reasoning without extensive retraining. |
| Computer Vision | Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation (Read more on [arXiv](https://arxiv.org/abs/2505.13215) or [HuggingFace](https://huggingface.co/papers/2505.13215))| epark, Heyjin, LeeYG, ohseungjun | The paper introduces a novel hybrid 3D-4D Gaussian Splatting (3D-4DGS) framework for fast dynamic scene representation. It addresses the inefficiencies of conventional 4DGS by adaptively representing static regions with 3D Gaussians and dynamic regions with 4D Gaussians. The method iteratively converts temporally invariant Gaussians into 3D, reducing parameters and improving efficiency while retaining high fidelity for dynamic elements. Experiments on the N3V dataset demonstrate a competitive PSNR of 32.25 dB and faster training times (12 minutes) compared to baseline 4DGS methods. This approach allows for efficient and high-quality dynamic scene reconstruction, enabling faster training and reduced memory consumption for AI practitioners. |
| Multi-Modal | MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable
  Step-Level Supervision (Read more on [arXiv](https://arxiv.org/abs/2505.13427) or [HuggingFace](https://huggingface.co/papers/2505.13427))| wqshao126, Domingo12, SuperposedWave, FanqingM, Cierra0506 | The paper presents MM-PRM, a process reward model for enhancing multimodal mathematical reasoning through scalable step-level supervision. It addresses the limitation of fine-grained supervision in complex reasoning by training a process reward model within an automated framework. The methodology involves constructing a multimodal policy model (MM-Policy) and generating step-level annotations using Monte Carlo Tree Search.  MM-PRM achieves significant improvements on benchmarks like MathVista (62.93% to 67.60%) using Best-of-N inference.  The work suggests process supervision is a powerful tool for enhancing the logical robustness of multimodal reasoning systems, enabling more accurate intermediate steps and potentially improving interpretability. |
| Machine Learning | FedSVD: Adaptive Orthogonalization for Private Federated Learning with
  LoRA (Read more on [arXiv](https://arxiv.org/abs/2505.12805) or [HuggingFace](https://huggingface.co/papers/2505.12805))| Sangwoo Park, hbseong, dwgnr, dongboklee, Seanie-lee | The paper introduces FedSVD, a novel federated learning method to improve private fine-tuning with LoRA. It addresses noise amplification in DP-SGD by reparameterizing LoRA updates using SVD, enabling adaptive orthogonalization. FedSVD optimizes only one LoRA matrix and refactorizes the product of aggregated updates with SVD to update the second matrix. Experiments on GLUE datasets show that FedSVD outperforms baselines like FFA-LORA, achieving up to 8.77 percentage points improvement under DP constraints. This approach stabilizes training and accelerates optimization, offering a more effective private federated learning strategy for AI practitioners. |
| Reinforcement Learning | CPGD: Toward Stable Rule-based Reinforcement Learning for Language
  Models (Read more on [arXiv](https://arxiv.org/abs/2505.12504) or [HuggingFace](https://huggingface.co/papers/2505.12504))| wqshao126, SuperposedWave, Cierra0506, FanqingM, Zkkkai | The paper introduces Clipped Policy Gradient Optimization with Policy Drift (CPGD) to enhance the stability of rule-based reinforcement learning for language models. It addresses the instability issues in existing RL methods by introducing a policy drift constraint based on KL divergence and a clip mechanism on the logarithm of the ratio to prevent excessive policy updates. CPGD achieves +21.8% gain on the in-domain benchmark MMK12. The method mitigates training collapse and improves performance by dynamically regulating policy updates, providing a robust alternative for RL post-training of LMs. This advancement offers AI practitioners a more reliable RL algorithm for refining language model reasoning capabilities. |
| Computer Vision | Faster Video Diffusion with Trainable Sparse Attention (Read more on [arXiv](https://arxiv.org/abs/2505.13389) or [HuggingFace](https://huggingface.co/papers/2505.13389))| EricX003, hunterhector, BrianChen1129, haofeng666, PY007 | This paper presents VSA, a trainable sparse attention mechanism, to accelerate video diffusion transformers (DiTs). The research aims to alleviate the quadratic attention bottleneck in DiTs by focusing computation on critical tokens. VSA uses a hierarchical approach with coarse-grained cube-to-cube attention followed by fine-grained token-level attention within selected cubes, achieving 85% MFU of FlashAttention3. Experiments show VSA reaches a Pareto point that cuts training FLOPS by 2.53x with comparable diffusion loss, and reduces inference time by 1.7x on Wan2.1. VSA offers a practical alternative to full attention, enabling further scaling of video diffusion models. |
| Natural Language Processing | Fractured Chain-of-Thought Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.12992) or [HuggingFace](https://huggingface.co/papers/2505.12992))| JunnanLi, doyensahoo, yuhuixu, hendrydong, baohao | The paper introduces Fractured Sampling, a novel inference-time strategy for enhancing the efficiency of chain-of-thought reasoning in large language models. The research aims to improve accuracy-cost trade-offs by interpolating between full chain-of-thought and solution-only sampling across three dimensions: reasoning trajectories, solution diversity, and reasoning depth. Fractured Sampling truncates reasoning traces and strategically allocates computation across these dimensions. Experiments on five reasoning benchmarks demonstrate Fractured Sampling achieves superior accuracy-cost trade-offs and yields steep log-linear scaling gains in Pass@k versus token budget; for example, it can achieve a 10.4% improvement over baseline settings. This approach allows for more efficient and scalable LLM reasoning by optimizing the balance between reasoning depth and breadth. |
| Computer Vision | VisionReasoner: Unified Visual Perception and Reasoning via
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.12081) or [HuggingFace](https://huggingface.co/papers/2505.12081))| Shu Liu, BoHao0326, zszhong, TainU, Ricky06662 | VisionReasoner is a unified framework for diverse visual perception tasks using reinforcement learning. The paper addresses the challenge of performing detection, segmentation, and counting within a shared model. It employs a multi-object cognitive learning strategy and task reformulation, along with specifically designed reward mechanisms, to enhance reasoning capabilities. VisionReasoner achieves superior performance, outperforming Qwen2.5VL by 29.1% on COCO detection. This suggests a potentially more scalable and generalizable approach to visual perception by unifying different tasks within a single architecture and training paradigm. |
| Natural Language Processing | Neuro-Symbolic Query Compiler (Read more on [arXiv](https://arxiv.org/abs/2505.11932) or [HuggingFace](https://huggingface.co/papers/2505.11932))| jrwen, wuyongkang, lixiaoxi45, douzc, KeriaZhang | The paper introduces QCompiler, a neuro-symbolic framework for enhancing query understanding in retrieval-augmented generation (RAG) systems. It addresses the challenge of processing complex queries with nested structures and dependencies by compiling them into Abstract Syntax Trees (ASTs). The methodology involves designing a minimal Backus-Naur Form (BNF) grammar and using a small language model to translate natural language queries into BNF expressions. Experiments on multi-hop benchmarks show that QCompiler achieves an EM score of 44.5% on 2Wiki, outperforming existing RAG systems. The work implies AI practitioners can significantly improve the efficiency and accuracy of RAG systems for complex queries. |
| Multi-Modal | ViPlan: A Benchmark for Visual Planning with Symbolic Predicates and
  Vision-Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.13180) or [HuggingFace](https://huggingface.co/papers/2505.13180))| Pietroferr, giobin, minttusofia, dainesn1, merlerm | The paper introduces ViPlan, a benchmark for evaluating visual planning capabilities of Vision-Language Models (VLMs) using symbolic predicates. It investigates the ability of VLMs to either directly plan actions or ground symbolic plans in visual environments. The methodology involves benchmarking nine open-source VLM families on Blocksworld and household robotics tasks, comparing VLM-grounded symbolic planning against direct VLM planning. Results show symbolic planning outperforms direct VLM planning in Blocksworld, while the opposite is true in household robotics tasks, with no significant benefit from Chain-of-Thought prompting. ViPlan enables AI practitioners to assess and improve VLMs' visual reasoning and planning abilities in grounded environments. |
| Natural Language Processing | Model Merging in Pre-training of Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.12082) or [HuggingFace](https://huggingface.co/papers/2505.12082))| Jing Liu, Chaoyi Zhang, Shen Yan, Yiyuan Ma, Yunshui Li | This paper investigates model merging techniques during the pre-training of large language models (LLMs). The research explores whether merging checkpoints trained with constant learning rates can improve performance and predictability of annealing behavior. The methodology involves extensive experiments with dense and Mixture-of-Experts (MoE) architectures ranging from millions to over 100 billion parameters, introducing a novel Pre-trained Model Average (PMA) strategy. Results demonstrate that model merging during the stable training phase yields consistent performance gains; specifically, Seed-MoE-1.3B/13B improved on Humaneval from 31.1 to 36.6.  The findings offer practical pre-training guidelines for effective model merging, potentially leading to more efficient model development and reduced training costs for LLMs. |
| Computer Vision | Accelerate TarFlow Sampling with GS-Jacobi Iteration (Read more on [arXiv](https://arxiv.org/abs/2505.12849) or [HuggingFace](https://huggingface.co/papers/2505.12849))| zhenqincn, encoreus | This paper introduces a method to accelerate the sampling process of TarFlow, an image generation model, which traditionally suffers from slow sampling due to its autoregressive Transformer blocks. The research aims to improve the efficiency of TarFlow sampling by applying Gauss-Seidel-Jacobi (GS-Jacobi) iteration. The key methodology involves transforming the sampling process into a diagonalized nonlinear system and utilizing the GS-Jacobi iteration scheme with metrics like Convergence Ranking Metric (CRM) and Initial Guessing Metric (IGM) to adapt the iteration strategy. Experiments on four TarFlow models demonstrate significant speed-ups, such as 4.53x in Img128cond, while maintaining image quality as measured by FID. This allows AI practitioners to generate high-quality images with TarFlow models more efficiently. |
| Natural Language Processing | When AI Co-Scientists Fail: SPOT-a Benchmark for Automated Verification
  of Scientific Research (Read more on [arXiv](https://arxiv.org/abs/2505.11855) or [HuggingFace](https://huggingface.co/papers/2505.11855))| sngwon, Cartinoe5930, HazelNam, JW17, amphora | The paper introduces SPOT, a benchmark for evaluating LLMs in the automated verification of scientific manuscripts. The research explores the use of LLMs as verifiers to identify errors in published papers, a task underexplored compared to LLMs' generative roles. SPOT consists of 83 papers with 91 validated errors across various scientific fields, cross-validated with actual authors and human annotators. Evaluation of state-of-the-art LLMs on SPOT reveals a performance ceiling of 21.1% recall and 6.1% precision by the best-performing model (03), highlighting the substantial gap between LLM capabilities and requirements for reliable AI-assisted academic verification. The main implication is that current LLMs are not yet reliable for dependable AI-assisted verification of scientific research due to issues like low confidence, inconsistency, and misunderstanding of domain knowledge. |
| Multi-Modal | ChartMuseum: Testing Visual Reasoning Capabilities of Large
  Vision-Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.13444) or [HuggingFace](https://huggingface.co/papers/2505.13444))| wadhma, PrasannSinghal, fcyin, thomlake, lytang | The paper introduces ChartMuseum, a benchmark for evaluating the visual reasoning capabilities of large vision-language models (LVLMs). It addresses the imbalance in current LVLMs, which often underperform in visual reasoning compared to textual reasoning. ChartMuseum comprises 1,162 expert-annotated questions curated from real-world charts. Evaluation reveals a substantial gap between model and human performance, with the best model, Gemini-2.5-Pro, achieving 63.0% accuracy, while humans achieve 93%. This benchmark demonstrates the challenge that current LVLMs face when dealing with complex visual reasoning tasks, highlighting the need for improvement in this area. |
| Computer Vision | MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation (Read more on [arXiv](https://arxiv.org/abs/2505.10238) or [HuggingFace](https://huggingface.co/papers/2505.10238))| Yali Wang, Zhizhi Guo, Xirui Hu, yanboding | The paper introduces MTVCrafter, a novel framework for open-world human image animation by directly modeling raw 3D motion sequences. It addresses the limitation of existing methods that rely on 2D-rendered pose images by proposing a 4D motion tokenizer (4DMoT) to quantize 3D motion sequences into 4D motion tokens. MTVCrafter incorporates a motion-aware video Diffusion Transformer (MV-DiT) with unique motion attention mechanisms and 4D positional encodings. The approach achieves state-of-the-art results on the TikTok benchmark, with an FID-VID of 6.98, surpassing the second-best method by 65%. This approach offers AI practitioners a more robust and generalizable method for human image animation by leveraging raw 3D motion data. |
| Computer Vision | FinePhys: Fine-grained Human Action Generation by Explicitly
  Incorporating Physical Laws for Effective Skeletal Guidance (Read more on [arXiv](https://arxiv.org/abs/2505.13437) or [HuggingFace](https://huggingface.co/papers/2505.13437))| Shengda Xu, Mingfei Shi, Dian Shao, Jason-Huang824, Harold328 | FinePhys addresses the challenge of generating physically plausible and fine-grained human actions in videos. The paper aims to synthesize realistic gymnastics routines by incorporating physical laws into a generative model. The method estimates 2D poses, lifts them to 3D using in-context learning, and refines the motion using a physics-based motion re-estimation module governed by Euler-Lagrange equations.  FinePhys achieves superior performance over baselines on fine-grained action subsets of FineGym, with significantly better CLIP-SIM* scores and user study results, indicating improved biomechanical plausibility. The research offers AI practitioners a framework for generating more realistic human motion by explicitly integrating physical constraints into video generation pipelines. |
| Natural Language Processing | ExTrans: Multilingual Deep Reasoning Translation via Exemplar-Enhanced
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.12996) or [HuggingFace](https://huggingface.co/papers/2505.12996))| Jie Zhou, fandong, Krystalan | The paper introduces ExTrans, a multilingual deep reasoning translation model enhanced via exemplar-based reinforcement learning. It addresses the research question of improving translation quality in low-resource languages by leveraging strong language models as exemplars. The methodology involves a novel reward modeling approach comparing policy MT model translations with those of a strong LRM, combined with a lightweight approach to extend the method to multilingual settings. ExTrans-7B achieves state-of-the-art performance in English-to-Chinese literary translation, outperforming OpenAI-01 and DeepSeek-R1 (e.g., 90.55 GRF on MetaphorTrans test set) and the lightweight multilingual adaptation (mExTrans-7B) allows effective transfer of MT capabilities across different languages, offering AI practitioners a scalable solution for multilingual translation tasks. |
| Natural Language Processing | SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.11484) or [HuggingFace](https://huggingface.co/papers/2505.11484))| Chunyan Miao, Xu Guo, Aver3, xuyige | The paper introduces SoftCoT++, a test-time scaling method that enhances reasoning performance in large language models by exploring diverse thinking paths. It addresses the limitation of fixed latent representations in SoftCoT by perturbing latent thoughts via multiple specialized initial tokens and applying contrastive learning to promote diversity. SoftCoT++ was evaluated on five reasoning benchmarks and two LLM architectures, demonstrating significant performance boosts compared to SoftCoT and outperforming SoftCoT with self-consistency scaling.  For example, on GSM8K, SoftCoT++ achieved a 90.99% accuracy on the LLaMA-3.1-8B-Instruct model, outperforming other methods. SoftCoT++ provides a mechanism for AI practitioners to scale reasoning at test time without modifying model parameters while maintaining efficiency and stability. |
| Computer Vision | HISTAI: An Open-Source, Large-Scale Whole Slide Image Dataset for
  Computational Pathology (Read more on [arXiv](https://arxiv.org/abs/2505.12120) or [HuggingFace](https://huggingface.co/papers/2505.12120))| Ekaterina Ivanova, alpchel, mgvz | The paper introduces HISTAI, a large-scale, open-source Whole Slide Image (WSI) dataset for computational pathology. The main objective is to address the limitations of existing WSI datasets by providing a diverse collection of cases with comprehensive clinical metadata to improve the robustness and generalizability of AI models. The dataset contains over 60,000 slides from various tissue types, each accompanied by clinical metadata like diagnosis, demographics, pathological annotations, and ICD-10 codes. By releasing this dataset, the authors aim to foster innovation, promote reproducibility, and drive the development of clinically relevant AI solutions in digital pathology. The HISTAI dataset contains 57,647 slides at 20X magnification and 2,463 at 40X. |
| Computer Vision | QVGen: Pushing the Limit of Quantized Video Generative Models (Read more on [arXiv](https://arxiv.org/abs/2505.11497) or [HuggingFace](https://huggingface.co/papers/2505.11497))| Jing Liu, HaotongQin, lvchengtao, Ruihao, Harahan | QVGen introduces a novel quantization-aware training (QAT) framework for efficient video diffusion models under low-bit quantization. The paper addresses the challenge of ineffective direct application of quantization to video DMs by minimizing gradient norm via auxiliary modules and a rank-decay strategy. QVGen achieves full-precision comparable quality under 4-bit settings, significantly outperforming existing methods. For example, a 3-bit CogVideoX-2B achieves +25.28 in Dynamic Degree and +8.43 in Scene Consistency on VBench. The framework allows practitioners to deploy quantized video DMs with minimal performance loss and reduced computational cost. |
| Reinforcement Learning | From Grunts to Grammar: Emergent Language from Cooperative Foraging (Read more on [arXiv](https://arxiv.org/abs/2505.12872) or [HuggingFace](https://huggingface.co/papers/2505.12872))| Mingfei Sun, Wei Pan, Weicheng Tao, Rujikorn Charakorn, Maytus Piriyajitakonkij | This paper introduces Foraging Games (FG), a multi-agent reinforcement learning framework to study the emergence of language in cooperative settings. The study investigates how agents learn to communicate and coordinate actions in a partially observable grid world with temporal dependencies. Using deep reinforcement learning, agents develop communication protocols exhibiting characteristics of natural language, achieving success rates above 95% in various games. The authors demonstrate that factors like population size and training regimes influence properties like interchangeability and compositionality. This research provides a platform for studying language evolution from cooperation, partial observability, and temporal reasoning in embodied multi-agent AI systems. |
| Natural Language Processing | Tiny QA Benchmark++: Ultra-Lightweight, Synthetic Multilingual Dataset
  Generation & Smoke-Tests for Continuous LLM Evaluation (Read more on [arXiv](https://arxiv.org/abs/2505.12058) or [HuggingFace](https://huggingface.co/papers/2505.12058))| vincentkoc | The paper introduces Tiny QA Benchmark++ (TQB++), an ultra-lightweight evaluation suite for Large Language Models (LLMs). It addresses the need for rapid, continuous LLM evaluation by providing a synthetic multilingual dataset generation toolkit and smoke-tests. The methodology involves a Python LiteLLM script for on-demand micro-benchmark generation and pre-built multilingual packs for cross-lingual smoke testing. Empirical results show high accuracy (≈ 90% Exact Match) for top-tier models on the core English set, with varied performance on low-resource languages, demonstrating TQB++'s utility. TQB++ offers AI practitioners a tool for rapidly detecting regressions and quality shifts in LLMOps workflows. |
| Natural Language Processing | HelpSteer3-Preference: Open Human-Annotated Preference Data across
  Diverse Tasks and Languages (Read more on [arXiv](https://arxiv.org/abs/2505.11475) or [HuggingFace](https://huggingface.co/papers/2505.11475))| Felipe Soares, Hoo-Chang Shin, Olivier Delalleau, Jiaqi Zeng, Zhilin Wang | The paper introduces HelpSteer3-Preference, a new high-quality, human-annotated preference dataset for training instruction-following language models. It aims to enhance the quality and diversity of preference data for Reinforcement Learning from Human Feedback (RLHF). The methodology involves collecting over 40,000 preference samples across diverse tasks like STEM, coding, and multilingual scenarios, using expert annotators and stringent quality control. The reward models trained on this dataset achieve 82.4% on RM-Bench and 73.7% on JudgeBench, significantly improving over existing RMs. This dataset enables AI practitioners to develop better aligned and more capable general-domain language models suitable for various real-world applications. |
| Computer Vision | Learned Lightweight Smartphone ISP with Unpaired Data (Read more on [arXiv](https://arxiv.org/abs/2505.10420) or [HuggingFace](https://huggingface.co/papers/2505.10420))| Radu Timofte, AndreiArhire | The paper introduces a novel training method for a learnable Image Signal Processor (ISP) on smartphones using unpaired data. It addresses the challenge of acquiring pixel-wise aligned paired data by proposing an unpaired approach guided by adversarial training with multiple discriminators and a multi-term loss function. The key methodology involves training lightweight neural networks with feature maps from pre-trained networks to maintain content structure and learn color and texture characteristics. Evaluation on Zurich RAW to RGB and Fujifilm UltraISP datasets demonstrates strong potential, achieving fidelity scores comparable to paired training, with a PSNR of 19.448 achieved on the ZRR test data for the unpaired setting. This work enables the development of high-quality, learned ISPs without the need for costly and difficult-to-obtain paired datasets. |
| Natural Language Processing | Fast, Not Fancy: Rethinking G2P with Rich Data and Rule-Based Models (Read more on [arXiv](https://arxiv.org/abs/2505.12973) or [HuggingFace](https://huggingface.co/papers/2505.12973))| Hamid R. Rabiee, Zahra Dehghanian, Mahta Fetrat Qharabagh | The paper addresses homograph disambiguation in grapheme-to-phoneme (G2P) conversion, focusing on low-resource languages like Persian. It aims to improve G2P accuracy while maintaining low latency for real-time applications. The methodology involves creating a rich homograph dataset (HomoRich) using a semi-automated pipeline and developing a fast, rule-based system (HomoFast eSpeak) enhanced with statistical context understanding. Results demonstrate a 30.66% improvement in homograph disambiguation accuracy using HomoFast eSpeak. This approach enables the development of more accurate and efficient G2P systems for accessibility tools in low-resource settings. |
| Natural Language Processing | LLM Context Conditioning and PWP Prompting for Multimodal Validation of
  Chemical Formulas (Read more on [arXiv](https://arxiv.org/abs/2505.12257) or [HuggingFace](https://huggingface.co/papers/2505.12257))| PChemGuy | The paper investigates techniques to improve the reliability of Large Language Models (LLMs) for validating chemical formulas within scientific documents, specifically addressing their tendency to mask errors through error correction. The main research question is how to modulate LLM behavior at inference time using structured context conditioning informed by Persistent Workflow Prompting (PWP) principles. The key methodology involves testing various prompting strategies, including adapting PWP structures to condition the LLM's analytical mindset, on Gemini 2.5 Pro and ChatGPT Plus 03 using only standard chat interfaces. The results show that PWP-informed context conditioning improved textual error identification and, notably, guided Gemini 2.5 Pro to identify an image-based error previously overlooked. The study implies that PWP-informed context conditioning offers a promising technique for developing robust LLM-driven analytical workflows for meticulous error detection, particularly when modifications to models and API access are inaccessible. |
| Natural Language Processing | TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique
  Annotation in Cyber Threat Intelligence Text (Read more on [arXiv](https://arxiv.org/abs/2505.11988) or [HuggingFace](https://huggingface.co/papers/2505.11988))| mparvez, TahaSencar, utsavshukla, lekssays | The paper introduces TechniqueRAG, a retrieval-augmented generation framework for automatically annotating adversarial techniques in cyber threat intelligence text. It aims to address the trade-off between generic models with limited precision and resource-intensive pipelines requiring extensive labeled data. TechniqueRAG integrates off-the-shelf retrievers, instruction-tuned LLMs, and minimal text-technique pairs, enhanced by a zero-shot LLM re-ranking. Experiments demonstrate that TechniqueRAG achieves state-of-the-art performance without extensive task-specific optimization, reaching an F1 score of 91.09% on the Procedures dataset. This provides AI practitioners with an effective method for automating adversarial technique identification in security texts. |
| Natural Language Processing | AI-Driven Scholarly Peer Review via Persistent Workflow Prompting,
  Meta-Prompting, and Meta-Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.03332) or [HuggingFace](https://huggingface.co/papers/2505.03332))| PChemGuy | This paper introduces Persistent Workflow Prompting (PWP), a prompt engineering methodology for complex analytical tasks using LLMs. The research focuses on codifying expert review workflows, including tacit knowledge, through meta-prompting and meta-reasoning techniques. A proof-of-concept PWP prompt is presented for critical analysis of experimental chemistry manuscripts, demonstrating detailed workflow decomposition. Demonstrations show the PWP-guided LLM identifying major methodological flaws in a test case and mitigating LLM input bias. This work offers insights into meta-development process using PWP to enable sophisticated analysis for complex scientific tasks. |
