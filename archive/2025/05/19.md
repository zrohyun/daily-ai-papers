

## Papers for 2025-05-19

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | Qwen3 Technical Report (Read more on [arXiv](https://arxiv.org/abs/2505.09388) or [HuggingFace](https://huggingface.co/papers/2505.09388))| huybery, BeichenZhang, Baosong, laf070810, yangapku | The Qwen3 Technical Report introduces a new version of the Qwen large language model family, focusing on enhanced performance and multilingual capabilities. The primary objective is to integrate thinking and non-thinking modes within a unified framework, allowing dynamic mode switching during inference. The methodology involves pre-training on 36 trillion tokens, incorporating a thinking budget mechanism, and multi-stage post-training involving long-CoT finetuning and reinforcement learning. Empirical results show that the Qwen3-235B-A22B model achieves 85.7 on AIME'24, demonstrating state-of-the-art results across diverse benchmarks. This allows for more flexible and efficient resource allocation during inference based on task complexity. |
| Multi-Modal | GuardReasoner-VL: Safeguarding VLMs via Reinforced Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.11049) or [HuggingFace](https://huggingface.co/papers/2505.11049))| Tri Cao, Yulin Chen, Mingzhe Du, Shengfang Zhai, Yue Liu | The paper introduces GuardReasoner-VL, a novel reasoning-based VLM guard model to enhance the safety of VLMs. It aims to improve safety by incentivizing the guard model to reason before moderation decisions via online RL. The methodology involves constructing a large reasoning corpus, cold-starting the model via SFT, and enhancing reasoning through online RL with safety-aware data concatenation and a dynamic clipping parameter. Experiments demonstrate that GuardReasoner-VL surpasses the runner-up by 19.27% F1 score on average, indicating significant performance improvements. This work offers a new approach to building interpretable and generalizable VLM guard models, contributing to safer AI systems. |
| Multi-Modal | MMLongBench: Benchmarking Long-Context Vision-Language Models
  Effectively and Thoroughly (Read more on [arXiv](https://arxiv.org/abs/2505.10610) or [HuggingFace](https://huggingface.co/papers/2505.10610))| Yu Zhao, Jipeng Zhang, Xiyu Ren, Wenhao Yu, Zhaowei Wang | The paper introduces MMLONGBENCH, a new benchmark for evaluating long-context vision-language models (LCVLMs). It addresses shortcomings in existing benchmarks, such as limited task coverage and lack of context length control. The benchmark comprises 13,331 examples across five downstream tasks and various image types with standardized input lengths up to 128K tokens. Benchmarking of 46 LCVLMs reveals that performance on a single task is a weak proxy for overall long-context capability; for example, even GPT-4o only achieves 62.9% average accuracy. MMLONGBENCH facilitates diagnosing limitations like OCR and cross-modality retrieval in current LCVLMs, guiding the development of next-generation models. |
| Computer Vision | Visual Planning: Let's Think Only with Images (Read more on [arXiv](https://arxiv.org/abs/2505.11409) or [HuggingFace](https://huggingface.co/papers/2505.11409))| ivulic, akorhonen, caiqizh, masonxw, hzhouml | The paper introduces Visual Planning, a novel paradigm enabling planning through purely visual representations independent of text for tasks requiring spatial reasoning. It questions the reliance on language for reasoning in multimodal models, particularly in vision-first tasks. The key methodology involves a reinforcement learning framework, VPRL, that uses GRPO for post-training vision models to generate image trajectories. The results show VPRL significantly outperforms text-based reasoning, achieving over 40% higher exact-match rate across navigation tasks like FROZENLAKE, MAZE, and MINIBEHAVIOR. This work suggests a promising alternative to language-based reasoning for tasks that benefit from image-based inference, improving both performance and generalization. |
| Computer Vision | Simple Semi-supervised Knowledge Distillation from Vision-Language
  Models via texttt{D}ual-texttt{H}ead
  texttt{O}ptimization (Read more on [arXiv](https://arxiv.org/abs/2505.07675) or [HuggingFace](https://huggingface.co/papers/2505.07675))| Sung Ju Hwang, Hyungjoon Jang, Seongjae Kang, dongboklee | This paper introduces Dual-Head Optimization (DHO), a knowledge distillation framework for transferring knowledge from large Vision-Language Models (VLMs) to compact models in semi-supervised settings. The research aims to improve knowledge distillation by mitigating gradient conflicts between supervised and distillation signals. DHO employs dual prediction heads, independently learning from labeled data and teacher predictions, linearly combining their outputs during inference. Experiments show DHO improves ImageNet accuracy by 3% and 0.1% with 1% and 10% labeled data, respectively, outperforming single-head baselines across 11 datasets. DHO enables AI practitioners to create more efficient and accurate computer vision models by improving knowledge distillation from VLMs with reduced computational overhead. |
| Natural Language Processing | Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token
  Level Granularity (Read more on [arXiv](https://arxiv.org/abs/2505.11107) or [HuggingFace](https://huggingface.co/papers/2505.11107))| Yi-Chang Chen, Feng-Ting Liao, Jamie McGowan, Davide Buffelli, Splend1dchan | The paper introduces Group Think, a novel paradigm where a single LLM acts as multiple concurrent reasoning agents that collaborate at the token level to improve generation quality and reduce latency. The research objective focuses on enabling fine-grained, token-level collaboration among reasoning trajectories, allowing them to adapt dynamically to each other. The methodology involves modifying existing LLMs to perform concurrent reasoning, where multiple threads share visibility into each other's progress and can shift generation mid-sentence based on which thread is better positioned to continue. Evaluation with open-source LLMs demonstrates that Group Think can improve reasoning accuracy while reducing latency without explicit training for the paradigm. This approach offers AI practitioners a more efficient and sophisticated way to achieve higher-quality generation, especially in resource-constrained environments, such as edge inference. |
| Machine Learning | Mergenetic: a Simple Evolutionary Model Merging Library (Read more on [arXiv](https://arxiv.org/abs/2505.11427) or [HuggingFace](https://huggingface.co/papers/2505.11427))| erodola, crisostomi, teelinsan, tmencatt, adrianrob | Mergenetic is an open-source library facilitating evolutionary model merging to combine capabilities of existing models without retraining. The library addresses the lack of tools for experimenting with evolutionary algorithms in language models by enabling easy composition of merging methods and evolutionary algorithms, while incorporating lightweight fitness estimators. It integrates 19 evolutionary algorithms and 6 merging strategies, reducing evaluation costs through subsampling and approximation. Mergenetic achieves competitive results across tasks and languages using modest hardware, with up to 19% accuracy gain demonstrated on the ARC-Challenge benchmark when merging multilingual models. The library allows AI practitioners to explore high-quality model compositions without large-scale infrastructure. |
| Machine Learning | MPS-Prover: Advancing Stepwise Theorem Proving by Multi-Perspective
  Search and Data Curation (Read more on [arXiv](https://arxiv.org/abs/2505.10962) or [HuggingFace](https://huggingface.co/papers/2505.10962))| Tao Yang, Yang Li, haitaominlp, freesunshine0316, invokerliang | The paper introduces MPS-Prover, a novel stepwise Automated Theorem Proving (ATP) system leveraging multi-perspective search and curated training data. It aims to overcome limitations in existing stepwise provers, such as biased search guidance. The system incorporates a data curation strategy and a multi-perspective tree search mechanism using a learned critic model and heuristic rules. MPS-Prover achieves state-of-the-art performance on benchmarks like miniF2F (75.82% accuracy) and ProofNet, outperforming prior 7B parameter models. This demonstrates a robust framework for LLM-based formal reasoning and the development of more powerful theorem provers. |
| Natural Language Processing | Multi-Token Prediction Needs Registers (Read more on [arXiv](https://arxiv.org/abs/2505.10518) or [HuggingFace](https://huggingface.co/papers/2505.10518))| Nikos Komodakis, Spyros Gidaris, nasos10 | The paper introduces MuToR, a novel and efficient multi-token prediction approach for autoregressive language models. It addresses the limitations of standard next-token prediction by interleaving trainable register tokens into input sequences, each tasked with predicting future targets at scalable horizons. MuToR demonstrates effectiveness in supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and pretraining, improving performance on generative tasks in both language and vision domains.  For example, MuToR improves exact match accuracy in mathematical reasoning tasks by up to ~2%, outperforming Multi-Token and standard fine-tuning baselines. This method offers AI practitioners a simple yet powerful tool to enhance the learning signal and improve task performance without architectural modifications. |
| Computer Vision | Learning Dense Hand Contact Estimation from Imbalanced Data (Read more on [arXiv](https://arxiv.org/abs/2505.11152) or [HuggingFace](https://huggingface.co/papers/2505.11152))| kyoungmu, dqj5182 | The paper introduces a framework for learning dense hand contact estimation from imbalanced data. It aims to address class and spatial imbalance issues prevalent in hand contact datasets. The method employs balanced contact sampling to mitigate class imbalance and a vertex-level class-balanced loss to handle spatial imbalance. Experiments show substantial performance gains over prior methods, with the full model achieving an F1-score of 0.531 on the MOW dataset. This enables improved downstream tasks like 3D grasp optimization and hand-object reconstruction. |
| Natural Language Processing | Scaling Reasoning can Improve Factuality in Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.11140) or [HuggingFace](https://huggingface.co/papers/2505.11140))| rubis, bjerva, jjzha | This paper investigates whether scaling reasoning in large language models (LLMs) can improve factual accuracy in open-domain question answering (QA). The study examines LLM reasoning by distilling traces from large reasoning models and fine-tuning Qwen2.5 models with knowledge graph (KG) paths integrated into reasoning traces. Results indicate that smaller instruction-tuned models benefit from KG-enhanced reasoning, improving factual accuracy. Test-time scaling through increased compute and token budgets consistently improves accuracy by 2-8%, suggesting the effectiveness of scaling reasoning for open-domain QA. The findings suggest that carefully scaled reasoning approaches can improve factuality in LLMs, especially for smaller models. |
| Machine Learning | Humans expect rationality and cooperation from LLM opponents in
  strategic games (Read more on [arXiv](https://arxiv.org/abs/2505.11011) or [HuggingFace](https://huggingface.co/papers/2505.11011))| Miguel Costa-Gomes, Darija Barak | This paper investigates human behavior in strategic games when interacting with LLM opponents. The study explores whether humans perceive LLMs differently than humans in a multi-player p-beauty contest. A within-subject experiment was conducted where participants played against both human and LLM (ChatGPT 3.5 and Claude v2) opponents. Results show that human subjects choose significantly lower numbers against LLMs, driven by an increased prevalence of zero-choices, especially among participants with high strategic reasoning ability (p < 0.004). The finding implies that human-AI mechanism design should account for varied beliefs about LLM rationality and potential cooperativeness. |
| Natural Language Processing | MatTools: Benchmarking Large Language Models for Materials Science Tools (Read more on [arXiv](https://arxiv.org/abs/2505.10852) or [HuggingFace](https://huggingface.co/papers/2505.10852))| David J. Srolovitz, Bo Hu, Beilin Ye, Jiamin Xu, SiyuLiu | This paper introduces MatTools, a benchmark for evaluating large language models (LLMs) in materials science tool usage. It assesses LLMs' ability to generate and execute codes based on physics-based computational materials science packages. The methodology involves a materials simulation tool question-answer (QA) benchmark derived from the pymatgen codebase and a real-world tool-usage benchmark comprising 49 tasks. Results show that general-purpose LLMs outperform materials science-focused LLMs, with GPT-40 achieving 80% accuracy in QA tasks, and that LLM-generated documentation improves performance in retrieval-augmented generation (RAG) systems by up to 115.7%. MatTools provides a standardized framework for improving LLM capabilities in materials science and scientific research. |
