

## Papers for 2025-05-12

| Category | Title | Authors | Summary |
|----------|-------|---------|---------|
| Natural Language Processing | Bielik v3 Small: Technical Report (Read more on [arXiv](https://arxiv.org/abs/2505.02550) or [HuggingFace](https://huggingface.co/papers/2505.02550))| Adrian Gwoździej, Łukasz Flis, djstrong, Remek, chrisociepa | This paper introduces Bielik v3, a series of parameter-efficient (1.5B, 4.5B) generative text models optimized for Polish language processing. The research objective is to demonstrate that smaller, well-optimized architectures can achieve performance comparable to much larger models for less-resourced languages like Polish, requiring substantially fewer computational resources. Key methodologies include adapting Qwen2.5 models using depth up-scaling, replacing the original tokenizer with a custom Polish one (APT4), utilizing Adaptive Learning Rate, pre-training on a curated 292 billion token corpus, and applying post-training techniques like SFT and DPO-P. The 4.5B parameter model achieves results competitive with models 2-3 times its size across multiple Polish benchmarks, such as scoring 56.13 on the Open PL LLM Leaderboard (instruct, 5-shot). The main implication is that high-quality, efficient language models for less-represented languages are feasible, enhancing accessibility for resource-constrained applications. |
| Natural Language Processing | Bielik 11B v2 Technical Report (Read more on [arXiv](https://arxiv.org/abs/2505.02410) or [HuggingFace](https://huggingface.co/papers/2505.02410))| Adrian Gwoździej, Łukasz Flis, Remek, djstrong, chrisociepa | This report introduces Bielik 11B v2, a state-of-the-art language model optimized for Polish text processing with 11 billion parameters. The primary objective was to develop and evaluate a high-performing, parameter-efficient language model specifically for Polish, building upon the Mistral 7B v0.2 architecture. Key methodologies include depth up-scaling to 11B parameters, pre-training on 198 billion tokens, and innovative techniques like Weighted Instruction Cross-Entropy Loss (WICEL) and Adaptive Learning Rate (ALR), followed by supervised fine-tuning (SFT) and DPO-Positive (DPO-P) alignment. Results show Bielik 11B v2 significantly outperforms previous Polish models and many larger models, achieving a score of 65.71 on the Open PL LLM Leaderboard (v2.3-Instruct) and demonstrating strong resilience to quantization. The main implication for AI practitioners is the availability of a powerful, resource-efficient model for Polish language tasks, showcasing effective methods for developing LLMs for less-represented languages. |
| Natural Language Processing | Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health
  Information (Read more on [arXiv](https://arxiv.org/abs/2505.06046) or [HuggingFace](https://huggingface.co/papers/2505.06046))| Toby Nonnenmacher, Timothy Laurence, Felix Feldman, Fan Grayson, Joshua-Harris | This paper introduces PubHealthBench, a new benchmark and dataset for evaluating Large Language Models' (LLMs) knowledge of UK Government public health information. The primary objective is to assess the accuracy and reliability of LLMs in retrieving and understanding this critical domain-specific information. The methodology involves an automated pipeline to generate over 8000 Multiple Choice Question Answering (MCQA) and free-form questions from extracted UK public health guidance documents, followed by evaluating 24 LLMs. Key findings show that state-of-the-art private LLMs like GPT-4.5 achieve over 90% accuracy in MCQA, surpassing human performance with cursory search, but no model scores above 75% in the more challenging free-form response setting. This implies that while advanced LLMs are increasingly accurate sources of public health information, additional safeguards are necessary when they provide free-form responses, particularly for smaller models. |
| Multi-Modal | UniVLA: Learning to Act Anywhere with Task-centric Latent Actions (Read more on [arXiv](https://arxiv.org/abs/2505.06111) or [HuggingFace](https://huggingface.co/papers/2505.06111))| Shenyuan Gao, Jisong Cai, Yanting Yang, Qingwen Bu, sundrops | UniVLA introduces a generalist vision-language-action (VLA) framework enabling robot policy learning across diverse environments using task-centric latent actions derived from videos without explicit action labels. The objective is to overcome limitations of action supervision and enable scalable knowledge transfer across different embodiments by learning a unified action representation. Key methodology involves unsupervised learning of discretized latent actions from video frame pairs using a VQ-VAE on DINOv2 features, conditioned on language instructions to isolate task-relevant dynamics, followed by pretraining an auto-regressive VLM and efficient downstream decoding. UniVLA significantly outperforms prior methods like OpenVLA, achieving a 95.2% average success rate on the LIBERO benchmark with substantially less pretraining compute and data. This work demonstrates a path towards scalable robot policy learning by effectively leveraging large-scale, heterogeneous video data through latent action modeling. |
| Multi-Modal | G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness (Read more on [arXiv](https://arxiv.org/abs/2505.05026) or [HuggingFace](https://huggingface.co/papers/2505.05026))| Yejin Choi, Sumin Shim, Min Soo Kim, Jang Han Yoon, jeochris | This paper introduces G-FOCUS, a robust method using Vision-Language Models (VLMs) to assess the comparative persuasiveness of user interface (UI) designs. The primary objectives are to quantitatively evaluate VLM capabilities in this domain and enhance evaluation reliability by mitigating biases like position bias. The key methodology involves introducing WISERUI-BENCH, a benchmark of 300 real-world UI image pairs with A/B test results, and proposing G-FOCUS, a multi-step inference-time reasoning strategy (goal extraction, difference localization, contrastive reasoning, rationale-based evaluation). Experiments show G-FOCUS significantly improves performance, achieving +12.66% higher Consistent Accuracy (CA) with GPT-4o compared to the best baseline. The main implication is providing a scalable, AI-driven approach to complement traditional A/B testing for UI preference modeling and design optimization. |
| Reinforcement Learning | Sailing AI by the Stars: A Survey of Learning from Rewards in
  Post-Training and Test-Time Scaling of Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.02686) or [HuggingFace](https://huggingface.co/papers/2505.02686))| Xiaobao Wu | This survey provides a comprehensive overview of the "Learning from Rewards" paradigm used in post-training and test-time scaling of Large Language Models (LLMs). The main objective is to categorize and analyze the diverse strategies that leverage reward signals across training, inference, and post-inference stages to guide LLM behavior. Key methodologies reviewed encompass techniques like Reinforcement Learning from Human/AI Feedback (RLHF/RLAIF), Direct Preference Optimization (DPO), Group Relative Policy Optimization (GRPO), reward-guided decoding, and post-hoc correction, organized via a unified taxonomy based on reward source, design, and learning strategy. While the survey itself doesn't introduce new quantitative metrics, it synthesizes the successes reported in cited works, such as DeepSeek-R1 achieving advanced reasoning capabilities through GRPO and rule-based rewards. The primary implication for practitioners is a structured understanding of the available techniques for aligning LLMs with preferences, enhancing reasoning, and scaling models effectively beyond pre-training. |
| Multi-Modal | A Preliminary Study for GPT-4o on Image Restoration (Read more on [arXiv](https://arxiv.org/abs/2505.05621) or [HuggingFace](https://huggingface.co/papers/2505.05621))| Liyuan Pan, Ruikun Zhang, Yan Yang, Hao Yang | This paper presents the first systematic evaluation of OpenAI's GPT-4o for image restoration tasks. The primary objective is to investigate GPT-4o's potential and limitations in restoring images across diverse degradations like haze, rain, blur, and noise. Methodologically, the study involves quantitative (PSNR, CLIP-IQA) and qualitative assessment on various datasets, identifies common failure modes (e.g., geometric distortion, viewpoint shifts), and proposes a baseline approach using GPT-4o's outputs as visual priors fused into a traditional restoration network (Restormer). Key results show that while GPT-4o generates visually appealing outputs (high CLIP-IQA), it suffers from poor pixel-level structural fidelity (e.g., 13.13 PSNR on O-Haze); however, using its outputs as priors significantly enhances existing networks, improving both perceptual quality (0.566 CLIP-IQA) and structural fidelity (22.08 PSNR on O-Haze) over the baseline. The main implication for AI practitioners is that while GPT-4o is not yet a standalone solution for high-fidelity restoration, its generative outputs can serve as powerful priors to boost the performance of specialized restoration models. |
